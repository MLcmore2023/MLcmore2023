{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fba795af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'C': 0.1, 'gamma': 0.1, 'kernel': 'poly'}\n",
      "Test accuracy with best hyperparameters: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the Iris dataset\n",
    "data = load_iris()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the SVM classifier\n",
    "svm_classifier = SVC()\n",
    "\n",
    "# Define the hyperparameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'kernel': ['linear', 'poly', 'rbf'],\n",
    "    'C': [0.1, 1, 10],\n",
    "    'gamma': [0.1, 1, 'scale']\n",
    "}\n",
    "\n",
    "# Create the GridSearchCV object with cross-validation (e.g., 5-fold cross-validation)\n",
    "grid_search = GridSearchCV(svm_classifier, param_grid, cv=5)\n",
    "\n",
    "# Perform the hyperparameter tuning on the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters from the GridSearchCV\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best hyperparameters:\", best_params)\n",
    "\n",
    "# Evaluate the model with the best hyperparameters on the test data\n",
    "best_svm_classifier = grid_search.best_estimator_\n",
    "y_pred = best_svm_classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Test accuracy with best hyperparameters:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a2d77a",
   "metadata": {},
   "source": [
    "Bagging\n",
    "- Question: What is the main principle behind the Bagging technique? How does it help in reducing overfitting?\n",
    "- Answer: Bagging, or Bootstrap Aggregating, involves training multiple models independently on different bootstrapped subsets of the data and then aggregating their predictions. By averaging out the errors, bagging helps in reducing the variance and thus overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb3d1ed",
   "metadata": {},
   "source": [
    "Boosting\n",
    "- Question: Describe how boosting works. How is it different from bagging?\n",
    "- Answer: Boosting trains learners sequentially where each subsequent learner tries to correct the mistakes of the previous one. Unlike bagging, which aims to reduce variance, boosting aims to reduce bias and variance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb38a29a",
   "metadata": {},
   "source": [
    "1. High Variance Model:\n",
    "- You've trained a deep decision tree on your dataset and noticed that it performs extremely well on the training data but poorly on the validation data.\n",
    "\n",
    "- Question: Which ensemble technique might help remedy this, bagging or boosting?\n",
    "- Answer: Bagging. The described scenario suggests overfitting, which is a result of high variance. Bagging is more appropriate for reducing variance.\n",
    "2. High Bias Model:\n",
    "- Your team trained a shallow decision tree (i.e., a decision stump) on a complex dataset. The model performs poorly on both training and validation sets.\n",
    "\n",
    "- Question: Which ensemble technique might help improve this model's performance, bagging or boosting?\n",
    "- Answer: Boosting. The model is underfitting the data, which is a sign of high bias. Boosting aims to reduce bias by sequentially correcting the errors of the previous models.\n",
    "3. Large Dataset:\n",
    "- You have a very large dataset and are concerned about the training time. You're considering an ensemble technique to improve your model's performance.\n",
    "\n",
    "- Question: Which technique, bagging or boosting, would typically be faster in training?\n",
    "- Answer: Bagging. Boosting trains models sequentially, where each model tries to correct the errors of the previous one, which can be time-consuming. Bagging trains its models in parallel, making it often faster, especially with large datasets.\n",
    "4. Noisy Data:\n",
    "- Your dataset contains a significant amount of noise, and outliers are causing models to underperform.\n",
    "\n",
    "- Question: Which ensemble method, bagging or boosting, might be more robust to such noise and why?\n",
    "- Answer: Bagging. Boosting might overemphasize the outliers by giving them higher weights, leading to overfitting. Bagging, by averaging out predictions, is generally more robust to noisy data.\n",
    "5. Model Diversity:\n",
    "- You're working on an ensemble model, and you have access to various diverse base models. You believe the errors in these models are largely uncorrelated.\n",
    "\n",
    "- Question: Which ensemble technique might benefit more from this diversity, bagging or boosting?\n",
    "- Answer: Bagging. Bagging benefits greatly from the independence of errors among base models. If each model makes different errors, bagging can average them out, leading to a strong combined prediction.\n",
    "6. Information on Error Types:\n",
    "- After evaluating a model, you've noticed that it's making many types of errors, but the frequency of each type is low.\n",
    "\n",
    "- Question: If you had to choose an ensemble technique to correct diverse error types, would you pick bagging or boosting?\n",
    "- Answer: Boosting. Boosting is designed to sequentially correct the errors of previous models, making it suitable for addressing diverse types of errors.\n",
    "7. Final Model Interpretability:\n",
    "- You're working on a healthcare project where the interpretability of the model is crucial. Doctors want to understand how the model makes decisions.\n",
    "\n",
    "- Question: Which ensemble technique, bagging or boosting, might be more challenging in terms of interpretability, and why?\n",
    "- Answer: Both techniques can be challenging for interpretability as they combine multiple models. However, boosting, especially with many iterations, can be more challenging because it focuses on correcting errors sequentially, leading to a more complex combined model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe903d28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
