# MLcmore2023

| Session | Lecture                          | Lab (up to 2 hours)                   | TA    |
| ------- | -------------------------------- | ------------------------------------- | ----- |
| D1-M    | 1. Introduction to AI and ML     | 1. Colab setup                        | Bruce |
|         | 2. Steps in ML project           | 2. Python refresh                     |       |
|         |                                  | 3. Visualization: t-SNE              |       |
| D1-A    | 1. Data preprocessing & EDA      | 1. Data prep: scaling, normalization, imputation | Bruce |
|         | 2. Performance evaluation        | 2. Feature selection                  |       |
|         |                                  | 3. Model evaluation: classification, regression |       |
| D2-M    | 1. Model training                | 1. Model tune up                      | Bruce |
|         |                                  | 2. Bagging and Boosting               |       |
|         |                                  | 3. Supply chain example               |       |
| D2-A    | 1. Supervised learning           | 1. Supervised learning                | Ramy  |
| D3-M    | 1. Supervised learning           | 1. Supervised learning                | Nathan, Ramy |
| D3-A    | 1. Supervised learning           | 1. Supervised learning                | Ramy  |
| D4-M    | 1. Deep learning                 | 1. Deep learning                      | Nathan, Ramy |
| D4-A    | 1. Deep learning                 | 1. Deep learning                      | Ramy  |
| D5-M    | 1. Deep learning                 | 1. Deep learning                      | Nathan, Ramy |
| D5-A    | Evaluation                       |                                      | Ramy  |
| D6-M    | 1. Unsupervised learning         | 1. PCA                                | Ramy  |
|         |                                  | 2. K-mean and cluster # optimization (elbow method) |       |
| D6-A    | 1. Unsupervised learning         | 1. Hierarchical clustering            | Ramy  |
|         |                                  | 2. Soft-clustering (expectation maximization) |       |
| D7-M    | 1. Markov decision process       | 1. Standard methods for MDP such as PI and VI | Matin |
|         |                                  | • Formulation: transition probabilities, reward, … |       |
|         |                                  | • Policy evaluation                   |       |
| D7-A    | 1. MDP                          | 1. PI and VI                          | Matin |
|         | 2. Monte Carlo method            | 2. Monte Carlo method                  |       |
|         |                                  | • Return computation                  |       |
|         |                                  | • Generalized Policy Iteration        |       |
| D8-M    | 1. Tabular RL                   | 1. Tabular RL: Q-learning, SARSA       | Matin |
| D8-A    | 1. Deep RL                      | 1. Deep RL: DQN and others            | Matin |
| D9-M    | 1. Policy optimization           | 1. Policy optimization: REINFORCE, DPG, DDPG | Matin |
| D9-A    | 1. Model-based RL, MARL          | 1. Dyna-Q, MARL                       | Matin |
| D10-M   | 2. RL for Applications           | 1. DQN for optimal maintenance, Sim2Real for robotic control | Matin |
| D10-A   | Evaluation                       |                                      | Matin |
