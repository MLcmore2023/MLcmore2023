{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e21a0f0d",
   "metadata": {
    "id": "e21a0f0d"
   },
   "source": [
    "# Model Prediction Improvement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf1a029",
   "metadata": {
    "id": "0cf1a029"
   },
   "source": [
    "# 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2444c37",
   "metadata": {
    "id": "c2444c37"
   },
   "source": [
    "There are several methods that can help improve the prediction performance of models. Here are some commonly used techniques:\n",
    "\n",
    "1. Feature engineering: This involves creating new features or transforming existing ones to better represent the underlying patterns in the data. It can include techniques like scaling, normalization, one-hot encoding, dimensionality reduction, and creating interaction terms.\n",
    "\n",
    "\n",
    "2. Hyperparameter tuning: Models often have hyperparameters that need to be set before training. Hyperparameter tuning involves systematically searching for the best combination of hyperparameter values that optimize the model's performance. Techniques like grid search, random search, and Bayesian optimization can be used for hyperparameter tuning.\n",
    "\n",
    "\n",
    "3. Cross-validation: Cross-validation is a technique used to assess the performance of a model and tune hyperparameters. It involves splitting the data into multiple subsets, training the model on one subset, and evaluating its performance on the remaining subsets. This helps to get a more reliable estimate of the model's performance and avoid overfitting.\n",
    "\n",
    "\n",
    "4. Ensemble methods: Ensemble methods combine multiple models to improve prediction performance. This can be done by averaging the predictions of individual models (e.g., bagging), using weighted averages (e.g., boosting), or allowing models to vote on the final prediction (e.g., random forests). Ensemble methods can help reduce variance, increase stability, and improve generalization.\n",
    "\n",
    "\n",
    "5. Regularization techniques: Regularization methods help prevent overfitting by adding a penalty term to the model's objective function. Techniques like L1 regularization (Lasso), L2 regularization (Ridge), and Elastic Net can be used to shrink the coefficients of less important features or encourage sparsity in the model.\n",
    "\n",
    "\n",
    "6. Data augmentation: Data augmentation involves generating additional training data by applying random transformations or perturbations to the existing data. This helps to increase the diversity of the training set and can improve the model's ability to generalize to new examples.\n",
    "\n",
    "\n",
    "7. Transfer learning: Transfer learning leverages knowledge from pre-trained models that have been trained on large-scale datasets. By utilizing the learned representations from these models, transfer learning allows for better performance on smaller or domain-specific datasets. This is particularly useful when the available training data is limited.\n",
    "\n",
    "\n",
    "8. Model ensembling: Model ensembling involves combining the predictions of multiple models, often of different types, to make a final prediction. This can be done through techniques like stacking, where the predictions of individual models are used as input features for a meta-model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07281e64",
   "metadata": {
    "id": "07281e64"
   },
   "source": [
    "# 2. Basic Model without Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3a0cf2d5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "3a0cf2d5",
    "outputId": "fc4ada05-d780-4b4d-bddf-3367cefed5ff"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.001383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.037193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.013667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2 score</th>\n",
       "      <td>0.998021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Result\n",
       "MSE       0.001383\n",
       "RMSE      0.037193\n",
       "MAE       0.013667\n",
       "r2 score  0.998021"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Model without additional techniques\n",
    "model_basic = RandomForestRegressor(random_state=42)\n",
    "model_basic.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_pred_basic = model_basic.predict(X_test)\n",
    "mse_basic = mean_squared_error(y_test, y_pred_basic)\n",
    "rmse_basic = np.sqrt(mse_basic)\n",
    "mae_basic = mean_absolute_error(y_test, y_pred_basic)\n",
    "r2_basic = r2_score(y_test, y_pred_basic)\n",
    "\n",
    "finalleaderboard = {\n",
    "    'MSE': mse_basic,\n",
    "    'RMSE': rmse_basic,\n",
    "    'MAE': mae_basic,\n",
    "    'r2 score': r2_basic\n",
    "}\n",
    "\n",
    "finalleaderboard = pd.DataFrame.from_dict(finalleaderboard, orient='index', columns=['Result'])\n",
    "finalleaderboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8269c8d",
   "metadata": {},
   "source": [
    "1. **Mean Squared Error (MSE)**: It measures how close the predicted values are to the true values by calculating the average of the squared differences between them. Smaller MSE values are better.\n",
    "\n",
    "\n",
    "2. **Root Mean Squared Error (RMSE)**: It's the square root of MSE. It gives an average measure of the difference between the predicted values and the true values. Smaller RMSE values are better.\n",
    "\n",
    "\n",
    "3. **Mean Absolute Error (MAE)**: It measures the average difference between the predicted values and the true values, regardless of the direction. Smaller MAE values are better.\n",
    "\n",
    "\n",
    "4. **R-squared (R2) Score**: It tells us how well the model fits the data by representing the proportion of the target variable's variance that can be explained by the model. Higher R2 values are better, with 1 being the best possible score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61aa2cf8",
   "metadata": {},
   "source": [
    "**For MSE, RMSE, and MAE, lower values are better. For R2, a higher value closer to 1 is better.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b123a81a",
   "metadata": {
    "id": "b123a81a"
   },
   "source": [
    "# 3. Improved Model with Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac468ab",
   "metadata": {
    "id": "cac468ab"
   },
   "source": [
    "Here's an example showcasing a few methods for improving prediction performance using a real dataset. In this example, we'll be using the Boston Housing dataset, which is available in the scikit-learn library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b434ae1",
   "metadata": {
    "id": "1b434ae1"
   },
   "source": [
    "## 3.1 Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1d5f6307",
   "metadata": {
    "id": "1d5f6307"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aab62b7",
   "metadata": {
    "id": "4aab62b7"
   },
   "source": [
    "In this example, we start by loading the Boston Housing dataset using **load_boston()** from scikit-learn. Then, we split the data into training and test sets using **train_test_split()**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4ee79785",
   "metadata": {
    "id": "4ee79785"
   },
   "outputs": [],
   "source": [
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91212808",
   "metadata": {
    "id": "91212808"
   },
   "source": [
    "## 3.2 Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244f0dce",
   "metadata": {
    "id": "244f0dce"
   },
   "source": [
    "We perform data augmentation by shuffling and duplicating the training data. This helps increase the diversity of the training set and can improve the model's generalization capability. We use **shuffle()** from scikit-learn's **utils** module to shuffle the training data, and then concatenate the original and shuffled data along with their respective target values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bdd51daa",
   "metadata": {
    "id": "bdd51daa"
   },
   "outputs": [],
   "source": [
    "# Data augmentation: Shuffle and duplicate training data\n",
    "X_train_augmented = np.vstack((X_train, shuffle(X_train)))\n",
    "y_train_augmented = np.concatenate((y_train, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6dcc840",
   "metadata": {},
   "source": [
    "`X_train_augmented = np.vstack((X_train, shuffle(X_train)))`: This line vertically stacks (concatenates vertically) the original training data X_train with a shuffled version of X_train. The shuffle(X_train) function shuffles the rows of X_train randomly. This augmentation technique helps introduce additional variations in the training data.\n",
    "\n",
    "`y_train_augmented = np.concatenate((y_train, y_train))`: This line concatenates the original training labels y_train with itself, duplicating the labels. The duplicated labels are added to match the augmented training data created in the previous line. By duplicating the labels, we ensure that each augmented example has a corresponding label."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd05536e",
   "metadata": {},
   "source": [
    "#### What is vertically stacking?\n",
    "\n",
    "Vertically stacking refers to concatenating arrays or matrices along their vertical axis. When you vertically stack two arrays or matrices, you are essentially stacking one on top of the other"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2fb962",
   "metadata": {
    "id": "ef2fb962"
   },
   "source": [
    "## 3.3 Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8a3a51",
   "metadata": {
    "id": "aa8a3a51"
   },
   "source": [
    "Next, we apply feature engineering by scaling the features using **StandardScaler().**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "884cc62c",
   "metadata": {
    "id": "884cc62c"
   },
   "outputs": [],
   "source": [
    "# Feature engineering: Scaling the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_augmented)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b874bc",
   "metadata": {
    "id": "25b874bc"
   },
   "source": [
    "## 3.4 Hyperparameter tuning using GridSearchCV for RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120c5cd4",
   "metadata": {
    "id": "120c5cd4"
   },
   "source": [
    "After that, we perform hyperparameter tuning using **GridSearchCV.** We define a parameter grid with different values for **n_estimators**, **max_depth**, and **min_samples_split**, and use it to search for the best combination of hyperparameters for the **RandomForestRegressor** model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1914778e",
   "metadata": {
    "id": "1914778e"
   },
   "outputs": [],
   "source": [
    "# Hyperparameter tuning using GridSearchCV for RandomForestRegressor\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [None, 5],\n",
    "    'min_samples_split': [2, 5]\n",
    "}\n",
    "\n",
    "\n",
    "grid_search_rf = GridSearchCV(RandomForestRegressor(random_state=42), # the model to be tuned (RandomForestRegressor)\n",
    "                              param_grid_rf, # the hyperparameter grid (param_grid_rf)\n",
    "                              cv=5 # the number of cross-validation folds\n",
    "                             )\n",
    "grid_search_rf.fit(X_train_scaled, y_train_augmented)\n",
    "best_model_rf = grid_search_rf.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1910986",
   "metadata": {},
   "source": [
    "`param_grid_rf`: Defines the grid of hyperparameters to be searched, including 'n_estimators', 'max_depth', and 'min_samples_split'.\n",
    "\n",
    "`grid_search_rf`: Creates a GridSearchCV object with the RandomForestRegressor model and the defined parameter grid.\n",
    "\n",
    "`grid_search_rf.fit(X_train_scaled, y_train_augmented)`: Fits the GridSearchCV object on the scaled training data and augmented labels, performing an exhaustive search and cross-validation to find the best hyperparameters.\n",
    "\n",
    "`best_model_rf`: Retrieves the best-performing model found during the search, represented by the optimal hyperparameter values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c9c5bc",
   "metadata": {
    "id": "29c9c5bc"
   },
   "source": [
    "## 3.5 Ridge Regression with Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243701fe",
   "metadata": {
    "id": "243701fe"
   },
   "source": [
    " We use **RidgeCV** from scikit-learn to perform ridge regression with built-in cross-validation for hyperparameter tuning. We select the best alpha (regularization parameter) using the training set and create a pipeline that includes scaling the features with **StandardScaler().**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "24a40737",
   "metadata": {
    "id": "24a40737"
   },
   "outputs": [],
   "source": [
    "ridge_cv = RidgeCV(alphas=[0.1, 1.0, 10.0])\n",
    "ridge_cv.fit(X_train_scaled, y_train_augmented)\n",
    "best_model_ridge = make_pipeline(StandardScaler(), RidgeCV())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ccbe7f",
   "metadata": {},
   "source": [
    "1. `ridge_cv`: Creates a RidgeCV object, which is a ridge regression model with built-in cross-validation. The alphas parameter specifies a list of alpha values to be tested during the cross-validation process.\n",
    "\n",
    "\n",
    "2. `ridge_cv.fit(X_train_scaled, y_train_augmented)`: Fits the RidgeCV model on the scaled training data (X_train_scaled) and augmented training labels (y_train_augmented). It performs cross-validation to determine the best alpha value based on the specified list.\n",
    "\n",
    "\n",
    "3. `best_model_ridge`: Creates a pipeline using make_pipeline. A pipeline is a way to chain multiple steps together, in this case, combining the StandardScaler and RidgeCV steps. The StandardScaler performs feature scaling, and RidgeCV is the ridge regression model with the best alpha value determined from cross-validation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db76390",
   "metadata": {
    "id": "2db76390"
   },
   "source": [
    "## 3.6 Ensemble method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61bf240b",
   "metadata": {
    "id": "61bf240b"
   },
   "source": [
    "We create an ensemble model using the best **RandomForestRegressor** model from the previous hyperparameter tuning step. We use **TransformedTargetRegressor** from scikit-learn to apply scaling to the target variable **(y)**. The ensemble model combines the predictions of the random forest model with the scaled target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0120eea9",
   "metadata": {
    "id": "0120eea9"
   },
   "outputs": [],
   "source": [
    "# Ensemble method: Model averaging\n",
    "ensemble_model = TransformedTargetRegressor(regressor=best_model_rf, transformer=StandardScaler())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbf8f36",
   "metadata": {
    "id": "abbf8f36"
   },
   "source": [
    "## 3.7 Cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd74804e",
   "metadata": {
    "id": "cd74804e"
   },
   "source": [
    "We use cross_val_score() from scikit-learn to perform cross-validation on the best models. We calculate the mean cross-validation scores and evaluate the models based on negative mean squared error (-cv_scores). Additionally, we calculate the mean squared error for the ensemble model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "de3d963b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "de3d963b",
    "outputId": "57fbe885-e7ae-4a0a-8eb1-87cf1609689e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest CV Score:  0.8646026859337071\n",
      "Ridge Regression CV Score:  0.7837979139653724\n"
     ]
    }
   ],
   "source": [
    "# Cross-validation\n",
    "cv_scores_rf = cross_val_score(best_model_rf, X_train_scaled, y_train_augmented, cv=5, scoring='neg_mean_squared_error')\n",
    "cv_scores_ridge = cross_val_score(best_model_ridge, X_train_scaled, y_train_augmented, cv=5, scoring='neg_mean_squared_error')\n",
    "cv_scores_ensemble = cross_val_score(ensemble_model, X_train_scaled, y_train_augmented, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Get the mean cross-validation scores\n",
    "mean_cv_score_rf = np.mean(np.sqrt(-cv_scores_rf))\n",
    "mean_cv_score_ridge = np.mean(np.sqrt(-cv_scores_ridge))\n",
    "mean_cv_score_ensemble = np.mean(np.sqrt(-cv_scores_ensemble))\n",
    "\n",
    "print(\"Random Forest CV Score: \", mean_cv_score_rf)\n",
    "print(\"Ridge Regression CV Score: \", mean_cv_score_ridge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18dd7bb9",
   "metadata": {},
   "source": [
    "`cv_scores_rf`: Uses cross_val_score to perform cross-validation for the RandomForestRegressor model (best_model_rf). It computes the negative mean squared error (neg_mean_squared_error) for each fold and stores the scores in cv_scores_rf.\n",
    "\n",
    "`cv_scores_ridge`: Performs cross-validation for the RidgeCV model (best_model_ridge). It computes the negative mean squared error (neg_mean_squared_error) for each fold and stores the scores in cv_scores_ridge.\n",
    "\n",
    "`cv_scores_ensemble`: Performs cross-validation for an ensemble model (not shown in the provided code). It computes the negative mean squared error (neg_mean_squared_error) for each fold and stores the scores in cv_scores_ensemble.\n",
    "\n",
    "`mean_cv_score_rf`: Calculates the mean cross-validation score for the RandomForestRegressor model by taking the negative square root of the average of cv_scores_rf.\n",
    "\n",
    "`mean_cv_score_ridge`: Calculates the mean cross-validation score for the RidgeCV model by taking the negative square root of the average of cv_scores_ridge.\n",
    "\n",
    "`mean_cv_score_ensemble`: Calculates the mean cross-validation score for the ensemble model by taking the negative square root of the average of cv_scores_ensemble."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ea55cb",
   "metadata": {
    "id": "e2ea55cb"
   },
   "source": [
    "## 3.8 Evaluate the ensemble model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "13d7f752",
   "metadata": {
    "id": "13d7f752"
   },
   "outputs": [],
   "source": [
    "ensemble_model.fit(X_train_scaled, y_train_augmented)\n",
    "y_pred_ensemble = ensemble_model.predict(X_test_scaled)\n",
    "mse_ensemble = mean_squared_error(y_test, y_pred_ensemble)\n",
    "rmse_ensemble = np.sqrt(mse_ensemble)\n",
    "mae_ensemble = mean_absolute_error(y_test, y_pred_ensemble)\n",
    "r2_ensemble = r2_score(y_test, y_pred_ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "af2bb079",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "af2bb079",
    "outputId": "6c17984b-3de9-4799-e826-95094ae3572a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.307318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.554363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.461029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2 score</th>\n",
       "      <td>0.560276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Result\n",
       "MSE       0.307318\n",
       "RMSE      0.554363\n",
       "MAE       0.461029\n",
       "r2 score  0.560276"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalleaderboard = {\n",
    "    'MSE': mse_ensemble,\n",
    "    'RMSE': rmse_ensemble,\n",
    "    'MAE': mae_ensemble,\n",
    "    'r2 score': r2_ensemble\n",
    "}\n",
    "\n",
    "finalleaderboard = pd.DataFrame.from_dict(finalleaderboard, orient='index', columns=['Result'])\n",
    "# finalleaderboard = finalleaderboard.sort_values('Accuracy', ascending=False)\n",
    "finalleaderboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43aa4faf",
   "metadata": {
    "id": "43aa4faf"
   },
   "source": [
    "# 4. Result Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4b08ca67",
   "metadata": {
    "id": "4b08ca67"
   },
   "outputs": [],
   "source": [
    "rmse_improved = rmse_ensemble\n",
    "mae_improved = mae_ensemble\n",
    "r2_improved = r2_ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0cf4162f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 130
    },
    "id": "0cf4162f",
    "outputId": "365f9a1f-d254-48e8-dcaa-9b1b050f3dbb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance Comparison\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R^2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Basic</td>\n",
       "      <td>0.037193</td>\n",
       "      <td>0.013667</td>\n",
       "      <td>0.998021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Improved</td>\n",
       "      <td>0.554363</td>\n",
       "      <td>0.461029</td>\n",
       "      <td>0.560276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Model      RMSE       MAE       R^2\n",
       "0     Basic  0.037193  0.013667  0.998021\n",
       "1  Improved  0.554363  0.461029  0.560276"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dataframe to display the evaluation metrics\n",
    "data = {\n",
    "    \"Model\": [\"Basic\", \"Improved\"],\n",
    "    \"RMSE\": [rmse_basic, rmse_improved],\n",
    "    \"MAE\": [mae_basic, mae_improved],\n",
    "    \"R^2\": [r2_basic, r2_improved]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(\"Model Performance Comparison\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840fcca0",
   "metadata": {
    "id": "840fcca0"
   },
   "source": [
    "## Why Model Improvement Techniques Sometimes Fail\n",
    "\n",
    "There could be several reasons why using model performance improvement techniques does not result in improved performance or may even worsen the results. Here are a few potential reasons:\n",
    "\n",
    "1. Data quality: The techniques applied might not be appropriate for the dataset or the specific problem at hand. It's important to select techniques that are suitable for the data characteristics and problem domain.\n",
    "\n",
    "2. Improper implementation: The techniques may not have been implemented correctly or may not have been tuned properly. It's crucial to understand the techniques thoroughly and apply them correctly to ensure their effectiveness.\n",
    "\n",
    "3. Overfitting: Some techniques, such as complex ensemble models or hyperparameter tuning, may inadvertently lead to overfitting if not properly controlled. Overfitting occurs when the model learns to perform well on the training data but fails to generalize to unseen data. This can result in worse performance on new data.\n",
    "\n",
    "4. Insufficient data or features: If the dataset is too small or lacks informative features, it may be challenging to improve the model's performance significantly. Techniques like feature engineering or data augmentation may not yield substantial improvements in such cases.\n",
    "\n",
    "5. Noise or outliers: If the dataset contains a significant amount of noise or outliers, it can adversely affect the model's performance. Some techniques may be sensitive to noise or outliers, leading to suboptimal results.\n",
    "\n",
    "6. Randomness and variability: Machine learning models can exhibit variability due to randomness, especially when using techniques like cross-validation or random initialization. It's possible that the observed performance differences are within the expected range of variability.\n",
    "\n",
    "It's essential to carefully analyze the specific techniques applied, the dataset characteristics, and thoroughly evaluate the results to understand why the model's performance did not improve as expected. Additionally, it's always beneficial to experiment with different techniques, explore alternative approaches, and iterate on the model improvement process to achieve better results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9997e95",
   "metadata": {
    "id": "f9997e95"
   },
   "source": [
    "# 5. Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277cf549",
   "metadata": {
    "id": "277cf549"
   },
   "source": [
    "You have been provided with a code snippet that compares the performance of a basic model with an improved model using various techniques. Your task is to modify the code and incorporate additional techniques to further enhance the model's performance. Experiment with at least two additional techniques such as feature selection, regularization, or ensemble methods. Evaluate the modified model and compare its performance against the basic model and the previous improved model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bede34d3",
   "metadata": {
    "id": "bede34d3"
   },
   "source": [
    "#### Instructions:\n",
    "\n",
    "1. Study the code provided and understand the implementation of the basic model and the techniques applied in the improved model.\n",
    "\n",
    "\n",
    "2. Choose two additional techniques that you want to incorporate into the model to further enhance its performance. Examples include feature selection (e.g., using SelectKBest), regularization (e.g., L1 or L2 regularization), or ensemble methods (e.g., Gradient Boosting or Stacking).\n",
    "\n",
    "\n",
    "3. Modify the code to include the chosen techniques. Make sure to appropriately apply the techniques, train the modified model, and evaluate its performance.\n",
    "\n",
    "\n",
    "4. Calculate and compare the evaluation metrics such as RMSE, MAE, and R-squared for the basic model, the previous improved model, and the modified model.\n",
    "\n",
    "\n",
    "5. Reflect on the results and analyze the impact of the additional techniques on the model's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0cc500",
   "metadata": {
    "id": "4c0cc500"
   },
   "source": [
    "#### Challenge:\n",
    "\n",
    "Experiment with different parameter settings or combinations of the additional techniques to find the best-performing model. Compare the performance of different combinations and discuss the findings in terms of the evaluation metrics.\n",
    "\n",
    "Note: You can refer to the scikit-learn documentation for more information about the techniques and parameters you choose to incorporate.\n",
    "\n",
    "By completing this exercise, you will gain hands-on experience in modifying and improving the model's performance using various techniques. It will also help deepen your understanding of how different techniques impact the evaluation metrics and overall model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d4048760",
   "metadata": {
    "id": "d4048760"
   },
   "outputs": [],
   "source": [
    "# write your code here\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
