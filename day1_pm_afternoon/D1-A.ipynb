{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "576fc3a2",
   "metadata": {},
   "source": [
    "# Day 1 - Afternoon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d89bebd",
   "metadata": {},
   "source": [
    "# 1. Data Cleaning and Data Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a023dcbf",
   "metadata": {},
   "source": [
    "## 1.1 Introduction to Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a59673",
   "metadata": {},
   "source": [
    "Data cleaning, also known as data cleansing or data scrubbing, refers to the process of identifying and correcting or removing errors, inconsistencies, and inaccuracies in a dataset. It is an essential step in data preprocessing and analysis to ensure that the data is accurate, reliable, and suitable for further analysis or modeling.\n",
    "\n",
    "Data cleaning is important because real-world data is often imperfect. It can contain various issues such as missing values, duplicate records, incorrect formatting, inconsistent spellings, outliers, and more. These problems can arise due to human errors during data entry, technical glitches, or the integration of data from different sources.\n",
    "\n",
    "The primary objectives of data cleaning are as follows:\n",
    "\n",
    "1. **Removing or correcting errors:** Data cleaning involves identifying and addressing errors in the dataset. For example, it may involve fixing typos, resolving inconsistent date formats, or rectifying inaccurate numerical entries.\n",
    "\n",
    "\n",
    "2. **Handling missing data:** Missing data refers to the absence of values in certain records or attributes. Data cleaning techniques help in dealing with missing data, which may involve imputing missing values based on statistical methods or removing records with excessive missing data.\n",
    "\n",
    "\n",
    "3. **Handling duplicates:** Duplicates are identical or near-identical records that exist within a dataset. Data cleaning aims to identify and remove or merge duplicate records, ensuring that each unique entity is represented only once.\n",
    "\n",
    "\n",
    "4. **Standardizing and transforming data:** Inconsistent formatting, units, or scales can hinder data analysis. Data cleaning involves standardizing variables, converting units, and transforming data to ensure consistency and compatibility across the dataset.\n",
    "\n",
    "\n",
    "5. **Handling outliers:** Outliers are extreme values that deviate significantly from the typical pattern of the data. Data cleaning techniques help in identifying and dealing with outliers, which may involve removing them if they are due to data entry errors or handling them separately if they represent important observations.\n",
    "\n",
    "\n",
    "Data cleaning is typically performed using a combination of manual and automated techniques. It requires domain knowledge, data exploration, and the use of various data cleaning tools and algorithms.\n",
    "\n",
    "By performing effective data cleaning, analysts and data scientists can improve the quality of the data and enhance the accuracy and reliability of their subsequent analyses, predictive models, or decision-making processes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d71aabd",
   "metadata": {},
   "source": [
    "## 1.2 Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd534886",
   "metadata": {},
   "source": [
    "### 1.2.1 Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "65920588",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "04150d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'MLcmore2023'...\n",
      "remote: Enumerating objects: 610, done.\u001b[K\n",
      "remote: Counting objects: 100% (191/191), done.\u001b[K\n",
      "remote: Compressing objects: 100% (126/126), done.\u001b[K\n",
      "remote: Total 610 (delta 56), reused 167 (delta 40), pack-reused 419\u001b[K\n",
      "Receiving objects: 100% (610/610), 99.74 MiB | 28.23 MiB/s, done.\n",
      "Resolving deltas: 100% (235/235), done.\n",
      "Updating files: 100% (172/172), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/MLcmore2023/MLcmore2023.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6ee81cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv ./MLcmore2023/'day1_pm_afternoon'/* ./MLcmore2023/'day1_pm_afternoon'/.* ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4b13f60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Load Titanic dataset from seaborn\n",
    "titanic = pd.read_csv('titanic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d5ad72ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>pclass</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>boat</th>\n",
       "      <th>body</th>\n",
       "      <th>home.dest</th>\n",
       "      <th>survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1216</td>\n",
       "      <td>3</td>\n",
       "      <td>Smyth, Miss. Julia</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>335432</td>\n",
       "      <td>7.7333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>699</td>\n",
       "      <td>3</td>\n",
       "      <td>Cacic, Mr. Luka</td>\n",
       "      <td>male</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315089</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Croatia</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1267</td>\n",
       "      <td>3</td>\n",
       "      <td>Van Impe, Mrs. Jean Baptiste (Rosalie Paula Go...</td>\n",
       "      <td>female</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>345773</td>\n",
       "      <td>24.1500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>449</td>\n",
       "      <td>2</td>\n",
       "      <td>Hocking, Mrs. Elizabeth (Eliza Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>54.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>29105</td>\n",
       "      <td>23.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cornwall / Akron, OH</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>576</td>\n",
       "      <td>2</td>\n",
       "      <td>Veal, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28221</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Barre, Co Washington, VT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passenger_id  pclass                                               name  \\\n",
       "0          1216       3                                 Smyth, Miss. Julia   \n",
       "1           699       3                                    Cacic, Mr. Luka   \n",
       "2          1267       3  Van Impe, Mrs. Jean Baptiste (Rosalie Paula Go...   \n",
       "3           449       2              Hocking, Mrs. Elizabeth (Eliza Needs)   \n",
       "4           576       2                                    Veal, Mr. James   \n",
       "\n",
       "      sex   age  sibsp  parch  ticket     fare cabin embarked boat  body  \\\n",
       "0  female   NaN      0      0  335432   7.7333   NaN        Q   13   NaN   \n",
       "1    male  38.0      0      0  315089   8.6625   NaN        S  NaN   NaN   \n",
       "2  female  30.0      1      1  345773  24.1500   NaN        S  NaN   NaN   \n",
       "3  female  54.0      1      3   29105  23.0000   NaN        S    4   NaN   \n",
       "4    male  40.0      0      0   28221  13.0000   NaN        S  NaN   NaN   \n",
       "\n",
       "                  home.dest  survived  \n",
       "0                       NaN         1  \n",
       "1                   Croatia         0  \n",
       "2                       NaN         0  \n",
       "3      Cornwall / Akron, OH         1  \n",
       "4  Barre, Co Washington, VT         0  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display the dataframe\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa5d275",
   "metadata": {},
   "source": [
    "### 1.2.2 Explore the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "922fb5a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 850 entries, 0 to 849\n",
      "Data columns (total 15 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   passenger_id  850 non-null    int64  \n",
      " 1   pclass        850 non-null    int64  \n",
      " 2   name          850 non-null    object \n",
      " 3   sex           850 non-null    object \n",
      " 4   age           676 non-null    float64\n",
      " 5   sibsp         850 non-null    int64  \n",
      " 6   parch         850 non-null    int64  \n",
      " 7   ticket        850 non-null    object \n",
      " 8   fare          849 non-null    float64\n",
      " 9   cabin         191 non-null    object \n",
      " 10  embarked      849 non-null    object \n",
      " 11  boat          308 non-null    object \n",
      " 12  body          73 non-null     float64\n",
      " 13  home.dest     464 non-null    object \n",
      " 14  survived      850 non-null    int64  \n",
      "dtypes: float64(3), int64(5), object(7)\n",
      "memory usage: 99.7+ KB\n"
     ]
    }
   ],
   "source": [
    "titanic.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37aaf9d",
   "metadata": {},
   "source": [
    "The Titanic dataset is a historical dataset that contains information about the passengers aboard the RMS Titanic, which was a British passenger liner that sank on its maiden voyage in April 1912 after colliding with an iceberg. The dataset has been made available for public use and is commonly used as a learning resource for data analysis, data visualization, and machine learning tasks.\n",
    "\n",
    "The dataset provides a glimpse into the demographics and circumstances surrounding the passengers on the Titanic. It is often used to explore the factors that influenced survival rates and to build predictive models to determine the likelihood of a passenger surviving based on various features.\n",
    "\n",
    "The columns (features) in the dataset are as follows:\n",
    "\n",
    "1. PassengerId: An identifier for each passenger.\n",
    "2. Pclass: The ticket class of the passenger (1st, 2nd, or 3rd class).\n",
    "3. Name: The name of the passenger.\n",
    "4. Sex: The gender of the passenger (male or female).\n",
    "5. Age: The age of the passenger in years.\n",
    "6. SibSp: The number of siblings or spouses onboard the Titanic with the passenger.\n",
    "7. Parch: The number of parents or children onboard the Titanic with the passenger.\n",
    "8. Ticket: The ticket number.\n",
    "9. Fare: The passenger's fare or ticket price.\n",
    "10. Cabin: The cabin number of the passenger.\n",
    "11. Embarked: The port of embarkation (C = Cherbourg, Q = Queenstown, S = Southampton).\n",
    "12. Boat: The lifeboat number if the passenger survived and was rescued.\n",
    "13. Body: The body number if the passenger did not survive and their body was recovered.\n",
    "14. Home.dest: The home or destination of the passenger.\n",
    "15. Survived: This is the target variable and indicates whether the passenger survived or not. It is binary with 0 for not survived and 1 for survived.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ccfc576",
   "metadata": {},
   "source": [
    "## 1.2 Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbdc5cd",
   "metadata": {},
   "source": [
    "### 1.2.1 Removing or correcting errors\n",
    "1. **Removing or correcting errors:** Data cleaning involves identifying and addressing errors in the dataset. For example, it may involve fixing typos, resolving inconsistent date formats, or rectifying inaccurate numerical entries.\n",
    "\n",
    "\n",
    "Correcting errors in the \"sex\" column of a dataset\n",
    "\n",
    "df['column_name'] = df['column_name'].str.replace('incorrect_value', 'correct_value')\n",
    "\n",
    "### Example\n",
    "\n",
    "Changing \"errors\" in the \"sex\" column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "19b574f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    female\n",
       "1      male\n",
       "2    female\n",
       "3    female\n",
       "4      male\n",
       "Name: sex, dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.sex[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "182c754c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# male -> M\n",
    "# female -> F\n",
    "df['sex'].replace('male', 'M', inplace=True)\n",
    "df['sex'].replace('female', 'F', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bd6660",
   "metadata": {},
   "source": [
    "the parameter `inplace=True` is used to specify that the replacement operation should be performed directly on the original DataFrame, modifying it in place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a820b013",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    M\n",
       "1    F\n",
       "2    F\n",
       "3    F\n",
       "4    M\n",
       "Name: sex, dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sex[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76359d9c",
   "metadata": {},
   "source": [
    "### 1.2.2 Handling missing data\n",
    "\n",
    "2. **Handling missing data:** Missing data refers to the absence of values in certain records or attributes. Data cleaning techniques help in dealing with missing data, which may involve imputing missing values based on statistical methods or removing records with excessive missing data.\n",
    "\n",
    "The first step is always to check missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "279dd79d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passenger_id      0\n",
      "pclass            0\n",
      "name              0\n",
      "sex               0\n",
      "age             174\n",
      "sibsp             0\n",
      "parch             0\n",
      "ticket            0\n",
      "fare              1\n",
      "cabin           659\n",
      "embarked          1\n",
      "boat            542\n",
      "body            777\n",
      "home.dest       386\n",
      "survived          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(titanic.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd3a33d",
   "metadata": {},
   "source": [
    "To fix missing data in a column, you can use various techniques depending on the nature of the missing values. Here are a few common approaches:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1fcfd2",
   "metadata": {},
   "source": [
    "### 1.2.3 Removing missing values:\n",
    "\n",
    "- If the missing values are relatively few and randomly distributed, you may choose to remove the rows or columns with missing values.\n",
    "- Use the **dropna()** method in pandas to drop rows or columns with missing values. For example: **df.dropna().**\n",
    "\n",
    "### Example\n",
    "drop the row with nan value in “embarked” column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eef01336",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.dropna(subset=['embarked'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a51df697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "survived         0\n",
      "pclass           0\n",
      "sex              0\n",
      "age            177\n",
      "sibsp            0\n",
      "parch            0\n",
      "fare             0\n",
      "embarked         0\n",
      "class            0\n",
      "who              0\n",
      "adult_male       0\n",
      "deck           688\n",
      "embark_town      0\n",
      "alive            0\n",
      "alone            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Now, the row with missing value in embarked column has been dropped\n",
    "print(titanic.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1051b83b",
   "metadata": {},
   "source": [
    "### 1.2.4 Imputing missing values:\n",
    "\n",
    "- If the missing values follow a certain pattern or have a relationship with other variables, you can fill them in with estimated or imputed values.\n",
    "- Use the **fillna()** method in pandas to fill missing values with a specific value, mean, median, or any other desired imputation method. For example: **df['column_name'].fillna(value)**.\n",
    "\n",
    "### Example\n",
    "Filling missing values with median age in \"age\" column:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "20f5c35e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = titanic['age'].median()\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "84350ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic['age'] = titanic['age'].replace(np.nan, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "605affa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "survived         0\n",
      "pclass           0\n",
      "sex              0\n",
      "age              0\n",
      "sibsp            0\n",
      "parch            0\n",
      "fare             0\n",
      "embarked         0\n",
      "class            0\n",
      "who              0\n",
      "adult_male       0\n",
      "deck           688\n",
      "embark_town      0\n",
      "alive            0\n",
      "alone            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(titanic.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78a0dad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
