{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "576fc3a2",
   "metadata": {},
   "source": [
    "# Day 1 - Afternoon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d89bebd",
   "metadata": {},
   "source": [
    "# 1. Data Cleaning and Data Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a023dcbf",
   "metadata": {},
   "source": [
    "## 1.1 Introduction to Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a59673",
   "metadata": {},
   "source": [
    "Data cleaning, also known as data cleansing or data scrubbing, refers to the process of identifying and correcting or removing errors, inconsistencies, and inaccuracies in a dataset. It is an essential step in data preprocessing and analysis to ensure that the data is accurate, reliable, and suitable for further analysis or modeling.\n",
    "\n",
    "Data cleaning is important because real-world data is often imperfect. It can contain various issues such as missing values, duplicate records, incorrect formatting, inconsistent spellings, outliers, and more. These problems can arise due to human errors during data entry, technical glitches, or the integration of data from different sources.\n",
    "\n",
    "The primary objectives of data cleaning are as follows:\n",
    "\n",
    "1. **Removing or correcting errors:** Data cleaning involves identifying and addressing errors in the dataset. For example, it may involve fixing typos, resolving inconsistent date formats, or rectifying inaccurate numerical entries.\n",
    "\n",
    "\n",
    "2. **Handling missing data:** Missing data refers to the absence of values in certain records or attributes. Data cleaning techniques help in dealing with missing data, which may involve imputing missing values based on statistical methods or removing records with excessive missing data.\n",
    "\n",
    "\n",
    "3. **Handling duplicates:** Duplicates are identical or near-identical records that exist within a dataset. Data cleaning aims to identify and remove or merge duplicate records, ensuring that each unique entity is represented only once.\n",
    "\n",
    "\n",
    "4. **Standardizing and transforming data:** Inconsistent formatting, units, or scales can hinder data analysis. Data cleaning involves standardizing variables, converting units, and transforming data to ensure consistency and compatibility across the dataset.\n",
    "\n",
    "\n",
    "5. **Handling outliers:** Outliers are extreme values that deviate significantly from the typical pattern of the data. Data cleaning techniques help in identifying and dealing with outliers, which may involve removing them if they are due to data entry errors or handling them separately if they represent important observations.\n",
    "\n",
    "\n",
    "Data cleaning is typically performed using a combination of manual and automated techniques. It requires domain knowledge, data exploration, and the use of various data cleaning tools and algorithms.\n",
    "\n",
    "By performing effective data cleaning, analysts and data scientists can improve the quality of the data and enhance the accuracy and reliability of their subsequent analyses, predictive models, or decision-making processes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d71aabd",
   "metadata": {},
   "source": [
    "## 1.2 Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd534886",
   "metadata": {},
   "source": [
    "### 1.2.1 Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "18acf9c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: category_encoders in /Users/brucehaoyuli/opt/anaconda3/lib/python3.9/site-packages (2.6.1)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /Users/brucehaoyuli/opt/anaconda3/lib/python3.9/site-packages (from category_encoders) (1.22.4)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /Users/brucehaoyuli/opt/anaconda3/lib/python3.9/site-packages (from category_encoders) (1.0.2)\n",
      "Requirement already satisfied: pandas>=1.0.5 in /Users/brucehaoyuli/opt/anaconda3/lib/python3.9/site-packages (from category_encoders) (1.4.2)\n",
      "Requirement already satisfied: statsmodels>=0.9.0 in /Users/brucehaoyuli/opt/anaconda3/lib/python3.9/site-packages (from category_encoders) (0.13.2)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /Users/brucehaoyuli/opt/anaconda3/lib/python3.9/site-packages (from category_encoders) (1.7.3)\n",
      "Requirement already satisfied: patsy>=0.5.1 in /Users/brucehaoyuli/opt/anaconda3/lib/python3.9/site-packages (from category_encoders) (0.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/brucehaoyuli/opt/anaconda3/lib/python3.9/site-packages (from pandas>=1.0.5->category_encoders) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/brucehaoyuli/opt/anaconda3/lib/python3.9/site-packages (from pandas>=1.0.5->category_encoders) (2021.3)\n",
      "Requirement already satisfied: six in /Users/brucehaoyuli/opt/anaconda3/lib/python3.9/site-packages (from patsy>=0.5.1->category_encoders) (1.16.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/brucehaoyuli/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn>=0.20.0->category_encoders) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/brucehaoyuli/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn>=0.20.0->category_encoders) (2.2.0)\n",
      "Requirement already satisfied: packaging>=21.3 in /Users/brucehaoyuli/opt/anaconda3/lib/python3.9/site-packages (from statsmodels>=0.9.0->category_encoders) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/brucehaoyuli/opt/anaconda3/lib/python3.9/site-packages (from packaging>=21.3->statsmodels>=0.9.0->category_encoders) (3.0.4)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install category_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "65920588",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "04150d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'MLcmore2023' already exists and is not an empty directory.\r\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/MLcmore2023/MLcmore2023.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6ee81cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: no matches found: ./MLcmore2023/day1_pm_afternoon/*\r\n"
     ]
    }
   ],
   "source": [
    "!mv ./MLcmore2023/'day1_pm_afternoon'/* ./MLcmore2023/'day1_pm_afternoon'/.* ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4b13f60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Load Titanic dataset from seaborn\n",
    "titanic = pd.read_csv('titanic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d5ad72ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>pclass</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>boat</th>\n",
       "      <th>body</th>\n",
       "      <th>home.dest</th>\n",
       "      <th>survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1216</td>\n",
       "      <td>3</td>\n",
       "      <td>Smyth, Miss. Julia</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>335432</td>\n",
       "      <td>7.7333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>699</td>\n",
       "      <td>3</td>\n",
       "      <td>Cacic, Mr. Luka</td>\n",
       "      <td>male</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315089</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Croatia</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1267</td>\n",
       "      <td>3</td>\n",
       "      <td>Van Impe, Mrs. Jean Baptiste (Rosalie Paula Go...</td>\n",
       "      <td>female</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>345773</td>\n",
       "      <td>24.1500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>449</td>\n",
       "      <td>2</td>\n",
       "      <td>Hocking, Mrs. Elizabeth (Eliza Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>54.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>29105</td>\n",
       "      <td>23.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cornwall / Akron, OH</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>576</td>\n",
       "      <td>2</td>\n",
       "      <td>Veal, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28221</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Barre, Co Washington, VT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passenger_id  pclass                                               name  \\\n",
       "0          1216       3                                 Smyth, Miss. Julia   \n",
       "1           699       3                                    Cacic, Mr. Luka   \n",
       "2          1267       3  Van Impe, Mrs. Jean Baptiste (Rosalie Paula Go...   \n",
       "3           449       2              Hocking, Mrs. Elizabeth (Eliza Needs)   \n",
       "4           576       2                                    Veal, Mr. James   \n",
       "\n",
       "      sex   age  sibsp  parch  ticket     fare cabin embarked boat  body  \\\n",
       "0  female   NaN      0      0  335432   7.7333   NaN        Q   13   NaN   \n",
       "1    male  38.0      0      0  315089   8.6625   NaN        S  NaN   NaN   \n",
       "2  female  30.0      1      1  345773  24.1500   NaN        S  NaN   NaN   \n",
       "3  female  54.0      1      3   29105  23.0000   NaN        S    4   NaN   \n",
       "4    male  40.0      0      0   28221  13.0000   NaN        S  NaN   NaN   \n",
       "\n",
       "                  home.dest  survived  \n",
       "0                       NaN         1  \n",
       "1                   Croatia         0  \n",
       "2                       NaN         0  \n",
       "3      Cornwall / Akron, OH         1  \n",
       "4  Barre, Co Washington, VT         0  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display the dataframe\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa5d275",
   "metadata": {},
   "source": [
    "### 1.2.2 Explore the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "922fb5a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 850 entries, 0 to 849\n",
      "Data columns (total 15 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   passenger_id  850 non-null    int64  \n",
      " 1   pclass        850 non-null    int64  \n",
      " 2   name          850 non-null    object \n",
      " 3   sex           850 non-null    object \n",
      " 4   age           676 non-null    float64\n",
      " 5   sibsp         850 non-null    int64  \n",
      " 6   parch         850 non-null    int64  \n",
      " 7   ticket        850 non-null    object \n",
      " 8   fare          849 non-null    float64\n",
      " 9   cabin         191 non-null    object \n",
      " 10  embarked      849 non-null    object \n",
      " 11  boat          308 non-null    object \n",
      " 12  body          73 non-null     float64\n",
      " 13  home.dest     464 non-null    object \n",
      " 14  survived      850 non-null    int64  \n",
      "dtypes: float64(3), int64(5), object(7)\n",
      "memory usage: 99.7+ KB\n"
     ]
    }
   ],
   "source": [
    "titanic.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37aaf9d",
   "metadata": {},
   "source": [
    "The Titanic dataset is a historical dataset that contains information about the passengers aboard the RMS Titanic, which was a British passenger liner that sank on its maiden voyage in April 1912 after colliding with an iceberg. The dataset has been made available for public use and is commonly used as a learning resource for data analysis, data visualization, and machine learning tasks.\n",
    "\n",
    "The dataset provides a glimpse into the demographics and circumstances surrounding the passengers on the Titanic. It is often used to explore the factors that influenced survival rates and to build predictive models to determine the likelihood of a passenger surviving based on various features.\n",
    "\n",
    "The columns (features) in the dataset are as follows:\n",
    "\n",
    "1. PassengerId: An identifier for each passenger.\n",
    "2. Pclass: The ticket class of the passenger (1st, 2nd, or 3rd class).\n",
    "3. Name: The name of the passenger.\n",
    "4. Sex: The gender of the passenger (male or female).\n",
    "5. Age: The age of the passenger in years.\n",
    "6. SibSp: The number of siblings or spouses onboard the Titanic with the passenger.\n",
    "7. Parch: The number of parents or children onboard the Titanic with the passenger.\n",
    "8. Ticket: The ticket number.\n",
    "9. Fare: The passenger's fare or ticket price.\n",
    "10. Cabin: The cabin number of the passenger.\n",
    "11. Embarked: The port of embarkation (C = Cherbourg, Q = Queenstown, S = Southampton).\n",
    "12. Boat: The lifeboat number if the passenger survived and was rescued.\n",
    "13. Body: The body number if the passenger did not survive and their body was recovered.\n",
    "14. Home.dest: The home or destination of the passenger.\n",
    "15. Survived: This is the target variable and indicates whether the passenger survived or not. It is binary with 0 for not survived and 1 for survived.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ccfc576",
   "metadata": {},
   "source": [
    "## 1.2 Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbdc5cd",
   "metadata": {},
   "source": [
    "### 1.2.1 Removing or correcting errors\n",
    "1. **Removing or correcting errors:** Data cleaning involves identifying and addressing errors in the dataset. For example, it may involve fixing typos, resolving inconsistent date formats, or rectifying inaccurate numerical entries.\n",
    "\n",
    "\n",
    "Correcting errors in the \"sex\" column of a dataset\n",
    "\n",
    "df['column_name'] = df['column_name'].str.replace('incorrect_value', 'correct_value')\n",
    "\n",
    "### Example\n",
    "\n",
    "Changing \"errors\" in the \"sex\" column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "19b574f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    female\n",
       "1      male\n",
       "2    female\n",
       "3    female\n",
       "4      male\n",
       "Name: sex, dtype: object"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.sex[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "182c754c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# male -> M\n",
    "# female -> F\n",
    "titanic['sex'].replace('male', 'M', inplace=True)\n",
    "titanic['sex'].replace('female', 'F', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bd6660",
   "metadata": {},
   "source": [
    "the parameter `inplace=True` is used to specify that the replacement operation should be performed directly on the original DataFrame, modifying it in place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a820b013",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    F\n",
       "1    M\n",
       "2    F\n",
       "3    F\n",
       "4    M\n",
       "Name: sex, dtype: object"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.sex[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76359d9c",
   "metadata": {},
   "source": [
    "### 1.2.2 Handling missing data\n",
    "\n",
    "2. **Handling missing data:** Missing data refers to the absence of values in certain records or attributes. Data cleaning techniques help in dealing with missing data, which may involve imputing missing values based on statistical methods or removing records with excessive missing data.\n",
    "\n",
    "The first step is always to check missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "279dd79d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passenger_id      0\n",
      "pclass            0\n",
      "name              0\n",
      "sex               0\n",
      "age             174\n",
      "sibsp             0\n",
      "parch             0\n",
      "ticket            0\n",
      "fare              1\n",
      "cabin           659\n",
      "embarked          1\n",
      "boat            542\n",
      "body            777\n",
      "home.dest       386\n",
      "survived          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(titanic.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd3a33d",
   "metadata": {},
   "source": [
    "To fix missing data in a column, you can use various techniques depending on the nature of the missing values. Here are a few common approaches:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1fcfd2",
   "metadata": {},
   "source": [
    "### 1.2.3 Removing missing values:\n",
    "\n",
    "- If the missing values are relatively few and randomly distributed, you may choose to remove the rows or columns with missing values.\n",
    "- Use the **dropna()** method in pandas to drop rows or columns with missing values. For example: **df.dropna().**\n",
    "\n",
    "### Example\n",
    "drop the row with nan value in “embarked” column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "eef01336",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.dropna(subset=['embarked'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a51df697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passenger_id      0\n",
      "pclass            0\n",
      "name              0\n",
      "sex               0\n",
      "age             174\n",
      "sibsp             0\n",
      "parch             0\n",
      "ticket            0\n",
      "fare              1\n",
      "cabin           659\n",
      "embarked          0\n",
      "boat            542\n",
      "body            776\n",
      "home.dest       385\n",
      "survived          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Now, the row with missing value in embarked column has been dropped\n",
    "print(titanic.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1051b83b",
   "metadata": {},
   "source": [
    "### 1.2.4 Imputing missing values:\n",
    "\n",
    "- If the missing values follow a certain pattern or have a relationship with other variables, you can fill them in with estimated or imputed values.\n",
    "- Use the **fillna()** method in pandas to fill missing values with a specific value, mean, median, or any other desired imputation method. For example: **df['column_name'].fillna(value)**.\n",
    "\n",
    "### Example\n",
    "Filling missing values with median age in \"age\" column:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "20f5c35e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.0"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = titanic['age'].median()\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "84350ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic['age'] = titanic['age'].replace(np.nan, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "605affa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passenger_id      0\n",
      "pclass            0\n",
      "name              0\n",
      "sex               0\n",
      "age               0\n",
      "sibsp             0\n",
      "parch             0\n",
      "ticket            0\n",
      "fare              1\n",
      "cabin           659\n",
      "embarked          0\n",
      "boat            542\n",
      "body            776\n",
      "home.dest       385\n",
      "survived          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(titanic.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba02e71",
   "metadata": {},
   "source": [
    "### 1.2.5 Handling duplicates:\n",
    "3. **Handling duplicates:** Duplicates are identical or near-identical records that exist within a dataset. Data cleaning aims to identify and remove or merge duplicate records, ensuring that each unique entity is represented only once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a2c068cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the original dataset does not contain any duplicates,\n",
    "# for educational purposes, I manually added some duplicates.\n",
    "\n",
    "# Select the row(s) to duplicate\n",
    "row_to_duplicate = titanic.loc[0]\n",
    "\n",
    "# Append the row(s) to create duplicates\n",
    "titanic = titanic.append([row_to_duplicate, row_to_duplicate], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6265ced",
   "metadata": {},
   "source": [
    "ignore_index=True ensures that the resulting DataFrame has a new sequential index starting from 0, regardless of the original index values in the appended rows.\n",
    "\n",
    "#### Example\n",
    "Remove the deplicated which I created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d2c83b4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>pclass</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>boat</th>\n",
       "      <th>body</th>\n",
       "      <th>home.dest</th>\n",
       "      <th>survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>849</th>\n",
       "      <td>1216</td>\n",
       "      <td>3</td>\n",
       "      <td>Smyth, Miss. Julia</td>\n",
       "      <td>F</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>335432</td>\n",
       "      <td>7.7333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850</th>\n",
       "      <td>1216</td>\n",
       "      <td>3</td>\n",
       "      <td>Smyth, Miss. Julia</td>\n",
       "      <td>F</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>335432</td>\n",
       "      <td>7.7333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     passenger_id  pclass                name sex   age  sibsp  parch  ticket  \\\n",
       "849          1216       3  Smyth, Miss. Julia   F  28.0      0      0  335432   \n",
       "850          1216       3  Smyth, Miss. Julia   F  28.0      0      0  335432   \n",
       "\n",
       "       fare cabin embarked boat  body home.dest  survived  \n",
       "849  7.7333   NaN        Q   13   NaN       NaN         1  \n",
       "850  7.7333   NaN        Q   13   NaN       NaN         1  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find duplicates in the DataFrame\n",
    "duplicates = titanic.duplicated()\n",
    "duplicate_rows = titanic[duplicates]\n",
    "duplicate_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "334becba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all the duplicates\n",
    "titanic.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d98374b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>pclass</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>boat</th>\n",
       "      <th>body</th>\n",
       "      <th>home.dest</th>\n",
       "      <th>survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [passenger_id, pclass, name, sex, age, sibsp, parch, ticket, fare, cabin, embarked, boat, body, home.dest, survived]\n",
       "Index: []"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now, the duplicates are gone\n",
    "duplicates = titanic.duplicated()\n",
    "duplicate_rows = titanic[duplicates]\n",
    "duplicate_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7cb40dd",
   "metadata": {},
   "source": [
    "### 1.2.6 Standardization & Normalization:\n",
    "\n",
    "**Standardization** scales the data to have a mean of 0 and a standard deviation of 1. It is performed using the formula:\n",
    "\n",
    "z= x−μ/σ\n",
    "\n",
    "where:\n",
    "\n",
    "- z is the standardized value,\n",
    "- x is the original value,\n",
    "- μ is the mean of the feature,\n",
    "- σ is the standard deviation of the feature.\n",
    " \n",
    "**Normalization** scales the data to a range between 0 and 1. It is performed using the formula:\n",
    "\n",
    "x_normalized = (x- x_max)/(x_max - x_min)\n",
    "\n",
    "where:\n",
    "\n",
    "- x_normalized is the normalized value,\n",
    "- x is the original value,\n",
    "- x_min is the minimum value of the feature\n",
    "- x_max is the maximum value of the feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f8bd3ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# Assume 'data' is your DataFrame containing the Titanic dataset\n",
    "# Replace 'data' with the actual DataFrame name in your code\n",
    "\n",
    "# Standardization\n",
    "age_values = titanic['age'].values.reshape(-1, 1)\n",
    "scaler = StandardScaler()\n",
    "age_standardized = scaler.fit_transform(age_values)\n",
    "\n",
    "# Create a new DataFrame with the standardized 'Age' column\n",
    "data_standardized = titanic.copy()\n",
    "data_standardized['age_standardized'] = age_standardized\n",
    "\n",
    "# Normalization\n",
    "scaler = MinMaxScaler()\n",
    "age_normalized = scaler.fit_transform(age_values)\n",
    "\n",
    "# Create a new DataFrame with the normalized 'Age' column\n",
    "data_normalized = titanic.copy()\n",
    "data_normalized['age_normalized'] = age_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "10abf0da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>pclass</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>boat</th>\n",
       "      <th>body</th>\n",
       "      <th>home.dest</th>\n",
       "      <th>survived</th>\n",
       "      <th>age_standardized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1216</td>\n",
       "      <td>3</td>\n",
       "      <td>Smyth, Miss. Julia</td>\n",
       "      <td>F</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>335432</td>\n",
       "      <td>7.7333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.092214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>699</td>\n",
       "      <td>3</td>\n",
       "      <td>Cacic, Mr. Luka</td>\n",
       "      <td>M</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315089</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Croatia</td>\n",
       "      <td>0</td>\n",
       "      <td>0.677282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1267</td>\n",
       "      <td>3</td>\n",
       "      <td>Van Impe, Mrs. Jean Baptiste (Rosalie Paula Go...</td>\n",
       "      <td>F</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>345773</td>\n",
       "      <td>24.1500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.061685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>449</td>\n",
       "      <td>2</td>\n",
       "      <td>Hocking, Mrs. Elizabeth (Eliza Needs)</td>\n",
       "      <td>F</td>\n",
       "      <td>54.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>29105</td>\n",
       "      <td>23.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cornwall / Akron, OH</td>\n",
       "      <td>1</td>\n",
       "      <td>1.908476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>576</td>\n",
       "      <td>2</td>\n",
       "      <td>Veal, Mr. James</td>\n",
       "      <td>M</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28221</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Barre, Co Washington, VT</td>\n",
       "      <td>0</td>\n",
       "      <td>0.831181</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passenger_id  pclass                                               name  \\\n",
       "0          1216       3                                 Smyth, Miss. Julia   \n",
       "1           699       3                                    Cacic, Mr. Luka   \n",
       "2          1267       3  Van Impe, Mrs. Jean Baptiste (Rosalie Paula Go...   \n",
       "3           449       2              Hocking, Mrs. Elizabeth (Eliza Needs)   \n",
       "4           576       2                                    Veal, Mr. James   \n",
       "\n",
       "  sex   age  sibsp  parch  ticket     fare cabin embarked boat  body  \\\n",
       "0   F  28.0      0      0  335432   7.7333   NaN        Q   13   NaN   \n",
       "1   M  38.0      0      0  315089   8.6625   NaN        S  NaN   NaN   \n",
       "2   F  30.0      1      1  345773  24.1500   NaN        S  NaN   NaN   \n",
       "3   F  54.0      1      3   29105  23.0000   NaN        S    4   NaN   \n",
       "4   M  40.0      0      0   28221  13.0000   NaN        S  NaN   NaN   \n",
       "\n",
       "                  home.dest  survived  age_standardized  \n",
       "0                       NaN         1         -0.092214  \n",
       "1                   Croatia         0          0.677282  \n",
       "2                       NaN         0          0.061685  \n",
       "3      Cornwall / Akron, OH         1          1.908476  \n",
       "4  Barre, Co Washington, VT         0          0.831181  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first few rows of the standardized and normalized DataFrames\n",
    "data_standardized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "27b37400",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>pclass</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>boat</th>\n",
       "      <th>body</th>\n",
       "      <th>home.dest</th>\n",
       "      <th>survived</th>\n",
       "      <th>age_normalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1216</td>\n",
       "      <td>3</td>\n",
       "      <td>Smyth, Miss. Julia</td>\n",
       "      <td>F</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>335432</td>\n",
       "      <td>7.7333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.348643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>699</td>\n",
       "      <td>3</td>\n",
       "      <td>Cacic, Mr. Luka</td>\n",
       "      <td>M</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315089</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Croatia</td>\n",
       "      <td>0</td>\n",
       "      <td>0.473904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1267</td>\n",
       "      <td>3</td>\n",
       "      <td>Van Impe, Mrs. Jean Baptiste (Rosalie Paula Go...</td>\n",
       "      <td>F</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>345773</td>\n",
       "      <td>24.1500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.373695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>449</td>\n",
       "      <td>2</td>\n",
       "      <td>Hocking, Mrs. Elizabeth (Eliza Needs)</td>\n",
       "      <td>F</td>\n",
       "      <td>54.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>29105</td>\n",
       "      <td>23.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cornwall / Akron, OH</td>\n",
       "      <td>1</td>\n",
       "      <td>0.674321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>576</td>\n",
       "      <td>2</td>\n",
       "      <td>Veal, Mr. James</td>\n",
       "      <td>M</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28221</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Barre, Co Washington, VT</td>\n",
       "      <td>0</td>\n",
       "      <td>0.498956</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passenger_id  pclass                                               name  \\\n",
       "0          1216       3                                 Smyth, Miss. Julia   \n",
       "1           699       3                                    Cacic, Mr. Luka   \n",
       "2          1267       3  Van Impe, Mrs. Jean Baptiste (Rosalie Paula Go...   \n",
       "3           449       2              Hocking, Mrs. Elizabeth (Eliza Needs)   \n",
       "4           576       2                                    Veal, Mr. James   \n",
       "\n",
       "  sex   age  sibsp  parch  ticket     fare cabin embarked boat  body  \\\n",
       "0   F  28.0      0      0  335432   7.7333   NaN        Q   13   NaN   \n",
       "1   M  38.0      0      0  315089   8.6625   NaN        S  NaN   NaN   \n",
       "2   F  30.0      1      1  345773  24.1500   NaN        S  NaN   NaN   \n",
       "3   F  54.0      1      3   29105  23.0000   NaN        S    4   NaN   \n",
       "4   M  40.0      0      0   28221  13.0000   NaN        S  NaN   NaN   \n",
       "\n",
       "                  home.dest  survived  age_normalized  \n",
       "0                       NaN         1        0.348643  \n",
       "1                   Croatia         0        0.473904  \n",
       "2                       NaN         0        0.373695  \n",
       "3      Cornwall / Akron, OH         1        0.674321  \n",
       "4  Barre, Co Washington, VT         0        0.498956  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_normalized.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5558f0",
   "metadata": {},
   "source": [
    "**Why do we use standardization and normalization?**\n",
    "\n",
    "1. **Improving Model Performance:** Many machine learning algorithms work better or converge faster when the input features have a similar scale. Features with significantly different scales can dominate the learning process, leading to suboptimal performance.\n",
    "\n",
    "2. **Interpretability and Comparisons:** Standardizing or normalizing the data ensures that all the features are in comparable units, making it easier to interpret the importance and effect of different features. It also allows for more meaningful comparisons between different features.\n",
    "\n",
    "3. **Regularization:** Some regularization techniques, like L1 and L2 regularization, penalize large values in the input features. Standardization and normalization can prevent certain features from being disproportionately penalized during model training.\n",
    "\n",
    "4. **Distance-Based Algorithms:** When using distance-based algorithms, such as k-nearest neighbors (KNN) or clustering algorithms, it is crucial to scale the features appropriately to ensure that distances are not dominated by a single feature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee3be0c",
   "metadata": {},
   "source": [
    "### 1.2.7 Handling Outliers\n",
    "\n",
    "5. **Handling outliers:** Outliers are extreme values that deviate significantly from the typical pattern of the data. Data cleaning techniques help in identifying and dealing with outliers, which may involve removing them if they are due to data entry errors or handling them separately if they represent important observations.\n",
    "\n",
    "### Example\n",
    "\n",
    "There is one outlier with person that survived with an overwhelming fare that is around 500.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "205b7d4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "data = pd.concat([titanic['survived'], titanic['fare']], axis=1)\n",
    "f, ax = plt.subplots(figsize=(16, 8))\n",
    "fig = sns.boxplot(x=titanic['survived'], y=titanic['fare'], data=data)\n",
    "plt.xticks(rotation=90);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02041a79",
   "metadata": {},
   "source": [
    "`data = pd.concat([df['survived'], df['fare']], axis=1)`: This line creates a new DataFrame called data by concatenating two columns from an existing DataFrame df. It selects the 'survived' and 'fare' columns and combines them horizontally (axis=1) to form the new DataFrame.\n",
    "\n",
    "`f, ax = plt.subplots(figsize=(16, 8))`: This line creates a figure (f) and an axis (ax) using plt.subplots(). The figsize parameter sets the size of the figure in inches, specifying a width of 16 and a height of 8.\n",
    "\n",
    "`fig = sns.boxplot(x=df['survived'], y=df['fare'], data=data)`: This line creates a box plot using Seaborn's boxplot function. The 'survived' column values are assigned to the x-axis (x=df['survived']), and the 'fare' column values are assigned to the y-axis (y=df['fare']). The data parameter specifies the DataFrame from which the values should be retrieved.\n",
    "\n",
    "`plt.xticks(rotation=90)`: This line rotates the x-axis tick labels by 90 degrees to prevent overlap when the labels are long. It improves the readability of the plot by ensuring that the x-axis labels are displayed vertically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "785eb56e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>pclass</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>boat</th>\n",
       "      <th>body</th>\n",
       "      <th>home.dest</th>\n",
       "      <th>survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>Cardeza, Mrs. James Warburton Martinez (Charlo...</td>\n",
       "      <td>F</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>PC 17755</td>\n",
       "      <td>512.3292</td>\n",
       "      <td>B51 B53 B55</td>\n",
       "      <td>C</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Germantown, Philadelphia, PA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>183</td>\n",
       "      <td>1</td>\n",
       "      <td>Lesurer, Mr. Gustave J</td>\n",
       "      <td>M</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17755</td>\n",
       "      <td>512.3292</td>\n",
       "      <td>B101</td>\n",
       "      <td>C</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>Cardeza, Mr. Thomas Drake Martinez</td>\n",
       "      <td>M</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>PC 17755</td>\n",
       "      <td>512.3292</td>\n",
       "      <td>B51 B53 B55</td>\n",
       "      <td>C</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Austria-Hungary / Germantown, Philadelphia, PA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     passenger_id  pclass                                               name  \\\n",
       "60             50       1  Cardeza, Mrs. James Warburton Martinez (Charlo...   \n",
       "789           183       1                             Lesurer, Mr. Gustave J   \n",
       "795            49       1                 Cardeza, Mr. Thomas Drake Martinez   \n",
       "\n",
       "    sex   age  sibsp  parch    ticket      fare        cabin embarked boat  \\\n",
       "60    F  58.0      0      1  PC 17755  512.3292  B51 B53 B55        C    3   \n",
       "789   M  35.0      0      0  PC 17755  512.3292         B101        C    3   \n",
       "795   M  36.0      0      1  PC 17755  512.3292  B51 B53 B55        C    3   \n",
       "\n",
       "     body                                       home.dest  survived  \n",
       "60    NaN                    Germantown, Philadelphia, PA         1  \n",
       "789   NaN                                             NaN         1  \n",
       "795   NaN  Austria-Hungary / Germantown, Philadelphia, PA         1  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic[titanic['fare'] > 500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6042d082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix the outlier\n",
    "titanic[\"fare\"].replace({ 512.3292 : 7.25}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c75b29d",
   "metadata": {},
   "source": [
    "### 1.2.8 Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "96b43c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passenger_id      0\n",
      "pclass            0\n",
      "name              0\n",
      "sex               0\n",
      "age               0\n",
      "sibsp             0\n",
      "parch             0\n",
      "ticket            0\n",
      "fare              1\n",
      "cabin           659\n",
      "embarked          0\n",
      "boat            542\n",
      "body            776\n",
      "home.dest       385\n",
      "survived          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(titanic.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5254e1d",
   "metadata": {},
   "source": [
    "As you continue exploring the fascinating Titanic dataset, you might have noticed that there are still some missing values in certain columns. You may choose two of them to do the data cleaning. Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8eef3474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdeb6dc",
   "metadata": {},
   "source": [
    "## 1.2 Encoding Categorical Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a77b376",
   "metadata": {},
   "source": [
    "Encoding categorical data involves converting categorical variables into numerical representations to be used in machine learning or statistical models. This process assigns numerical values to categories, allowing the data to be processed effectively by algorithms that work with numerical inputs. Common encoding techniques include one-hot encoding, label encoding, ordinal encoding, target encoding, binary encoding, frequency encoding, and hash encoding. By encoding categorical data, we enable the incorporation of these variables into models and leverage the information they provide for analysis and predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d0ca73",
   "metadata": {},
   "source": [
    "There are several ways to encode categorical data, depending on the specific requirements and characteristics of the data. Here are some common methods for categorical data encoding:\n",
    "\n",
    "One-Hot Encoding (Dummy Coding):\n",
    "\n",
    "1. This method creates binary columns for each category in the original variable. Each category is represented by a separate column, where a value of 1 indicates the presence of that category, and 0 indicates its absence. This approach is suitable when the categories are not ordinal.\n",
    "Example: Using **pd.get_dummies()** function in pandas or **OneHotEncoder** class in scikit-learn.\n",
    "Label Encoding:\n",
    "\n",
    "2. Label encoding assigns a unique numerical label to each category in the variable. Each category is replaced with an integer value. This method is useful for ordinal categorical variables where the order matters.\n",
    "Example: Using **LabelEncoder** class in scikit-learn.\n",
    "Ordinal Encoding:\n",
    "\n",
    "3. Ordinal encoding maps the categories to ordered numerical values based on a predefined order or mapping. It assigns integers to categories based on their relative order or specified mapping. This encoding is suitable for ordinal categorical variables.\n",
    "Example: Using a mapping dictionary or the OrdinalEncoder class in scikit-learn.\n",
    "Binary Encoding:\n",
    "\n",
    "4. Binary encoding represents each category with binary digits. It converts the categories into binary representations and uses a combination of 0s and 1s to encode the variables. This approach is suitable for variables with a large number of categories.\n",
    "Example: Using libraries like category_encoders or feature-engine.\n",
    "Frequency Encoding:\n",
    "\n",
    "5. Frequency encoding replaces each category with its frequency or proportion in the dataset. It assigns a numerical value based on the occurrence frequency of each category. This approach is useful when the frequency of categories is informative.\n",
    "Example: Manually calculating frequencies or using libraries like category_encoders.\n",
    "Hash Encoding:\n",
    "\n",
    "These are some common methods for encoding categorical data. The choice of encoding technique depends on the specific characteristics of the data, the nature of the categories, and the requirements of the analysis or modeling task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cda1a23",
   "metadata": {},
   "source": [
    "### 1.2.1 One-Hot Encoding (Dummy Coding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ebb227",
   "metadata": {},
   "source": [
    "One-hot encoding converts categorical variables into binary columns representing each unique category, enabling machine learning algorithms to process categorical data as numerical input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e1c2c087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with the \"color\" column\n",
    "df = pd.DataFrame({'color': ['red', 'green', 'blue', 'red']})\n",
    "\n",
    "# Apply one-hot encoding\n",
    "one_hot_encoded = pd.get_dummies(df['color'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "1fba4cd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>blue</th>\n",
       "      <th>green</th>\n",
       "      <th>red</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   blue  green  red\n",
       "0     0      0    1\n",
       "1     0      1    0\n",
       "2     1      0    0\n",
       "3     0      0    1"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f4ec9c",
   "metadata": {},
   "source": [
    "The resulting **one_hot_encoded** DataFrame will have three binary columns: \"color_red,\" \"color_green,\" and \"color_blue,\" where 1 indicates the presence of that color and 0 indicates its absence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b81390f",
   "metadata": {},
   "source": [
    "### 1.2.2 Label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9670fe14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with the \"color\" column\n",
    "label_df = pd.DataFrame({'color': ['red', 'green', 'blue', 'red']})\n",
    "\n",
    "# Apply label encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "label_df['color_encoded'] = label_encoder.fit_transform(df['color'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "37da5a18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color</th>\n",
       "      <th>color_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>red</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>green</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blue</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>red</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   color  color_encoded\n",
       "0    red              2\n",
       "1  green              1\n",
       "2   blue              0\n",
       "3    red              2"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9851de2",
   "metadata": {},
   "source": [
    "The resulting DataFrame will have an additional column named \"color_encoded\" that contains the encoded numerical values for each category: 2 for \"red,\" 1 for \"green,\" and 0 for \"blue.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5078079b",
   "metadata": {},
   "source": [
    "### 1.2.3 Ordinal encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "1964fa63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Size</th>\n",
       "      <th>Size_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Small</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Medium</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Large</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Small</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Large</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Size  Size_encoded\n",
       "0   Small             0\n",
       "1  Medium             1\n",
       "2   Large             2\n",
       "3   Small             0\n",
       "4   Large             2"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame with the categorical variable\n",
    "ordinal_df = pd.DataFrame({'Size': ['Small', 'Medium', 'Large', 'Small', 'Large']})\n",
    "\n",
    "# Define the order of the categories\n",
    "category_order = ['Small', 'Medium', 'Large']\n",
    "\n",
    "# Perform ordinal encoding\n",
    "ordinal_df['Size_encoded'] = ordinal_df['Size'].map(lambda x: category_order.index(x))\n",
    "\n",
    "# Print the encoded DataFrame\n",
    "ordinal_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b119c6",
   "metadata": {},
   "source": [
    "The map() function in combination with the lambda function allows us to apply the ordinal encoding logic to each value in the 'Size' column and obtain the corresponding encoded values. These encoded values are then assigned to the 'Size_encoded' column in the DataFrame.\n",
    "\n",
    "Consider a categorical variable \"Size\" with categories \"Small,\" \"Medium,\" and \"Large.\" After ordinal encoding, \"Small\" might be represented as 0, \"Medium\" as 1, and \"Large\" as 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2999b6e7",
   "metadata": {},
   "source": [
    "### 1.2.4 Binary encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "5b20e385",
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as ce\n",
    "\n",
    "# Create a DataFrame with the \"color\" column\n",
    "df = pd.DataFrame({'color': ['red', 'green', 'blue', 'red']})\n",
    "\n",
    "# Apply binary encoding\n",
    "binary_encoder = ce.BinaryEncoder(cols=['color'])\n",
    "binary_df = binary_encoder.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d16d21bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color_0</th>\n",
       "      <th>color_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   color_0  color_1\n",
       "0        0        1\n",
       "1        1        0\n",
       "2        1        1\n",
       "3        0        1"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3bc333a",
   "metadata": {},
   "source": [
    "The resulting **df_encoded** DataFrame will have binary-encoded columns for the \"color\" variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d274689",
   "metadata": {},
   "source": [
    "### 1.2.5 Frequency encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ae46a55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with the \"color\" column\n",
    "df = pd.DataFrame({'color': ['red', 'green', 'blue', 'red']})\n",
    "\n",
    "# Calculate the frequency of each category\n",
    "frequency = df['color'].value_counts(normalize=True)\n",
    "\n",
    "# Apply frequency encoding\n",
    "df['color_encoded'] = df['color'].map(frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d4d27d80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color</th>\n",
       "      <th>color_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>red</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>green</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blue</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>red</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   color  color_encoded\n",
       "0    red           0.50\n",
       "1  green           0.25\n",
       "2   blue           0.25\n",
       "3    red           0.50"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f52357",
   "metadata": {},
   "source": [
    "The resulting DataFrame will have an additional column named \"color_encoded\" that contains the frequency (proportion) of each category.\n",
    "\n",
    "These examples demonstrate how each encoding method can be applied to a categorical variable. It's important to adapt the code to your specific dataset and encoding requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841ad88b",
   "metadata": {},
   "source": [
    "### 1.2.6 Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "8e7996da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 849 entries, 0 to 848\n",
      "Data columns (total 15 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   passenger_id  849 non-null    int64  \n",
      " 1   pclass        849 non-null    int64  \n",
      " 2   name          849 non-null    object \n",
      " 3   sex           849 non-null    object \n",
      " 4   age           849 non-null    float64\n",
      " 5   sibsp         849 non-null    int64  \n",
      " 6   parch         849 non-null    int64  \n",
      " 7   ticket        849 non-null    object \n",
      " 8   fare          848 non-null    float64\n",
      " 9   cabin         190 non-null    object \n",
      " 10  embarked      849 non-null    object \n",
      " 11  boat          307 non-null    object \n",
      " 12  body          73 non-null     float64\n",
      " 13  home.dest     464 non-null    object \n",
      " 14  survived      849 non-null    int64  \n",
      "dtypes: float64(3), int64(5), object(7)\n",
      "memory usage: 106.1+ KB\n"
     ]
    }
   ],
   "source": [
    "titanic.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade13558",
   "metadata": {},
   "source": [
    "We still have some features that require encoding. Let's pick two of these features and apply the appropriate encoding techniques to convert them into numerical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3676fe3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c27c0bc",
   "metadata": {},
   "source": [
    "# 2. Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d50d968",
   "metadata": {},
   "source": [
    "## 2.1 Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6a4331",
   "metadata": {},
   "source": [
    "### 2.1.1 What is feature selection and why is it important"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99aa0fd7",
   "metadata": {},
   "source": [
    "Feature selection is a process in machine learning and data analysis that involves selecting a subset of relevant and important features (also known as attributes or variables) from a larger set of features in a dataset. The goal of feature selection is to choose the most informative and significant features that have a strong relationship with the target variable or outcome of interest.\n",
    "\n",
    "In many real-world datasets, there may be numerous features, some of which might be redundant, irrelevant, or even noisy, meaning they do not contribute much to the prediction or analysis task. Including such features in the model can lead to various issues, such as increased computational complexity, overfitting, reduced model interpretability, and degraded model performance on unseen data.\n",
    "\n",
    "By performing feature selection, we aim to:\n",
    "\n",
    "**1. Improve Model Performance:** By selecting only the most relevant features, the model can focus on the most important patterns and relationships in the data, leading to better generalization and improved model performance on new, unseen data.\n",
    "\n",
    "**2. Reduce Overfitting:** Including irrelevant or redundant features in the model can cause overfitting, where the model memorizes the training data but fails to generalize well to new data. Feature selection helps in reducing overfitting and promoting better model generalization.\n",
    "\n",
    "**3. Enhance Model Interpretability:** Models with a smaller number of features are easier to interpret and understand. Feature selection helps create simpler, more interpretable models, which can provide valuable insights into the underlying relationships between features and the target variable.\n",
    "\n",
    "**4. Save Computational Resources:** Removing irrelevant features from the dataset reduces the amount of data that needs to be processed during model training and prediction, leading to faster and more efficient computations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3622429f",
   "metadata": {},
   "source": [
    "### 2.1.2 Common Feature Selection Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9dffe00",
   "metadata": {},
   "source": [
    "Feature selection is a crucial step in data science that involves choosing the most relevant and informative features from a dataset to improve the performance of a machine learning model and reduce overfitting. There are various methods for feature selection, each with its advantages and use cases. Here are some common methods:\n",
    "\n",
    "### 1. Univariate Feature Selection (SelectKBest):\n",
    "Univariate feature selection is a statistical method that ranks each feature based on its individual relationship with the target variable. SelectKBest is one such technique that selects the top K features with the highest scores from a given statistical test. In our case, we use the F-test as the score function. The chosen features are those that show the strongest correlation with the target variable in isolation.\n",
    "\n",
    "\n",
    "### 2. Recursive Feature Elimination (RFE):\n",
    "Recursive Feature Elimination (RFE) is a recursive method that starts with all features and iteratively removes the least important feature at each step. It uses an underlying model (in our case, a linear regression model) to evaluate feature importance and eliminates the least significant feature based on its coefficient value. RFE continues this process until it reaches the desired number of features.\n",
    "\n",
    "\n",
    "### 3. Random Forest Feature Importance:\n",
    "Random Forest is an ensemble learning method that builds multiple decision trees and combines their predictions. Feature importance is calculated based on the average impurity reduction (or information gain) from each feature across all trees. Features with higher importance scores are considered more relevant to the target variable. In this method, we select the top features based on their importance scores without using any threshold.\n",
    "\n",
    "\n",
    "### 4. SelectPercentile:\n",
    "SelectPercentile is another univariate feature selection method that selects the top features based on a user-defined percentile of the highest-scoring features. In our case, we use the F-test score function to rank features based on their correlation with the target variable. The features that have importance scores above the specified percentile are chosen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7212281b",
   "metadata": {},
   "source": [
    "## 2.2 Load and Introduce the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "695fde7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "4512d80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the California housing dataset\n",
    "data = fetch_california_housing(as_frame=True)\n",
    "df = data.frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "250efdf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>MedHouseVal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "\n",
       "   Longitude  MedHouseVal  \n",
       "0    -122.23        4.526  \n",
       "1    -122.22        3.585  \n",
       "2    -122.24        3.521  \n",
       "3    -122.25        3.413  \n",
       "4    -122.25        3.422  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e0ec8c",
   "metadata": {},
   "source": [
    "The California housing dataset is a popular dataset often used for regression tasks in machine learning and data analysis. It contains data from the 1990 California census and provides various features related to housing in different districts of California. The target variable in this dataset is typically the median house value for California districts.\n",
    "\n",
    "The dataset includes the following features:\n",
    "\n",
    "1. **MedInc:** Median income of the district.\n",
    "2. **HouseAge:** Median age of the houses in the district.\n",
    "3. **AveRooms:** Average number of rooms in the houses in the district.\n",
    "4. **AveBedrms:** Average number of bedrooms in the houses in the district.\n",
    "5. **Population:** Total population of the district.\n",
    "6. **AveOccup:** Average household occupancy, i.e., the number of people living in a household in the district.\n",
    "7. **Latitude:** Latitude coordinate of the district's location.\n",
    "8. **Longitude:** Longitude coordinate of the district's location.\n",
    "\n",
    "\n",
    "The target variable is:\n",
    "\n",
    "9. **MedHouseVal:** Median house value for California districts (the target variable for regression)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "53a5b3c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20640 entries, 0 to 20639\n",
      "Data columns (total 9 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   MedInc       20640 non-null  float64\n",
      " 1   HouseAge     20640 non-null  float64\n",
      " 2   AveRooms     20640 non-null  float64\n",
      " 3   AveBedrms    20640 non-null  float64\n",
      " 4   Population   20640 non-null  float64\n",
      " 5   AveOccup     20640 non-null  float64\n",
      " 6   Latitude     20640 non-null  float64\n",
      " 7   Longitude    20640 non-null  float64\n",
      " 8   MedHouseVal  20640 non-null  float64\n",
      "dtypes: float64(9)\n",
      "memory usage: 1.4 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "5c33d28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into features (X) and target variable (y)\n",
    "X = df.drop('MedHouseVal', axis=1)\n",
    "y = df['MedHouseVal']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93916dc4",
   "metadata": {},
   "source": [
    "## 2.3 Feature Selection Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7d1fea",
   "metadata": {},
   "source": [
    "#### 2.3.1 Univariate Feature Selection (SelectKBest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "688581a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features using Univariate Feature Selection (SelectKBest):\n",
      "Index(['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Latitude'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# 1. Univariate Feature Selection (SelectKBest)\n",
    "k_best_features = 5  # Choose the desired number of top features\n",
    "selector_univariate = SelectKBest(score_func=f_regression, k=k_best_features)\n",
    "X_new_univariate = selector_univariate.fit_transform(X, y)\n",
    "selected_features_univariate = X.columns[selector_univariate.get_support()]\n",
    "print(\"Selected features using Univariate Feature Selection (SelectKBest):\")\n",
    "print(selected_features_univariate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9c8153",
   "metadata": {},
   "source": [
    "1. k_best_features = 5: This line sets the variable k_best_features to 5, which means we want to select the top 5 best features from the dataset.\n",
    "\n",
    "2. selector_univariate = SelectKBest(score_func=f_regression, k=k_best_features): Here, we create an instance of the SelectKBest class. The score_func parameter is set to f_regression, which means the method will use the F-test to determine the relationship between each feature and the target variable. The k parameter is set to k_best_features, indicating that we want to select the top 5 features.\n",
    "\n",
    "3. X_new_univariate = selector_univariate.fit_transform(X, y): This line fits the SelectKBest instance to the input data X and target variable y. It then transforms the original dataset X into a new dataset X_new_univariate, containing only the selected top 5 features based on the F-test scores.\n",
    "\n",
    "4. selected_features_univariate = X.columns[selector_univariate.get_support()]: After performing feature selection, this line retrieves the names of the selected features from the original dataset X using the get_support() method of the SelectKBest instance. This method returns a boolean mask that indicates which features were selected (True) and which were not selected (False). We use this mask to extract the names of the selected features from the X.columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "fc237c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features using Univariate Feature Selection (SelectKBest):\n",
      "Index(['MedInc', 'AveRooms', 'Latitude', 'HouseAge', 'AveBedrms'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# 1. Univariate Feature Selection (SelectKBest)\n",
    "k_best_features = 5  # Choose the desired number of top features\n",
    "# Compute feature scores using univariate regression (F-test)\n",
    "scores_univariate = f_regression(X, y)[0]\n",
    "# Get the indices of the top K features\n",
    "selected_indices_univariate = sorted(\n",
    "    range(len(scores_univariate)),\n",
    "    key=lambda i: scores_univariate[i], reverse=True)[:k_best_features]\n",
    "selected_features_univariate = X.columns[selected_indices_univariate]\n",
    "print(\"Selected features using Univariate Feature Selection (SelectKBest):\")\n",
    "print(selected_features_univariate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4853430",
   "metadata": {},
   "source": [
    "1. k_best_features = 5: As before, this line sets the variable k_best_features to 5, indicating that we want to select the top 5 best features.\n",
    "\n",
    "2. scores_univariate = f_regression(X, y)[0]: This line computes the F-test scores for each feature in the input dataset X with respect to the target variable y. The f_regression function is used for this purpose, and [0] is used to extract the F-test scores from the function's result. The F-test measures the correlation between each feature and the target variable, helping us identify the most relevant features.\n",
    "\n",
    "3. selected_indices_univariate = sorted(range(len(scores_univariate)), key=lambda i: scores_univariate[i], reverse=True)[:k_best_features]: This line calculates the indices of the top K features based on their F-test scores. It sorts the indices in descending order of their corresponding scores and selects the top k_best_features indices using Python slicing.\n",
    "\n",
    "4. selected_features_univariate = X.columns[selected_indices_univariate]: After obtaining the indices of the top features, this line extracts the names of these features from the original dataset X using the selected_indices_univariate variable. It retrieves the corresponding columns from the X DataFrame to get the selected feature names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "0132da80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveBedrms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>37.88</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1.023810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>37.86</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.971880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1.073446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1.073059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1.081081</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  AveRooms  Latitude  HouseAge  AveBedrms\n",
       "0  8.3252  6.984127     37.88      41.0   1.023810\n",
       "1  8.3014  6.238137     37.86      21.0   0.971880\n",
       "2  7.2574  8.288136     37.85      52.0   1.073446\n",
       "3  5.6431  5.817352     37.85      52.0   1.073059\n",
       "4  3.8462  6.281853     37.85      52.0   1.081081"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_univariate = pd.DataFrame(data=df, columns=selected_features_univariate)\n",
    "df_univariate.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2f5d82",
   "metadata": {},
   "source": [
    "#### 2.3.2 Recursive Feature Elimination (RFE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "2ea85d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selected features using Recursive Feature Elimination (RFE):\n",
      "Index(['MedInc', 'AveRooms', 'AveBedrms', 'Latitude', 'Longitude'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "num_features_to_select = 5  # Choose the desired number of features\n",
    "estimator_rfe = LinearRegression()\n",
    "selector_rfe = RFE(estimator_rfe, n_features_to_select=num_features_to_select)\n",
    "X_new_rfe = selector_rfe.fit_transform(X, y)\n",
    "selected_features_rfe = X.columns[selector_rfe.support_]\n",
    "print(\"\\nSelected features using Recursive Feature Elimination (RFE):\")\n",
    "print(selected_features_rfe)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732618e6",
   "metadata": {},
   "source": [
    "1. num_features_to_select = 5: This line sets the variable num_features_to_select to 5, indicating that we want to select the top 5 best features.\n",
    "\n",
    "2. estimator_rfe = LinearRegression(): Here, we create an instance of the LinearRegression class, which will be used as the estimator to rank and select features. The RFE algorithm will repeatedly fit the estimator to the data and remove the least important features based on the coefficients obtained from the estimator.\n",
    "\n",
    "3. selector_rfe = RFE(estimator_rfe, n_features_to_select=num_features_to_select): This line creates an instance of the RFE class and passes the estimator_rfe (i.e., the LinearRegression instance) as the estimator. The n_features_to_select parameter is set to num_features_to_select, indicating the number of features to be selected.\n",
    "\n",
    "4. X_new_rfe = selector_rfe.fit_transform(X, y): The fit_transform method is called on the selector_rfe instance to perform the RFE feature selection. It fits the estimator to the input dataset X and target variable y, and then transforms the original dataset X into a new dataset X_new_rfe, containing only the selected top 5 features.\n",
    "\n",
    "5. selected_features_rfe = X.columns[selector_rfe.support_]: After the RFE process, this line retrieves the names of the selected features from the original dataset X using the selector_rfe.support_ attribute. The selector_rfe.support_ attribute is a boolean mask that indicates which features were selected (True) and which were not selected (False). We use this mask to extract the names of the selected features from the X.columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "ddb1aa88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selected features using Recursive Feature Elimination (RFE):\n",
      "Index(['MedInc', 'AveRooms', 'AveBedrms', 'Latitude', 'Longitude'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# 2. Recursive Feature Elimination (RFE)\n",
    "num_features_to_select = 5  # Choose the desired number of features\n",
    "# Create a linear regression model\n",
    "estimator_rfe = LinearRegression()\n",
    "# RFE: Start with all features, recursively remove the least important one until reaching the desired number of features\n",
    "selected_indices_rfe = list(range(len(X.columns)))\n",
    "while len(selected_indices_rfe) > num_features_to_select:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X.iloc[:, selected_indices_rfe], y, test_size=0.3, random_state=42)\n",
    "    estimator_rfe.fit(X_train, y_train)\n",
    "    # Get the feature importances (coefficients) from the model\n",
    "    feature_importances_rfe = estimator_rfe.coef_\n",
    "    # Find the index of the least important feature and remove it\n",
    "    min_importance_index = None\n",
    "    min_importance_value = float('inf')\n",
    "    for i, importance in enumerate(feature_importances_rfe):\n",
    "        if abs(importance) < min_importance_value:\n",
    "            min_importance_index = i\n",
    "            min_importance_value = abs(importance)\n",
    "    selected_indices_rfe.pop(min_importance_index)\n",
    "selected_features_rfe = X.columns[selected_indices_rfe]\n",
    "print(\"\\nSelected features using Recursive Feature Elimination (RFE):\")\n",
    "print(selected_features_rfe)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83b7c03",
   "metadata": {},
   "source": [
    "1. num_features_to_select = 5: As before, this line sets the variable num_features_to_select to 5, indicating that we want to select the top 5 best features.\n",
    "\n",
    "2. estimator_rfe = LinearRegression(): Here, we create an instance of the LinearRegression class, which will be used as the estimator to rank and select features, just like in the previous example.\n",
    "\n",
    "3. selected_indices_rfe = list(range(len(X.columns))): This line creates a list selected_indices_rfe containing the indices of all features in the input dataset X. At the beginning, all features are considered for selection.\n",
    "\n",
    "4. while len(selected_indices_rfe) > num_features_to_select:: The code enters a while loop that continues until the number of selected indices becomes equal to num_features_to_select. Inside the loop, the RFE process will be performed.\n",
    "\n",
    "5. The loop starts by splitting the data into training and testing sets using train_test_split on the selected indices. This is done to evaluate the importance of each feature.\n",
    "\n",
    "6. estimator_rfe.fit(X_train, y_train): The LinearRegression estimator is fitted to the training data X_train and y_train.\n",
    "\n",
    "7. feature_importances_rfe = estimator_rfe.coef_: The coefficients (feature importances) of the LinearRegression model are obtained using estimator_rfe.coef_.\n",
    "\n",
    "8. The loop iterates through the feature_importances_rfe array to find the index of the least important feature. The feature with the smallest absolute coefficient value is considered the least important.\n",
    "\n",
    "10. selected_indices_rfe.pop(min_importance_index): The index of the least important feature is removed from the selected_indices_rfe list.\n",
    "\n",
    "11. The loop repeats the process (fitting, evaluating feature importances, removing least important feature) until the desired number of selected features (num_features_to_select) is reached.\n",
    "\n",
    "12. After the loop ends, the selected feature names are extracted from the original dataset X using the selected_indices_rfe list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "0fc7b15e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  AveRooms  AveBedrms  Latitude  Longitude\n",
       "0  8.3252  6.984127   1.023810     37.88    -122.23\n",
       "1  8.3014  6.238137   0.971880     37.86    -122.22\n",
       "2  7.2574  8.288136   1.073446     37.85    -122.24\n",
       "3  5.6431  5.817352   1.073059     37.85    -122.25\n",
       "4  3.8462  6.281853   1.081081     37.85    -122.25"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rfe = pd.DataFrame(data=df, columns=selected_features_rfe)\n",
    "df_rfe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19de445",
   "metadata": {},
   "source": [
    "#### 2.3.3 Random Forest Feature Importance with Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "350538be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selected features using Random Forest Feature Importance with Threshold:\n",
      "Index(['MedInc', 'HouseAge', 'AveOccup', 'Latitude', 'Longitude'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "threshold_importance = 0.05  # Choose the desired importance threshold\n",
    "estimator_rf = RandomForestRegressor()\n",
    "estimator_rf.fit(X, y)\n",
    "importances = estimator_rf.feature_importances_\n",
    "selected_features_rf = X.columns[importances > threshold_importance]\n",
    "print(\"\\nSelected features using Random Forest Feature Importance with Threshold:\")\n",
    "print(selected_features_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48177412",
   "metadata": {},
   "source": [
    "1. threshold_importance = 0.05: This line sets the variable threshold_importance to 0.05, indicating the minimum importance threshold. Features with an importance greater than this threshold will be selected.\n",
    "\n",
    "2. estimator_rf = RandomForestRegressor(): Here, we create an instance of the RandomForestRegressor class, which will be used to fit the random forest model to the data and calculate feature importances.\n",
    "\n",
    "3. estimator_rf.fit(X, y): The random forest model is fitted to the input dataset X and target variable y.\n",
    "\n",
    "4. importances = estimator_rf.feature_importances_: The feature importances obtained from the trained random forest model are stored in the importances variable. These importances represent the relative importance of each feature in predicting the target variable.\n",
    "\n",
    "5. selected_features_rf = X.columns[importances > threshold_importance]: This line filters the features based on their importances. It creates a boolean mask where each entry indicates whether the feature importance is greater than the threshold_importance or not. Using this mask, it extracts the names of the features that meet the importance threshold from the original dataset X.columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "662fe205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selected features using Random Forest Feature Importance with Threshold:\n",
      "Index(['MedInc', 'HouseAge', 'AveOccup', 'Latitude', 'Longitude'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# 3. Random Forest Feature Importance with Threshold\n",
    "threshold_importance = 0.05  # Choose the desired importance threshold\n",
    "# Create a random forest model\n",
    "estimator_rf = RandomForestRegressor()\n",
    "estimator_rf.fit(X, y)\n",
    "# Get the feature importances from the model\n",
    "importances_rf = estimator_rf.feature_importances_\n",
    "# Find the indices of the features that have importance scores above the threshold\n",
    "selected_indices_rf = []\n",
    "for i, importance in enumerate(importances_rf):\n",
    "    if importance > threshold_importance:\n",
    "        selected_indices_rf.append(i)\n",
    "selected_features_rf = X.columns[selected_indices_rf]\n",
    "print(\"\\nSelected features using Random Forest Feature Importance with Threshold:\")\n",
    "print(selected_features_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af85004b",
   "metadata": {},
   "source": [
    "1. threshold_importance = 0.05: As before, this line sets the variable threshold_importance to 0.05, indicating the minimum importance threshold. Features with an importance greater than this threshold will be selected.\n",
    "\n",
    "2. estimator_rf = RandomForestRegressor(): Here, we create an instance of the RandomForestRegressor class, which will be used to fit the random forest model to the data and calculate feature importances.\n",
    "\n",
    "3. estimator_rf.fit(X, y): The random forest model is fitted to the input dataset X and target variable y.\n",
    "\n",
    "4. importances_rf = estimator_rf.feature_importances_: The feature importances obtained from the trained random forest model are stored in the importances_rf variable. These importances represent the relative importance of each feature in predicting the target variable.\n",
    "\n",
    "5. selected_indices_rf = []: This line initializes an empty list selected_indices_rf to store the indices of the features that meet the importance threshold.\n",
    "\n",
    "6. The loop iterates through the importances_rf array using enumerate, where i represents the index of the feature, and importance represents the corresponding feature importance.\n",
    "\n",
    "7. if importance > threshold_importance:: The code checks if the importance of the current feature is greater than the specified threshold_importance.\n",
    "\n",
    "8. If the feature meets the importance threshold, its index (i) is appended to the selected_indices_rf list.\n",
    "\n",
    "9. After the loop ends, the selected_indices_rf list contains the indices of the features that have importance scores above the threshold.\n",
    "\n",
    "10. selected_features_rf = X.columns[selected_indices_rf]: This line retrieves the names of the selected features from the original dataset X using the selected_indices_rf list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "ef00c9af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveOccup  Latitude  Longitude\n",
       "0  8.3252      41.0  2.555556     37.88    -122.23\n",
       "1  8.3014      21.0  2.109842     37.86    -122.22\n",
       "2  7.2574      52.0  2.802260     37.85    -122.24\n",
       "3  5.6431      52.0  2.547945     37.85    -122.25\n",
       "4  3.8462      52.0  2.181467     37.85    -122.25"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rf = pd.DataFrame(data=df, columns=selected_features_rf)\n",
    "df_rf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d5deee",
   "metadata": {},
   "source": [
    "#### 2.3.4 SelectPercentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "91a9b3b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selected features using SelectPercentile:\n",
      "Index(['MedInc', 'HouseAge', 'AveRooms', 'Latitude'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "percentile_features = 50  # Choose the desired percentile of features to keep\n",
    "selector_percentile = SelectPercentile(score_func=f_regression, percentile=percentile_features)\n",
    "X_new_percentile = selector_percentile.fit_transform(X, y)\n",
    "selected_features_percentile = X.columns[selector_percentile.get_support()]\n",
    "print(\"\\nSelected features using SelectPercentile:\")\n",
    "print(selected_features_percentile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ddb5322",
   "metadata": {},
   "source": [
    "1. percentile_features = 50: This line sets the variable percentile_features to 50, indicating that we want to keep the top 50% of features based on their statistical significance.\n",
    "\n",
    "2. selector_percentile = SelectPercentile(score_func=f_regression, percentile=percentile_features): This line creates an instance of the SelectPercentile class. It uses the f_regression score function, which calculates the F-test scores between each feature and the target variable. The percentile parameter is set to percentile_features, indicating the desired percentile of features to keep.\n",
    "\n",
    "3. X_new_percentile = selector_percentile.fit_transform(X, y): The fit_transform method is called on the selector_percentile instance to perform the feature selection. It fits the SelectPercentile instance to the input dataset X and target variable y, and then transforms the original dataset X into a new dataset X_new_percentile, containing only the selected top features based on their statistical significance.\n",
    "\n",
    "4. selected_features_percentile = X.columns[selector_percentile.get_support()]: After performing feature selection, this line retrieves the names of the selected features from the original dataset X using the selector_percentile.get_support() method. This method returns a boolean mask that indicates which features were selected (True) and which were not selected (False). We use this mask to extract the names of the selected features from the X.columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "a9539c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selected features using SelectPercentile:\n",
      "Index(['MedInc', 'HouseAge', 'AveRooms', 'Latitude'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# 4. SelectPercentile\n",
    "percentile_features = 50  # Choose the desired percentile of features to keep\n",
    "# Compute feature scores using univariate regression (F-test)\n",
    "scores_percentile = f_regression(X, y)[0]\n",
    "# Find the importance score threshold for the desired percentile\n",
    "importance_threshold = np.percentile(scores_percentile, percentile_features)\n",
    "# Find the indices of the features that have importance scores above the threshold\n",
    "selected_indices_percentile = []\n",
    "for i, score in enumerate(scores_percentile):\n",
    "    if score >= importance_threshold:\n",
    "        selected_indices_percentile.append(i)\n",
    "selected_features_percentile = X.columns[selected_indices_percentile]\n",
    "print(\"\\nSelected features using SelectPercentile:\")\n",
    "print(selected_features_percentile)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e49a46",
   "metadata": {},
   "source": [
    "1. percentile_features = 50: As before, this line sets the variable percentile_features to 50, indicating that we want to keep the top 50% of features based on their statistical significance.\n",
    "\n",
    "2. scores_percentile = f_regression(X, y)[0]: This line computes the F-test scores for each feature in the input dataset X with respect to the target variable y. The f_regression function is used for this purpose, and [0] is used to extract the F-test scores from the function's result. The F-test measures the correlation between each feature and the target variable, helping us identify the most relevant features.\n",
    "\n",
    "3. importance_threshold = np.percentile(scores_percentile, percentile_features): This line calculates the importance score threshold that corresponds to the desired percentile. It uses the np.percentile function from NumPy to find the value at percentile_features percentile in the scores_percentile array.\n",
    "\n",
    "4. selected_indices_percentile = []: This line initializes an empty list selected_indices_percentile to store the indices of the features that have importance scores above the calculated threshold.\n",
    "\n",
    "5. The loop iterates through the scores_percentile array using enumerate, where i represents the index of the feature, and score represents the corresponding F-test score.\n",
    "\n",
    "6. if score >= importance_threshold:: The code checks if the F-test score of the current feature is greater than or equal to the calculated importance_threshold.\n",
    "\n",
    "7. If the feature meets the importance threshold, its index (i) is appended to the selected_indices_percentile list.\n",
    "\n",
    "8. After the loop ends, the selected_indices_percentile list contains the indices of the features that have importance scores above the threshold.\n",
    "\n",
    "9. selected_features_percentile = X.columns[selected_indices_percentile]: This line retrieves the names of the selected features from the original dataset X using the selected_indices_percentile list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "638a5c71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>Latitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>37.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>37.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>37.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>37.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>37.85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  Latitude\n",
       "0  8.3252      41.0  6.984127     37.88\n",
       "1  8.3014      21.0  6.238137     37.86\n",
       "2  7.2574      52.0  8.288136     37.85\n",
       "3  5.6431      52.0  5.817352     37.85\n",
       "4  3.8462      52.0  6.281853     37.85"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_percentile = pd.DataFrame(data=df, columns=selected_features_percentile)\n",
    "df_percentile.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5afb1cb",
   "metadata": {},
   "source": [
    "## 2.4 Performance Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd387f93",
   "metadata": {},
   "source": [
    "Here, we choose decision tree as the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "bbdb0b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "def decision_tree_func(df, y = data.target):\n",
    "    # Separate features and target\n",
    "    X = df  # Features\n",
    "\n",
    "    # Split the data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "    # Create a decision tree regressor\n",
    "    tree = DecisionTreeRegressor()\n",
    "\n",
    "    # Fit the model on the training data\n",
    "    tree.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the test data\n",
    "    y_pred = tree.predict(X_test)\n",
    "\n",
    "    # Calculate the mean squared error (MSE)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "    # Calculate the mean absolute error (MAE)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "    # Calculate the R-squared (coefficient of determination)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    # Print the predicted values, MSE, MAE, and R-squared\n",
    "    print(\"Mean Squared Error:\", mse)\n",
    "    print(\"Mean Absolute Error:\", mae)\n",
    "    print(\"R-squared:\", r2)\n",
    "\n",
    "    return r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "5e41b82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of feature selection methods\n",
    "feature_selection_methods = [\n",
    "    \"Univariate Feature Selection (SelectKBest)\",\n",
    "    \"Recursive Feature Elimination (RFE)\",\n",
    "    \"Random Forest Feature Importance with Threshold\",\n",
    "    \"SelectPercentile\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "cac3dbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list =  [df_univariate, df_rfe, df_rf, df_percentile]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "91121d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Univariate Feature Selection (SelectKBest):\n",
      "Mean Squared Error: 0.8507950330086239\n",
      "Mean Absolute Error: 0.63388371124031\n",
      "R-squared: 0.34752725612036495\n",
      "\n",
      "Recursive Feature Elimination (RFE):\n",
      "Mean Squared Error: 0.44905180960726737\n",
      "Mean Absolute Error: 0.4256104360465116\n",
      "R-squared: 0.6556232053653758\n",
      "\n",
      "Random Forest Feature Importance with Threshold:\n",
      "Mean Squared Error: 0.523841449975218\n",
      "Mean Absolute Error: 0.4551108938953488\n",
      "R-squared: 0.5982672030717502\n",
      "\n",
      "SelectPercentile:\n",
      "Mean Squared Error: 0.8854762924951549\n",
      "Mean Absolute Error: 0.6379457364341085\n",
      "R-squared: 0.3209302783989998\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy_dict = {}\n",
    "\n",
    "for i in range(len(df_list)):\n",
    "    print(feature_selection_methods[i] + \":\")\n",
    "    \n",
    "    accuracy_dict.update({feature_selection_methods[i]:decision_tree_func(df_list[i])})\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "d1884b47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Univariate Feature Selection (SelectKBest)': 0.34752725612036495,\n",
       " 'Recursive Feature Elimination (RFE)': 0.6556232053653758,\n",
       " 'Random Forest Feature Importance with Threshold': 0.5982672030717502,\n",
       " 'SelectPercentile': 0.3209302783989998}"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "a812d973",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Recursive Feature Elimination (RFE)</th>\n",
       "      <td>0.655623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest Feature Importance with Threshold</th>\n",
       "      <td>0.598267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Univariate Feature Selection (SelectKBest)</th>\n",
       "      <td>0.347527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SelectPercentile</th>\n",
       "      <td>0.320930</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Accuracy\n",
       "Recursive Feature Elimination (RFE)              0.655623\n",
       "Random Forest Feature Importance with Threshold  0.598267\n",
       "Univariate Feature Selection (SelectKBest)       0.347527\n",
       "SelectPercentile                                 0.320930"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalleaderboard = pd.DataFrame.from_dict(accuracy_dict, orient='index', columns=['Accuracy'])\n",
    "finalleaderboard = finalleaderboard.sort_values('Accuracy', ascending=False)\n",
    "finalleaderboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9eae2b",
   "metadata": {},
   "source": [
    "## 2.5 Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7389f181",
   "metadata": {},
   "source": [
    "Please choose one of the method before and perform the feature selection. Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "c12eb5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Load the Iris dataset\n",
    "data = load_iris()\n",
    "\n",
    "# Get the feature matrix (X) and target array (y)\n",
    "X = data.data\n",
    "y = data.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab71a32",
   "metadata": {},
   "source": [
    "# 3. Evaluation Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b66ce5",
   "metadata": {},
   "source": [
    "## 3.1 Introduction\n",
    "In data science, evaluation metrics are used to measure the performance and effectiveness of various machine learning models and algorithms. The choice of evaluation metrics depends on the specific problem being solved and the nature of the data. Here are some commonly used evaluation metrics in data science:\n",
    "\n",
    "**1. Accuracy:** Measures the proportion of correctly predicted instances to the total number of instances in the dataset. It is a straightforward metric but can be misleading in imbalanced datasets.\n",
    "\n",
    "**2. Precision:** The proportion of true positive predictions (correctly predicted positive instances) to the total number of positive predictions made by the model. It is useful when the cost of false positives is high.\n",
    "\n",
    "**3. Recall (Sensitivity or True Positive Rate):** The proportion of true positive predictions to the total number of actual positive instances in the dataset. It is valuable when the cost of false negatives is high.\n",
    "\n",
    "**4. F1 Score:** The harmonic mean of precision and recall. It provides a balance between precision and recall, especially in imbalanced datasets.\n",
    "\n",
    "**5. Specificity (True Negative Rate):** The proportion of true negative predictions to the total number of actual negative instances in the dataset. It is useful when the cost of false negatives is high.\n",
    "\n",
    "**6. ROC-AUC (Receiver Operating Characteristic - Area Under the Curve):** Evaluates the area under the ROC curve, which plots the true positive rate against the false positive rate at various classification thresholds. It provides an aggregate measure of a model's performance across various thresholds.\n",
    "\n",
    "**7. Confusion Matrix:** A table that presents the true positive, true negative, false positive, and false negative counts, allowing for a more detailed evaluation of a classifier's performance.\n",
    "\n",
    "**8. Mean Absolute Error (MAE):** Measures the average absolute difference between the actual and predicted values. It is commonly used for regression tasks.\n",
    "\n",
    "**9. Mean Squared Error (MSE):** Measures the average squared difference between the actual and predicted values. It is another popular metric for regression tasks.\n",
    "\n",
    "**10. Root Mean Squared Error (RMSE):** The square root of MSE, providing a more interpretable metric for regression tasks.\n",
    "\n",
    "**11. R-squared (R2):** Measures the proportion of variance in the dependent variable that is predictable from the independent variables. It represents the goodness of fit of a regression mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79188108",
   "metadata": {},
   "source": [
    "## 3.2 Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2844787",
   "metadata": {},
   "source": [
    "### 3.2.1 Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "692dd9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_curve, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af8bbcd",
   "metadata": {},
   "source": [
    "**Imports**: Here, we import the necessary libraries for our code. `numpy` and `pandas` are used for data manipulation, `matplotlib` for data visualization, `load_iris` from `sklearn.datasets` to load the Iris dataset, `train_test_split` from `sklearn.model_selection` to split the data, `LogisticRegression` from `sklearn.linear_model` for the classification model, and various evaluation metrics (`confusion_matrix`, `classification_report`, `roc_curve`, `roc_auc_score`) from sklearn.metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2026f4b4",
   "metadata": {},
   "source": [
    "### 3.2.2 Load and Introduce the Wine dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "46b32e21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "0    14.23        1.71  2.43               15.6      127.0           2.80   \n",
       "1    13.20        1.78  2.14               11.2      100.0           2.65   \n",
       "2    13.16        2.36  2.67               18.6      101.0           2.80   \n",
       "3    14.37        1.95  2.50               16.8      113.0           3.85   \n",
       "4    13.24        2.59  2.87               21.0      118.0           2.80   \n",
       "\n",
       "   flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "0        3.06                  0.28             2.29             5.64  1.04   \n",
       "1        2.76                  0.26             1.28             4.38  1.05   \n",
       "2        3.24                  0.30             2.81             5.68  1.03   \n",
       "3        3.49                  0.24             2.18             7.80  0.86   \n",
       "4        2.69                  0.39             1.82             4.32  1.04   \n",
       "\n",
       "   od280/od315_of_diluted_wines  proline  target  \n",
       "0                          3.92   1065.0       0  \n",
       "1                          3.40   1050.0       0  \n",
       "2                          3.17   1185.0       0  \n",
       "3                          3.45   1480.0       0  \n",
       "4                          2.93    735.0       0  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "wine = load_wine()\n",
    "X, y = wine.data, wine.target\n",
    "\n",
    "# Create a DataFrame\n",
    "wine_df = pd.DataFrame(data=X, columns=wine.feature_names)\n",
    "wine_df['target'] = y\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "wine_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfcd526d",
   "metadata": {},
   "source": [
    "**Dataset: Wine Dataset**\n",
    "\n",
    "**Source:** UCI Machine Learning Repository\n",
    "\n",
    "**Description:** The Wine dataset contains the results of a chemical analysis of wines grown in the same region in Italy, but from three different cultivars. The goal of this dataset is to classify wines into their respective classes based on their chemical attributes.\n",
    "\n",
    "**Features:**\n",
    "\n",
    "1. **Alcohol:** The alcohol content in the wine.\n",
    "2. **Malic Acid:** The amount of malic acid present in the wine.\n",
    "3. **Ash:** The ash content of the wine.\n",
    "4. **Alcalinity of Ash:** The level of alkalinity in the ash.\n",
    "5. **Magnesium:** The magnesium content in the wine.\n",
    "6. **Total Phenols:** The total phenolic content in the wine.\n",
    "7. **Flavanoids:** The amount of flavonoid compounds present in the wine.\n",
    "8. **Nonflavanoid Phenols:** The amount of non-flavonoid phenolic compounds.\n",
    "9. **Proanthocyanins:** The level of proanthocyanidins in the wine.\n",
    "10. **Color Intensity:** The color intensity of the wine.\n",
    "11. **Hue:** The hue or color shade of the wine.\n",
    "12. **OD280/OD315 of Diluted Wines:** The optical density at 280/315 nm, indicating color intensity.\n",
    "13. **Proline:** The amount of proline, an amino acid, in the wine.\n",
    "\n",
    "**Target Variable:**\n",
    "\n",
    "**target:** This feature represents the class or cultivar of the wine. It can take on three different values: 0, 1, or 2, corresponding to the three different cultivars.\n",
    "This dataset is commonly used for classification tasks in machine learning, where the goal is to predict the cultivar of a wine based on its chemical attributes. Each of the features contributes to the characterization of the wine's composition and can have an impact on its classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127e1c48",
   "metadata": {},
   "source": [
    "### 3.2.3 Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "eff796d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714de057",
   "metadata": {},
   "source": [
    "**Data Splitting**: The `train_test_split()` function is used to split the data into training and testing sets. We specify `test_size=0.3`, which means 30% of the data will be used for testing, and the remaining 70% for training. The `random_state` parameter is set to 42 to ensure reproducibility of the split."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b03745",
   "metadata": {},
   "source": [
    "### 3.2.4 Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "f2481f46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create and train a logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a1235d",
   "metadata": {},
   "source": [
    "**Model Training**: We create an instance of the logistic regression model using `LogisticRegression()`. Then, we fit the model to the training data using `model.fit(X_train, y_train)`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59aaa607",
   "metadata": {},
   "source": [
    "### 3.2.5 Model Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "26dbe124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04521fa9",
   "metadata": {},
   "source": [
    "**Model Prediction**: We use the trained model to make predictions on the test set using `model.predict(X_test)`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128880b8",
   "metadata": {},
   "source": [
    "### 3.2.6 Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "32338ada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9814814814814815"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate evaluation metrics\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8e0409",
   "metadata": {},
   "source": [
    "**Evaluation Metrics**: Here, we calculate the evaluation metrics for our classification model. We calculate the accuracy, which is the proportion of correct predictions. We use `np.mean(y_pred == y_test)` to calculate accuracy, where `y_pred` are the model predictions and `y_test` are the true labels. We also compute the confusion matrix using `confusion_matrix(y_test, y_pred)`, and the classification report using `classification_report(y_test, y_pred)`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ba6d98",
   "metadata": {},
   "source": [
    "### 3.2.7 Data Visualization - Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "862f8bef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Assuming you already have the 'conf_matrix' and 'wine.target_names' variables defined\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.imshow(conf_matrix, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "\n",
    "classes = wine.target_names  # Define 'classes' before using it in the loop\n",
    "\n",
    "# Add numbers to the Confusion Matrix cells\n",
    "for i in range(len(classes)):\n",
    "    for j in range(len(classes)):\n",
    "        plt.text(j, i, str(conf_matrix[i, j]),\n",
    "                 horizontalalignment=\"center\", color=\"white\" if i == j else \"black\")\n",
    "\n",
    "plt.title('Confusion Matrix')\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(classes))\n",
    "plt.xticks(tick_marks, classes, rotation=45)\n",
    "plt.yticks(tick_marks, classes)\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c556920",
   "metadata": {},
   "source": [
    "**Data Visualization** - Confusion Matrix: We use matplotlib to create a heatmap to visualize the confusion matrix. The heatmap's intensity represents the number of correct and incorrect predictions for each class. The color bar indicates the scale of the values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3803798",
   "metadata": {},
   "source": [
    "### 3.2.8 Classification Report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "02a3054b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97        19\n",
      "           1       0.95      1.00      0.98        21\n",
      "           2       1.00      1.00      1.00        14\n",
      "\n",
      "    accuracy                           0.98        54\n",
      "   macro avg       0.98      0.98      0.98        54\n",
      "weighted avg       0.98      0.98      0.98        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification Report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5af5861",
   "metadata": {},
   "source": [
    "**Classification Report**: We print the classification report, which includes metrics like precision, recall, F1-score, and support for each class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40e0fe4",
   "metadata": {},
   "source": [
    "## 3.3 Exercise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3268f358",
   "metadata": {},
   "source": [
    "Please choose the feature you selected above, train the features with SVM classifier, and apply two evaluation metrics to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "ca4ea328",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC  # Import the SVC class\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "iris_df[\"target\"] = iris.target\n",
    "\n",
    "# Create the SVM classifier\n",
    "svm_classifier = SVC()\n",
    "\n",
    "# Train the SVM classifier on the training data\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = svm_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7425e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
