{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "576fc3a2",
   "metadata": {},
   "source": [
    "# Day 1 - Afternoon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d89bebd",
   "metadata": {},
   "source": [
    "# 1. Data Cleaning and Data Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a023dcbf",
   "metadata": {},
   "source": [
    "## 1.1 Introduction to Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a59673",
   "metadata": {},
   "source": [
    "Data cleaning, also known as data cleansing or data scrubbing, refers to the process of identifying and correcting or removing errors, inconsistencies, and inaccuracies in a dataset. It is an essential step in data preprocessing and analysis to ensure that the data is accurate, reliable, and suitable for further analysis or modeling.\n",
    "\n",
    "Data cleaning is important because real-world data is often imperfect. It can contain various issues such as missing values, duplicate records, incorrect formatting, inconsistent spellings, outliers, and more. These problems can arise due to human errors during data entry, technical glitches, or the integration of data from different sources.\n",
    "\n",
    "The primary objectives of data cleaning are as follows:\n",
    "\n",
    "1. **Removing or correcting errors:** Data cleaning involves identifying and addressing errors in the dataset. For example, it may involve fixing typos, resolving inconsistent date formats, or rectifying inaccurate numerical entries.\n",
    "\n",
    "\n",
    "2. **Handling missing data:** Missing data refers to the absence of values in certain records or attributes. Data cleaning techniques help in dealing with missing data, which may involve imputing missing values based on statistical methods or removing records with excessive missing data.\n",
    "\n",
    "\n",
    "3. **Handling duplicates:** Duplicates are identical or near-identical records that exist within a dataset. Data cleaning aims to identify and remove or merge duplicate records, ensuring that each unique entity is represented only once.\n",
    "\n",
    "\n",
    "4. **Standardizing and transforming data:** Inconsistent formatting, units, or scales can hinder data analysis. Data cleaning involves standardizing variables, converting units, and transforming data to ensure consistency and compatibility across the dataset.\n",
    "\n",
    "\n",
    "5. **Handling outliers:** Outliers are extreme values that deviate significantly from the typical pattern of the data. Data cleaning techniques help in identifying and dealing with outliers, which may involve removing them if they are due to data entry errors or handling them separately if they represent important observations.\n",
    "\n",
    "\n",
    "Data cleaning is typically performed using a combination of manual and automated techniques. It requires domain knowledge, data exploration, and the use of various data cleaning tools and algorithms.\n",
    "\n",
    "By performing effective data cleaning, analysts and data scientists can improve the quality of the data and enhance the accuracy and reliability of their subsequent analyses, predictive models, or decision-making processes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d71aabd",
   "metadata": {},
   "source": [
    "## 1.2 Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd534886",
   "metadata": {},
   "source": [
    "### 1.2.1 Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "65920588",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "04150d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'MLcmore2023' already exists and is not an empty directory.\r\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/MLcmore2023/MLcmore2023.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6ee81cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: no matches found: ./MLcmore2023/day1_pm_afternoon/*\r\n"
     ]
    }
   ],
   "source": [
    "!mv ./MLcmore2023/'day1_pm_afternoon'/* ./MLcmore2023/'day1_pm_afternoon'/.* ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4b13f60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Load Titanic dataset from seaborn\n",
    "titanic = pd.read_csv('titanic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d5ad72ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>pclass</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>boat</th>\n",
       "      <th>body</th>\n",
       "      <th>home.dest</th>\n",
       "      <th>survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1216</td>\n",
       "      <td>3</td>\n",
       "      <td>Smyth, Miss. Julia</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>335432</td>\n",
       "      <td>7.7333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>699</td>\n",
       "      <td>3</td>\n",
       "      <td>Cacic, Mr. Luka</td>\n",
       "      <td>male</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315089</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Croatia</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1267</td>\n",
       "      <td>3</td>\n",
       "      <td>Van Impe, Mrs. Jean Baptiste (Rosalie Paula Go...</td>\n",
       "      <td>female</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>345773</td>\n",
       "      <td>24.1500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>449</td>\n",
       "      <td>2</td>\n",
       "      <td>Hocking, Mrs. Elizabeth (Eliza Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>54.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>29105</td>\n",
       "      <td>23.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cornwall / Akron, OH</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>576</td>\n",
       "      <td>2</td>\n",
       "      <td>Veal, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28221</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Barre, Co Washington, VT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passenger_id  pclass                                               name  \\\n",
       "0          1216       3                                 Smyth, Miss. Julia   \n",
       "1           699       3                                    Cacic, Mr. Luka   \n",
       "2          1267       3  Van Impe, Mrs. Jean Baptiste (Rosalie Paula Go...   \n",
       "3           449       2              Hocking, Mrs. Elizabeth (Eliza Needs)   \n",
       "4           576       2                                    Veal, Mr. James   \n",
       "\n",
       "      sex   age  sibsp  parch  ticket     fare cabin embarked boat  body  \\\n",
       "0  female   NaN      0      0  335432   7.7333   NaN        Q   13   NaN   \n",
       "1    male  38.0      0      0  315089   8.6625   NaN        S  NaN   NaN   \n",
       "2  female  30.0      1      1  345773  24.1500   NaN        S  NaN   NaN   \n",
       "3  female  54.0      1      3   29105  23.0000   NaN        S    4   NaN   \n",
       "4    male  40.0      0      0   28221  13.0000   NaN        S  NaN   NaN   \n",
       "\n",
       "                  home.dest  survived  \n",
       "0                       NaN         1  \n",
       "1                   Croatia         0  \n",
       "2                       NaN         0  \n",
       "3      Cornwall / Akron, OH         1  \n",
       "4  Barre, Co Washington, VT         0  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display the dataframe\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa5d275",
   "metadata": {},
   "source": [
    "### 1.2.2 Explore the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "922fb5a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 850 entries, 0 to 849\n",
      "Data columns (total 15 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   passenger_id  850 non-null    int64  \n",
      " 1   pclass        850 non-null    int64  \n",
      " 2   name          850 non-null    object \n",
      " 3   sex           850 non-null    object \n",
      " 4   age           676 non-null    float64\n",
      " 5   sibsp         850 non-null    int64  \n",
      " 6   parch         850 non-null    int64  \n",
      " 7   ticket        850 non-null    object \n",
      " 8   fare          849 non-null    float64\n",
      " 9   cabin         191 non-null    object \n",
      " 10  embarked      849 non-null    object \n",
      " 11  boat          308 non-null    object \n",
      " 12  body          73 non-null     float64\n",
      " 13  home.dest     464 non-null    object \n",
      " 14  survived      850 non-null    int64  \n",
      "dtypes: float64(3), int64(5), object(7)\n",
      "memory usage: 99.7+ KB\n"
     ]
    }
   ],
   "source": [
    "titanic.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37aaf9d",
   "metadata": {},
   "source": [
    "The Titanic dataset is a historical dataset that contains information about the passengers aboard the RMS Titanic, which was a British passenger liner that sank on its maiden voyage in April 1912 after colliding with an iceberg. The dataset has been made available for public use and is commonly used as a learning resource for data analysis, data visualization, and machine learning tasks.\n",
    "\n",
    "The dataset provides a glimpse into the demographics and circumstances surrounding the passengers on the Titanic. It is often used to explore the factors that influenced survival rates and to build predictive models to determine the likelihood of a passenger surviving based on various features.\n",
    "\n",
    "The columns (features) in the dataset are as follows:\n",
    "\n",
    "1. PassengerId: An identifier for each passenger.\n",
    "2. Pclass: The ticket class of the passenger (1st, 2nd, or 3rd class).\n",
    "3. Name: The name of the passenger.\n",
    "4. Sex: The gender of the passenger (male or female).\n",
    "5. Age: The age of the passenger in years.\n",
    "6. SibSp: The number of siblings or spouses onboard the Titanic with the passenger.\n",
    "7. Parch: The number of parents or children onboard the Titanic with the passenger.\n",
    "8. Ticket: The ticket number.\n",
    "9. Fare: The passenger's fare or ticket price.\n",
    "10. Cabin: The cabin number of the passenger.\n",
    "11. Embarked: The port of embarkation (C = Cherbourg, Q = Queenstown, S = Southampton).\n",
    "12. Boat: The lifeboat number if the passenger survived and was rescued.\n",
    "13. Body: The body number if the passenger did not survive and their body was recovered.\n",
    "14. Home.dest: The home or destination of the passenger.\n",
    "15. Survived: This is the target variable and indicates whether the passenger survived or not. It is binary with 0 for not survived and 1 for survived.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ccfc576",
   "metadata": {},
   "source": [
    "## 1.2 Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbdc5cd",
   "metadata": {},
   "source": [
    "### 1.2.1 Removing or correcting errors\n",
    "1. **Removing or correcting errors:** Data cleaning involves identifying and addressing errors in the dataset. For example, it may involve fixing typos, resolving inconsistent date formats, or rectifying inaccurate numerical entries.\n",
    "\n",
    "\n",
    "Correcting errors in the \"sex\" column of a dataset\n",
    "\n",
    "df['column_name'] = df['column_name'].str.replace('incorrect_value', 'correct_value')\n",
    "\n",
    "### Example\n",
    "\n",
    "Changing \"errors\" in the \"sex\" column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "19b574f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    female\n",
       "1      male\n",
       "2    female\n",
       "3    female\n",
       "4      male\n",
       "Name: sex, dtype: object"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.sex[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "182c754c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# male -> M\n",
    "# female -> F\n",
    "titanic['sex'].replace('male', 'M', inplace=True)\n",
    "titanic['sex'].replace('female', 'F', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bd6660",
   "metadata": {},
   "source": [
    "the parameter `inplace=True` is used to specify that the replacement operation should be performed directly on the original DataFrame, modifying it in place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a820b013",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    F\n",
       "1    M\n",
       "2    F\n",
       "3    F\n",
       "4    M\n",
       "Name: sex, dtype: object"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.sex[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76359d9c",
   "metadata": {},
   "source": [
    "### 1.2.2 Handling missing data\n",
    "\n",
    "2. **Handling missing data:** Missing data refers to the absence of values in certain records or attributes. Data cleaning techniques help in dealing with missing data, which may involve imputing missing values based on statistical methods or removing records with excessive missing data.\n",
    "\n",
    "The first step is always to check missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "279dd79d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passenger_id      0\n",
      "pclass            0\n",
      "name              0\n",
      "sex               0\n",
      "age             174\n",
      "sibsp             0\n",
      "parch             0\n",
      "ticket            0\n",
      "fare              1\n",
      "cabin           659\n",
      "embarked          1\n",
      "boat            542\n",
      "body            777\n",
      "home.dest       386\n",
      "survived          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(titanic.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd3a33d",
   "metadata": {},
   "source": [
    "To fix missing data in a column, you can use various techniques depending on the nature of the missing values. Here are a few common approaches:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1fcfd2",
   "metadata": {},
   "source": [
    "### 1.2.3 Removing missing values:\n",
    "\n",
    "- If the missing values are relatively few and randomly distributed, you may choose to remove the rows or columns with missing values.\n",
    "- Use the **dropna()** method in pandas to drop rows or columns with missing values. For example: **df.dropna().**\n",
    "\n",
    "### Example\n",
    "drop the row with nan value in “embarked” column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "eef01336",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.dropna(subset=['embarked'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a51df697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passenger_id      0\n",
      "pclass            0\n",
      "name              0\n",
      "sex               0\n",
      "age             174\n",
      "sibsp             0\n",
      "parch             0\n",
      "ticket            0\n",
      "fare              1\n",
      "cabin           659\n",
      "embarked          0\n",
      "boat            542\n",
      "body            776\n",
      "home.dest       385\n",
      "survived          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Now, the row with missing value in embarked column has been dropped\n",
    "print(titanic.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1051b83b",
   "metadata": {},
   "source": [
    "### 1.2.4 Imputing missing values:\n",
    "\n",
    "- If the missing values follow a certain pattern or have a relationship with other variables, you can fill them in with estimated or imputed values.\n",
    "- Use the **fillna()** method in pandas to fill missing values with a specific value, mean, median, or any other desired imputation method. For example: **df['column_name'].fillna(value)**.\n",
    "\n",
    "### Example\n",
    "Filling missing values with median age in \"age\" column:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "20f5c35e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.0"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = titanic['age'].median()\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "84350ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic['age'] = titanic['age'].replace(np.nan, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "605affa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passenger_id      0\n",
      "pclass            0\n",
      "name              0\n",
      "sex               0\n",
      "age               0\n",
      "sibsp             0\n",
      "parch             0\n",
      "ticket            0\n",
      "fare              1\n",
      "cabin           659\n",
      "embarked          0\n",
      "boat            542\n",
      "body            776\n",
      "home.dest       385\n",
      "survived          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(titanic.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba02e71",
   "metadata": {},
   "source": [
    "### 1.2.5 Handling duplicates:\n",
    "3. **Handling duplicates:** Duplicates are identical or near-identical records that exist within a dataset. Data cleaning aims to identify and remove or merge duplicate records, ensuring that each unique entity is represented only once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "a2c068cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the original dataset does not contain any duplicates,\n",
    "# for educational purposes, I manually added some duplicates.\n",
    "\n",
    "# Select the row(s) to duplicate\n",
    "row_to_duplicate = titanic.loc[0]\n",
    "\n",
    "# Append the row(s) to create duplicates\n",
    "titanic = titanic.append([row_to_duplicate, row_to_duplicate], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6265ced",
   "metadata": {},
   "source": [
    "ignore_index=True ensures that the resulting DataFrame has a new sequential index starting from 0, regardless of the original index values in the appended rows.\n",
    "\n",
    "#### Example\n",
    "Remove the deplicated which I created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d2c83b4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>pclass</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>boat</th>\n",
       "      <th>body</th>\n",
       "      <th>home.dest</th>\n",
       "      <th>survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>849</th>\n",
       "      <td>1216</td>\n",
       "      <td>3</td>\n",
       "      <td>Smyth, Miss. Julia</td>\n",
       "      <td>F</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>335432</td>\n",
       "      <td>7.7333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850</th>\n",
       "      <td>1216</td>\n",
       "      <td>3</td>\n",
       "      <td>Smyth, Miss. Julia</td>\n",
       "      <td>F</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>335432</td>\n",
       "      <td>7.7333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     passenger_id  pclass                name sex   age  sibsp  parch  ticket  \\\n",
       "849          1216       3  Smyth, Miss. Julia   F  28.0      0      0  335432   \n",
       "850          1216       3  Smyth, Miss. Julia   F  28.0      0      0  335432   \n",
       "\n",
       "       fare cabin embarked boat  body home.dest  survived  \n",
       "849  7.7333   NaN        Q   13   NaN       NaN         1  \n",
       "850  7.7333   NaN        Q   13   NaN       NaN         1  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find duplicates in the DataFrame\n",
    "duplicates = titanic.duplicated()\n",
    "duplicate_rows = titanic[duplicates]\n",
    "duplicate_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "334becba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all the duplicates\n",
    "titanic.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d98374b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>pclass</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>boat</th>\n",
       "      <th>body</th>\n",
       "      <th>home.dest</th>\n",
       "      <th>survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [passenger_id, pclass, name, sex, age, sibsp, parch, ticket, fare, cabin, embarked, boat, body, home.dest, survived]\n",
       "Index: []"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now, the duplicates are gone\n",
    "duplicates = titanic.duplicated()\n",
    "duplicate_rows = titanic[duplicates]\n",
    "duplicate_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7cb40dd",
   "metadata": {},
   "source": [
    "### 1.2.6 Standardization & Normalization:\n",
    "\n",
    "**Standardization** scales the data to have a mean of 0 and a standard deviation of 1. It is performed using the formula:\n",
    "\n",
    "z= x−μ/σ\n",
    "\n",
    "where:\n",
    "\n",
    "- z is the standardized value,\n",
    "- x is the original value,\n",
    "- μ is the mean of the feature,\n",
    "- σ is the standard deviation of the feature.\n",
    " \n",
    "**Normalization** scales the data to a range between 0 and 1. It is performed using the formula:\n",
    "\n",
    "x_normalized = (x- x_max)/(x_max - x_min)\n",
    "\n",
    "where:\n",
    "\n",
    "- x_normalized is the normalized value,\n",
    "- x is the original value,\n",
    "- x_min is the minimum value of the feature\n",
    "- x_max is the maximum value of the feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "f8bd3ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# Assume 'data' is your DataFrame containing the Titanic dataset\n",
    "# Replace 'data' with the actual DataFrame name in your code\n",
    "\n",
    "# Standardization\n",
    "age_values = titanic['age'].values.reshape(-1, 1)\n",
    "scaler = StandardScaler()\n",
    "age_standardized = scaler.fit_transform(age_values)\n",
    "\n",
    "# Create a new DataFrame with the standardized 'Age' column\n",
    "data_standardized = titanic.copy()\n",
    "data_standardized['age_standardized'] = age_standardized\n",
    "\n",
    "# Normalization\n",
    "scaler = MinMaxScaler()\n",
    "age_normalized = scaler.fit_transform(age_values)\n",
    "\n",
    "# Create a new DataFrame with the normalized 'Age' column\n",
    "data_normalized = titanic.copy()\n",
    "data_normalized['age_normalized'] = age_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "10abf0da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>pclass</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>boat</th>\n",
       "      <th>body</th>\n",
       "      <th>home.dest</th>\n",
       "      <th>survived</th>\n",
       "      <th>age_standardized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1216</td>\n",
       "      <td>3</td>\n",
       "      <td>Smyth, Miss. Julia</td>\n",
       "      <td>F</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>335432</td>\n",
       "      <td>7.7333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.092214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>699</td>\n",
       "      <td>3</td>\n",
       "      <td>Cacic, Mr. Luka</td>\n",
       "      <td>M</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315089</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Croatia</td>\n",
       "      <td>0</td>\n",
       "      <td>0.677282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1267</td>\n",
       "      <td>3</td>\n",
       "      <td>Van Impe, Mrs. Jean Baptiste (Rosalie Paula Go...</td>\n",
       "      <td>F</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>345773</td>\n",
       "      <td>24.1500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.061685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>449</td>\n",
       "      <td>2</td>\n",
       "      <td>Hocking, Mrs. Elizabeth (Eliza Needs)</td>\n",
       "      <td>F</td>\n",
       "      <td>54.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>29105</td>\n",
       "      <td>23.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cornwall / Akron, OH</td>\n",
       "      <td>1</td>\n",
       "      <td>1.908476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>576</td>\n",
       "      <td>2</td>\n",
       "      <td>Veal, Mr. James</td>\n",
       "      <td>M</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28221</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Barre, Co Washington, VT</td>\n",
       "      <td>0</td>\n",
       "      <td>0.831181</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passenger_id  pclass                                               name  \\\n",
       "0          1216       3                                 Smyth, Miss. Julia   \n",
       "1           699       3                                    Cacic, Mr. Luka   \n",
       "2          1267       3  Van Impe, Mrs. Jean Baptiste (Rosalie Paula Go...   \n",
       "3           449       2              Hocking, Mrs. Elizabeth (Eliza Needs)   \n",
       "4           576       2                                    Veal, Mr. James   \n",
       "\n",
       "  sex   age  sibsp  parch  ticket     fare cabin embarked boat  body  \\\n",
       "0   F  28.0      0      0  335432   7.7333   NaN        Q   13   NaN   \n",
       "1   M  38.0      0      0  315089   8.6625   NaN        S  NaN   NaN   \n",
       "2   F  30.0      1      1  345773  24.1500   NaN        S  NaN   NaN   \n",
       "3   F  54.0      1      3   29105  23.0000   NaN        S    4   NaN   \n",
       "4   M  40.0      0      0   28221  13.0000   NaN        S  NaN   NaN   \n",
       "\n",
       "                  home.dest  survived  age_standardized  \n",
       "0                       NaN         1         -0.092214  \n",
       "1                   Croatia         0          0.677282  \n",
       "2                       NaN         0          0.061685  \n",
       "3      Cornwall / Akron, OH         1          1.908476  \n",
       "4  Barre, Co Washington, VT         0          0.831181  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first few rows of the standardized and normalized DataFrames\n",
    "data_standardized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "27b37400",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>pclass</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>boat</th>\n",
       "      <th>body</th>\n",
       "      <th>home.dest</th>\n",
       "      <th>survived</th>\n",
       "      <th>age_normalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1216</td>\n",
       "      <td>3</td>\n",
       "      <td>Smyth, Miss. Julia</td>\n",
       "      <td>F</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>335432</td>\n",
       "      <td>7.7333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.348643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>699</td>\n",
       "      <td>3</td>\n",
       "      <td>Cacic, Mr. Luka</td>\n",
       "      <td>M</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315089</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Croatia</td>\n",
       "      <td>0</td>\n",
       "      <td>0.473904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1267</td>\n",
       "      <td>3</td>\n",
       "      <td>Van Impe, Mrs. Jean Baptiste (Rosalie Paula Go...</td>\n",
       "      <td>F</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>345773</td>\n",
       "      <td>24.1500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.373695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>449</td>\n",
       "      <td>2</td>\n",
       "      <td>Hocking, Mrs. Elizabeth (Eliza Needs)</td>\n",
       "      <td>F</td>\n",
       "      <td>54.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>29105</td>\n",
       "      <td>23.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cornwall / Akron, OH</td>\n",
       "      <td>1</td>\n",
       "      <td>0.674321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>576</td>\n",
       "      <td>2</td>\n",
       "      <td>Veal, Mr. James</td>\n",
       "      <td>M</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28221</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Barre, Co Washington, VT</td>\n",
       "      <td>0</td>\n",
       "      <td>0.498956</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passenger_id  pclass                                               name  \\\n",
       "0          1216       3                                 Smyth, Miss. Julia   \n",
       "1           699       3                                    Cacic, Mr. Luka   \n",
       "2          1267       3  Van Impe, Mrs. Jean Baptiste (Rosalie Paula Go...   \n",
       "3           449       2              Hocking, Mrs. Elizabeth (Eliza Needs)   \n",
       "4           576       2                                    Veal, Mr. James   \n",
       "\n",
       "  sex   age  sibsp  parch  ticket     fare cabin embarked boat  body  \\\n",
       "0   F  28.0      0      0  335432   7.7333   NaN        Q   13   NaN   \n",
       "1   M  38.0      0      0  315089   8.6625   NaN        S  NaN   NaN   \n",
       "2   F  30.0      1      1  345773  24.1500   NaN        S  NaN   NaN   \n",
       "3   F  54.0      1      3   29105  23.0000   NaN        S    4   NaN   \n",
       "4   M  40.0      0      0   28221  13.0000   NaN        S  NaN   NaN   \n",
       "\n",
       "                  home.dest  survived  age_normalized  \n",
       "0                       NaN         1        0.348643  \n",
       "1                   Croatia         0        0.473904  \n",
       "2                       NaN         0        0.373695  \n",
       "3      Cornwall / Akron, OH         1        0.674321  \n",
       "4  Barre, Co Washington, VT         0        0.498956  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_normalized.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5558f0",
   "metadata": {},
   "source": [
    "**Why do we use standardization and normalization?**\n",
    "\n",
    "1. **Improving Model Performance:** Many machine learning algorithms work better or converge faster when the input features have a similar scale. Features with significantly different scales can dominate the learning process, leading to suboptimal performance.\n",
    "\n",
    "2. **Interpretability and Comparisons:** Standardizing or normalizing the data ensures that all the features are in comparable units, making it easier to interpret the importance and effect of different features. It also allows for more meaningful comparisons between different features.\n",
    "\n",
    "3. **Regularization:** Some regularization techniques, like L1 and L2 regularization, penalize large values in the input features. Standardization and normalization can prevent certain features from being disproportionately penalized during model training.\n",
    "\n",
    "4. **Distance-Based Algorithms:** When using distance-based algorithms, such as k-nearest neighbors (KNN) or clustering algorithms, it is crucial to scale the features appropriately to ensure that distances are not dominated by a single feature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee3be0c",
   "metadata": {},
   "source": [
    "### 1.2.7 Handling Outliers\n",
    "\n",
    "5. **Handling outliers:** Outliers are extreme values that deviate significantly from the typical pattern of the data. Data cleaning techniques help in identifying and dealing with outliers, which may involve removing them if they are due to data entry errors or handling them separately if they represent important observations.\n",
    "\n",
    "### Example\n",
    "\n",
    "There is one outlier with person that survived with an overwhelming fare that is around 500.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "205b7d4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7MAAAHcCAYAAAAEI/3JAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAjk0lEQVR4nO3df7Ddd33n99dbugoYq6HmYnuEwRHNdTeFdULji7tJpiRLpKDEBdN02PVuNr7t0KHTGNuZ2c4WghPLY5FNk06n2A3ZZVqaq91uiNlmByf2XJDsZrLtZgISSyoMAd8JMvhHJe/dJiDbEO7Vp3/oiF4J6drH1rnf+9F9PGY093y+53uu3vJ4dPS8n3O+p1prAQAAgJ5sGXoAAAAAGJeYBQAAoDtiFgAAgO6IWQAAALojZgEAAOiOmAUAAKA7U0MP8FK8+tWvbjt37hx6DAAAACbg8OHD/6a1dvm57us6Znfu3JlDhw4NPQYAAAATUFWPne8+LzMGAACgO2IWAACA7ohZAAAAuiNmAQAA6I6YBQAAoDtiFgAAgO6IWQAAALojZgEAAOiOmAUAAKA7YhYAAIDuiFkAAAC6I2YBAADojpgFAACgO2IWAADWcOjQobz1rW/N4cOHhx4FWEXMAgDAGvbu3ZuTJ0/mzjvvHHoUYBUxCwAA53Ho0KGcOHEiSXLixAm7s7CBiFkAADiPvXv3nrG2Owsbh5gFAIDzOL0re741MBwxCwAA57F9+/Y118BwxCwAAJzH2S8zvuuuu4YZBPguYhYAAM5jdnb2O7ux27dvz3XXXTfwRMBpYhYAANawd+/ebNmyxa4sbDBTQw8AAAAb2ezsbB5++OGhxwDOMtGd2ao6WlVHqupzVXVodOxVVXWgqh4dfb1s1fnvr6rFqvpSVb1tkrMBAADQr/V4mfHfbK29qbU2O1q/L8lDrbVrkjw0Wqeq3pDkpiRvTLInyYeraus6zAcAAEBnhnjP7I1J5ke355O8c9Xxj7XWvtVa+0qSxSTXr/94AAAAbHSTjtmW5FNVdbiq3jM6dmVr7akkGX29YnT8qiRfW/XYx0fHAAAA4AyTvgDUj7XWnqyqK5IcqKo/W+PcOsex9l0nnYri9yTJ1VdffWGmBAAAoCsT3ZltrT05+no8yb/IqZcNH6uqHUky+np8dPrjSV636uGvTfLkOb7nR1prs6212csvv3yS4wMAALBBTSxmq+rSqvp3Tt9O8lNJPp/k/iRzo9PmknxidPv+JDdV1cuq6vVJrkny6UnNBwAAQL8m+TLjK5P8i6o6/fv8s9baQlV9Jsl9VfXuJF9N8q4kaa09UlX3JflCkuUkt7TWViY4HwAAAJ2aWMy21v48yQ+d4/hSkp88z2M+mOSDk5oJAACAi8MQH80DAAAAL4mYBQAAoDtiFgAAgO6IWQAAALojZgEAAOiOmAUAAKA7YhYAAIDuiFkAAAC6I2YBAADojpgFAACgO2IWAACA7ohZAAAAuiNmAQAA6I6YBQAAoDtiFgAAgO6IWQAAALojZgEAAOiOmAUAAKA7YhYAAIDuiFkAAAC6I2YBAADojpgFAACgO2IWAACA7ohZAAAAuiNmAQAA6I6YBQAAoDtiFgAAgO6IWQAAALojZgEAAOiOmAUAAKA7YhYAAIDuiFkAAAC6I2YBAADojpgFAACgO2IWAACA7ohZAAAAuiNmAQAA6I6YBQAAoDtiFgAAgO6IWQAAALojZgEAAOiOmAUAAKA7YhYAAIDuiFkAAAC6I2YBAADojpgFAACgO2IWAACA7ohZAAAAuiNmAQAA6I6YBQAAoDtiFgAAgO6IWQAAALojZgEAAOiOmAUAAKA7YhYAAIDuiFkAAAC6I2YBAADojpgFAACgO2IWAACA7ohZAAAAuiNmAQAA6I6YBQAAoDtiFgAAgO6IWQAAALojZgEAAOiOmAUAAKA7YhYAAIDuiFkAAAC6I2YBAADozsRjtqq2VtW/rqo/GK1fVVUHqurR0dfLVp37/qparKovVdXbJj0bAAAAfVqPndnbk3xx1fp9SR5qrV2T5KHROlX1hiQ3JXljkj1JPlxVW9dhPgAAADoz0ZitqtcmuSHJ/7zq8I1J5ke355O8c9Xxj7XWvtVa+0qSxSTXT3I+AAAA+jTpndn/Mck/SHJy1bErW2tPJcno6xWj41cl+dqq8x4fHTtDVb2nqg5V1aGnn356IkMDAACwsU0sZqvqP0lyvLV2+IU+5BzH2ncdaO0jrbXZ1trs5Zdf/pJmBAAAoE9TE/zeP5bkHVX1M0lenuR7q+qfJjlWVTtaa09V1Y4kx0fnP57kdase/9okT05wPgAAADo1sZ3Z1tr7W2uvba3tzKkLOz3cWvt7Se5PMjc6bS7JJ0a3709yU1W9rKpen+SaJJ+e1HwAAAD0a5I7s+fza0nuq6p3J/lqknclSWvtkaq6L8kXkiwnuaW1tjLAfAAAAGxw1dp3vS21G7Ozs+3QoUNDjwEAAMAEVNXh1trsue5bj8+ZBQAAgAtKzAIAANAdMQsAAEB3xCwAAADdEbMAAAB0R8wCAADQHTELAABAd8QsAAAA3RGzAAAAdEfMAgAA0B0xCwAAQHfELAAAAN0RswAAAHRHzAIAANAdMQsAAEB3xCwAAADdEbMAAAB0R8wCAADQHTELAABAd8QsAAAA3RGzAAAAdEfMAgAA0B0xCwAAQHfELAAAAN0RswAAAHRHzAIAANAdMQsAAEB3xCwAAADdEbMAAAB0R8wCAADQHTELAABAd8QsAAAA3RGzAAAAdEfMAgAA0B0xCwAAQHfELAAAAN0RswAAAHRHzAIAANAdMQsAAEB3xCwAAADdEbMAAAB0R8wCAADQHTELAABAd8QsAAAA3RGzAAAAdEfMAgAA0B0xCwAAQHfELAAAAN0RswAAAHRHzAIAANAdMQsAAEB3xCwAAADdEbMAAAB0R8wCAADQHTELAABAd8QsAAAA3RGzAAAAdEfMAgAA0B0xCwAAQHfELAAAAN0RswAAAHRHzAIAANAdMQsAAEB3xCwAAADdEbMAAAB0R8wCAADQHTELAABAd8QsAAAA3ZlYzFbVy6vq01X1p1X1SFXdNTr+qqo6UFWPjr5etuox76+qxar6UlW9bVKzAQAA0LdJ7sx+K8lbW2s/lORNSfZU1d9I8r4kD7XWrkny0GidqnpDkpuSvDHJniQfrqqtE5wPAACATk0sZtspJ0bLbaNfLcmNSeZHx+eTvHN0+8YkH2utfau19pUki0mun9R8AAAA9Gui75mtqq1V9bkkx5McaK39SZIrW2tPJcno6xWj069K8rVVD398dOzs7/meqjpUVYeefvrpSY4PAADABjXRmG2trbTW3pTktUmur6q/vsbpda5vcY7v+ZHW2mxrbfbyyy+/QJMCAADQk3W5mnFr7S+S/GFOvRf2WFXtSJLR1+Oj0x5P8rpVD3ttkifXYz4AAAD6MsmrGV9eVf/u6PYlSXYl+bMk9yeZG502l+QTo9v3J7mpql5WVa9Pck2ST09qPgAAAPo1NcHvvSPJ/OiKxFuS3Nda+4Oq+uMk91XVu5N8Ncm7kqS19khV3ZfkC0mWk9zSWluZ4HwAAAB0qlr7rreldmN2drYdOnRo6DEAAACYgKo63FqbPdd96/KeWQAAALiQxCwAAADdEbMAAAB0R8wCAADQHTELAABAd8QsAAAA3RGzAAAAdEfMAgAA0B0xCwAAQHfELAAAAN0RswAAAHRHzAIAANAdMQsAAEB3xCwAAADdEbMAAAB0R8wCAADQHTELAABAd8QsAAAA3RGzAAAAdEfMAmNbWlrKbbfdlqWlpaFHAYCJu+eee/ITP/ET+c3f/M2hRwFWEbPA2Obn53PkyJHs379/6FEAYOJ+7/d+L0ny8Y9/fOBJgNVeUMxW1SVV9dcmPQyw8S0tLWVhYSGttSwsLNidBeCids8995yxtjsLG8fzxmxVvT3J55IsjNZvqqr7JzwXsEHNz8/n5MmTSZKVlRW7swBc1E7vyp5mdxY2jheyM7s3yfVJ/iJJWmufS7JzUgMBG9vBgwezvLycJFleXs6BAwcGnggAgM3ohcTscmvtLyc+CdCFXbt2ZWpqKkkyNTWV3bt3DzwRAACb0QuJ2c9X1d9NsrWqrqmqe5P8qwnPBWxQc3Nz2bLl1F8dW7duzc033zzwRAAwOT/7sz97xvpd73rXQJMAZ3shMXtrkjcm+VaSf5bkL5P84gRnAjaw6enp7NmzJ1WVPXv2ZHp6euiRAGBibrvttjPWt9xyy0CTAGdbM2aramuS+1trH2itvXn0647W2jfXaT5gA5qbm8u1115rVxaATeH07qxdWdhYqrW29gmnrlz88xvxfbOzs7Pt0KFDQ48BAADABFTV4dba7Lnum3oBj/9mkiNVdSDJM6cPttZuO/9DAAAAYHJeSMw+MPoFAAAAG8LzxmxrbX49BgEAgI1oaWkpd911V+68804XPoQN5HmvZjz6OJ5/XlVfqKo/P/1rPYYDAIChzc/P58iRI9m/f//QowCrvJCP5vlfk/xWkuUkfzPJ/iT/ZJJDAQDARrC0tJSFhYW01rKwsJClpaWhRwJGXkjMXtJaeyinrnz8WGttb5K3TnYsAAAY3vz8fE6ePJkkWVlZsTsLG8gLidlvVtWWJI9W1Xur6j9NcsWE5wIAgMEdPHgwy8vLSZLl5eUcOHBg4ImA084bs1V1+qXEn0jyiiS3Jbkuyc8nmZv8aAAAMKxdu3ZlaurUNVOnpqaye/fugScCTltrZ/a6qvq+JD+XZFuSZ5P8/ST/ZZIvr8NsAAAwqLm5uWzZcuqfzFu3bs3NN9888ETAaWvF7D9KspDkB5IcHv06tOorAABc1Kanp7Nnz55UVfbs2eOjeWADOe/nzLbW7klyT1X9Vmvtv17HmQAAYMOYm5vL0aNH7crCBlOttaFneNFmZ2fboUM2iQEAAC5GVXW4tTZ7rvteyNWMAQAAYEMRswAAAHRHzAIAANAdMQsAAEB3xCwAAADdEbPA2BYXF3PDDTdkcXFx6FEAYOI878HGJGaBse3bty/PPPNM9u3bN/QoADBxnvdgYxKzwFgWFxdz9OjRJMnRo0f9lBqAi5rnPdi4xCwwlrN/Ku2n1ABczDzvwcYlZoGxnP7p9PnWAHAx8bwHG5eYBcayc+fONdcAcDHxvAcbl5gFxnLHHXesuQaAi4nnPdi4xCwAAJzHZZddlqpKklRVLrvssoEnAk4Ts8BYXAgDgM1kfn4+W7ac+ifzli1bsn///oEnAk4Ts8BYXAgDgM3k4MGDWVlZSZKsrKzkwIEDA08EnCZmgbG4EAYAm8muXbsyNTWVJJmamsru3bsHngg4TcwCY3EhDAA2k7m5ue+8zHjr1q25+eabB54IOE3MAmOZmZnJFVdckSS58sorMzMzM/BEADA509PT+dEf/dEkyY/8yI9kenp64ImA08QsMLYTJ04kSb7xjW8MPAkATN4XvvCFJMkXv/jFgScBVhOzwFgOHTqUZ599Nkny7LPP5vDhwwNPBACTs7i4mOPHjydJjh07lsXFxYEnAk4Ts8BY9u7de8b6zjvvHGYQAFgHv/zLv3zG+ld+5VcGmgQ4m5gFxnL6JcbnWwPAxeSpp546Y/3kk08ONAlwNjELjGX79u1rrgEAYD2IWWAsZ7/M+K677hpmEABYBzt27FhzDQxHzAJjmZ2d/c5u7Pbt23PdddcNPBEATM7dd9+95hoYjpgFxrZ3795s2bLFriwAF72ZmZnv7Mbu2LHD56vDBiJmgbHNzs7m4YcftisLwKZw991359JLL7UrCxvMxGK2ql5XVf9HVX2xqh6pqttHx19VVQeq6tHR18tWPeb9VbVYVV+qqrdNajYAAHihZmZm8sADD9iVhQ1mkjuzy0n+fmvtP0jyN5LcUlVvSPK+JA+11q5J8tBondF9NyV5Y5I9ST5cVVsnOB8AAACdmljMttaeaq19dnT7G0m+mOSqJDcmmR+dNp/knaPbNyb5WGvtW621ryRZTHL9pOYDAACgX+vyntmq2pnkP0zyJ0mubK09lZwK3iRXjE67KsnXVj3s8dGxs7/Xe6rqUFUdevrppyc6NwAAABvTxGO2qrYn+d+T/GJr7etrnXqOY+27DrT2kdbabGtt9vLLL79QYwIAANCRicZsVW3LqZD931prvzc6fKyqdozu35Hk+Oj440let+rhr03y5CTnAwAAoE+TvJpxJflfknyxtfY/rLrr/iRzo9tzST6x6vhNVfWyqnp9kmuSfHpS8wEAANCvqQl+7x9L8vNJjlTV50bHfinJryW5r6reneSrSd6VJK21R6rqviRfyKkrId/SWluZ4HwAAAB0amIx21r7P3Pu98EmyU+e5zEfTPLBSc0EAADAxWFdrmYMAAAAF5KYBQAAoDtiFgAAgO6IWQAAALojZgEAAOiOmAUAAKA7YhYAAIDuiFkAAAC6I2YBAADojpgFAACgO2IWAACA7ohZAAAAuiNmAQAA6I6YBQAAoDtiFgAAgO6IWQAAALojZgEAAOiOmAXGtrS0lNtuuy1LS0tDjwIAE7e4uJgbbrghi4uLQ48CrCJmgbHNz8/nyJEj2b9//9CjAMDE7du3L88880z27ds39CjAKmIWGMvS0lIWFhbSWsvCwoLdWQAuaouLizl69GiS5OjRo3ZnYQMRs8BY5ufnc/LkySTJysqK3VkALmpn78banYWNQ8wCYzl48GCWl5eTJMvLyzlw4MDAEwHA5JzelT3fGhiOmAXGsmvXrkxNTSVJpqamsnv37oEnAoDJ2blz55prYDhiFhjL3Nxctmw59VfH1q1bc/PNNw88EQBMzh133LHmGhiOmAXGMj09nT179qSqsmfPnkxPTw89EgBMzMzMzHd2Y3fu3JmZmZlhBwK+Q8wCY5ubm8u1115rVxaATeGOO+7IpZdealcWNhgxCwAAa7jsssvy/d///bnsssuGHgVYRcwCY5ufn8+RI0d8LA8Am4LnPdiYxCwwlqWlpTzwwANpreWBBx7I0tLS0CMBwMQsLS3lwQcfTGstDz74oOc92EDELDCW+fn5rKysJDn1ObN+Sg3AxWx+fv47n6/+7W9/2/MebCBiFhjLJz/5yTPWCwsLA00CAJP3qU996oz12c+DwHDELDCW07uy51sDwMVkampqzTUwHDELjOX0S63OtwaAi8mJEyfWXAPDEbPAWLZv377mGgAuJjt37lxzDQxHzAJj2bt37xnru+66a5hBAGAdvPe97z1jfeuttw40CXA2MQuMZXZ29ju7sdu3b89111038EQAMDl/9Ed/tOYaGI6YBca2d+/ebNmyxa4sABe9gwcPnrE+cODAQJMAZxOzwNhmZ2fz8MMP25UF4KK3a9eu71zBeGpqKrt37x54IuA0MQsAAOcxNzeXLVtO/ZN569atufnmmweeCDhNzAIAwHlMT09nz549qars2bMn09PTQ48EjIhZYGxLS0u57bbbsrS0NPQoADBxb3nLW1JVectb3jL0KMAqYhYY2/z8fI4cOZL9+/cPPQoATNxv/MZv5OTJk/n1X//1oUcBVhGzwFiWlpaysLCQ1loWFhbszgJwUVtcXMyxY8eSJMeOHcvi4uLAEwGniVlgLPPz8zl58mSSZGVlxe4sABe1D3zgA2uugeGIWWAsBw8ezPLycpJkeXnZ5+0BcFE7vSt7vjUwHDELjMXn7QEAsBGIWWAsPm8PgM3kkksuWXMNDEfMAmPxeXsAbCZ33333Get9+/YNNAlwtqmhBwD6Mzc3l6NHj9qVBeCiNzs7m0suuSTPPfdcLrnkklx33XVDjwSM2JkFxjY9PZ177rnHriwAm8Ldd9+dLVu22JWFDcbOLAAArGF2djYPP/zw0GMAZ7EzCwAAQHfELAAAAN0RswAAAHRHzAIAANAdF4ACAOjYvffem8XFxaHHuKg98cQTSZKrrrpq4EkubjMzM7n11luHHoOOiFkAAFjDc889N/QIwDmIWWBsS0tLueuuu3LnnXf6rFmAgdnJmrzbb789SfKhD31o4EmA1bxnFhjb/Px8jhw5kv379w89CgAAm5SYBcaytLSUhYWFtNaysLCQpaWloUcCAGATErPAWObn53Py5MkkycrKit1ZAAAGIWaBsRw8eDDLy8tJkuXl5Rw4cGDgiQAA2IzELDCWXbt2paqSJFWV3bt3DzwRAACbkZgFxvKOd7wjrbUkSWstb3/72weeCACAzUjMAmO5//77z1j//u///kCTAACwmYlZYCxnv0f2U5/61ECTAACwmYlZYCxXXnnlmmsAAFgPYhYYy7Fjx9ZcAwDAephYzFbVR6vqeFV9ftWxV1XVgap6dPT1slX3vb+qFqvqS1X1tknNBbw0u3fvPuNqxj/1Uz818EQAAGxGk9yZ/e0ke8469r4kD7XWrkny0GidqnpDkpuSvHH0mA9X1dYJzga8SHNzc9m2bVuSZNu2bbn55psHnggAgM1oYjHbWvujJP/2rMM3Jpkf3Z5P8s5Vxz/WWvtWa+0rSRaTXD+p2YAXb3p6Onv27ElV5ad/+qczPT099EgAAGxC6/2e2Stba08lyejrFaPjVyX52qrzHh8d+y5V9Z6qOlRVh55++umJDguc29zcXK699lq7sgAADGajXACqznGsnevE1tpHWmuzrbXZyy+/fMJjAecyPT2de+65x64sAACDWe+YPVZVO5Jk9PX46PjjSV636rzXJnlynWcDXqDFxcXccMMNWVxcHHoUAAA2qfWO2fuTzI1uzyX5xKrjN1XVy6rq9UmuSfLpdZ4NeIH27duXZ555Jvv27Rt6FAAANqlJfjTP7yT54yR/raoer6p3J/m1JLur6tEku0frtNYeSXJfki8kWUhyS2ttZVKzAS/e4uJijh49miQ5evSo3VkAAAYxNalv3Fr7O+e56yfPc/4Hk3xwUvMAF8bZu7H79u3Lb//2bw8zDAAAm9ZGuQAU0InTu7LnWwMAwHoQs8BYdu7cueYaAADWg5gFxnLHHXesuQYAgPUgZoGxzMzMZMeOHUmS17zmNZmZmRl4IgAANiMxC4xtZeXUxcaXl5cHngQAgM1KzAJjWVxczPHjx5Mkx48f99E8AAAMQswCY9m7d++aawAAWA9iFhjL448/vuYaAADWg5gFxlJVa64BAGA9iFlgLNdee+0Z6x/8wR8caBIAADYzMQuM5dFHHz1j/eUvf3mgSQAA2MzELDCW5557bs01AACsBzELAABAd8QsAAAA3RGzAAAAdEfMAgAA0B0xCwAAQHfELAAAAN0RswAAAHRHzAIAANAdMQuMparWXAMAwHoQs8BYtmzZsuYaAADWg3+FAmN585vffMb6+uuvH2gSAAA2MzELjOWxxx5bcw0AAOtBzAJjeeqpp85YP/nkkwNNAgDAZiZmAQAA6M7U0AMAfdmyZUtOnjx5xhrgXO69994sLi4OPQa8ZKf/P7799tsHngRempmZmdx6661Dj3HBiFlgLC9/+cvz7LPPnrEGOJfFxcU8+si/ztXbV4YeBV6S7/n2qR/cfuuxQwNPAi/eV09sHXqEC07MAmNZHbLnWgOsdvX2lfzSD3996DEANr1f/ez3Dj3CBef1gcBYqmrNNQAArAcxC4zlx3/8x9dcAwDAevAyYy4qLjYyed/+9rfPWB8/ftwFMSbkYrtIAwDAhWRnFhjLtm3bsnXrqQsIvPKVr8y2bdsGnggAgM3IziwXFbtY6+MXfuEX8thjj+WjH/1opqenhx4HAIBNyM4sMLZt27ZlZmZGyAIAMBgxCwAAQHfELAAAAN0RswAAAHRHzAIAANAdMQsAAEB3xCwAAADdEbMAAAB0R8wCAADQHTELAABAd8QsAAAA3RGzAAAAdEfMAgAA0B0xCwAAQHfELAAAAN0RswAAAHRHzAIAANCdqaEH2EzuvffeLC4uDj0GvGSn/z++/fbbB54EXpqZmZnceuutQ49x0XriiSfyzDe25lc/+71DjwKw6T32ja259Iknhh7jghKz62hxcTGf+/wXs/KKVw09CrwkW/6qJUkO//mxgSeBF2/rs/926BEAgJdAzK6zlVe8Ks/9wM8MPQbApnfJnz049AgXvauuuirfWn4qv/TDXx96FIBN71c/+7152VVXDT3GBeU9swAAAHRHzAIAANAdMQsAAEB3xCwAAADdEbMAAAB0R8wCAADQHTELAABAd3zOLAAwMV89sTW/+tnvHXoMeEmOPXtq/+fKV5wceBJ48b56YmuuGXqIC0zMAgATMTMzM/QIcEH81eJikuRl3+f/afp1TS6+v5fF7Dp64oknsvXZv8wlf/bg0KMAbHpbn13KE08sDz3GRe3WW28degS4IG6//fYkyYc+9KGBJwFW855ZAAAAuiNm19FVV12VpIYeA16yLd/8erZ88+tDjwEvUY3+XgYAeuRlxuvoYnuNOpvX4uI3kiQz/96VA08CL8WV/l4GgI6J2XXkvUNcLLx3CACAoW24lxlX1Z6q+lJVLVbV+4aeBwAAgI1nQ8VsVW1N8ptJfjrJG5L8nap6w7BTAQAAsNFsqJhNcn2Sxdban7fW/irJx5LcOPBMAAAAbDAb7T2zVyX52qr140n+o4FmoUP33ntvFkcfbM7knP5vfPq9s0zGzMyM99oDz8tz3+R53lsfnvcY10aL2XN9bk0744Sq9yR5T5JcffXV6zETcJZLLrlk6BEAYN143oONqVprz3/WOqmqH0myt7X2ttH6/UnSWvuH5zp/dna2HTp0aB0nBAAAYL1U1eHW2uy57tto75n9TJJrqur1VfU9SW5Kcv/AMwEAALDBbKiXGbfWlqvqvUk+mWRrko+21h4ZeCwAAAA2mA0Vs0nSWnswyYNDzwEAAMDGtdFeZgwAAADPS8wCAADQHTELAABAd8QsAAAA3RGzAAAAdEfMAgAA0B0xCwAAQHfELAAAAN0RswAAAHRHzAIAANAdMQsAAEB3xCwAAADdEbMAAAB0R8wCAADQnWqtDT3Di1ZVTyd5bOg5YJN6dZJ/M/QQALBOPO/BML6vtXb5ue7oOmaB4VTVodba7NBzAMB68LwHG4+XGQMAANAdMQsAAEB3xCzwYn1k6AEAYB153oMNxntmAQAA6I6dWQAAALojZgEAAOiOmAUAAKA7U0MPAGx8VfUDSW5MclWSluTJJPe31r446GAAAGxadmaBNVXVf5vkY0kqyaeTfGZ0+3eq6n1DzgYA662q/ouhZwBOcTVjYE1V9eUkb2ytffus49+T5JHW2jXDTAYA66+qvtpau3roOQAvMwae38kkr0ny2FnHd4zuA4CLSlX93+e7K8mV6zkLcH5iFng+v5jkoap6NMnXRseuTjKT5L1DDQUAE3Rlkrcl+X/POl5J/tX6jwOci5gF1tRaW6iqfz/J9Tl1AahK8niSz7TWVgYdDgAm4w+SbG+tfe7sO6rqD9d9GuCcvGcWAACA7riaMQAAAN0RswAAAHRHzAJAR6rqHRfqM56r6sSF+D4AMATvmQWADaaqplpry+vw+5xorW2f9O8DAJNgZxYAJqSqLq2qB6rqT6vq81X1t6vqaFW9enT/7Okro1bV3qr6SFV9Ksn+qvqTqnrjqu/1h1V1XVX951X1P1XVK0ffa8vo/ldU1deqaltVfX9VLVTV4ar6l1X1A6NzXl9Vf1xVn6mqu9f/vwgAXDhiFgAmZ0+SJ1trP9Ra++tJFp7n/OuS3Nha+7tJPpbkbyVJVe1I8prW2uHTJ7bW/jLJnyb58dGhtyf5ZGvt20k+kuTW1tp1Sf6bJB8enfOhJL/VWntzkv/nQvwBAWAoYhYAJudIkl1V9d9V1X88CtC13N9ae250+74k7xrd/ltJPn6O8383yd8e3b4pye9W1fYkP5rk41X1uST/OMmO0Tk/luR3Rrf/ybh/GADYSKaGHgAALlattS9X1XVJfibJPxy9hHg5//8Pk19+1kOeWfXYJ6pqqap+MKeC9b86x29x/+j7viqndnUfTnJpkr9orb3pfGO92D8PAGwkdmYBYEKq6jVJnm2t/dMk/32SH05yNKfCM0n+s+f5Fh9L8g+SvLK1duTsO1trJ5J8OqdePvwHrbWV1trXk3ylqt41mqGq6odGD/m/cmoHN0l+7kX/wQBgAxCzADA51yb59Ojlvh9Isi/JXUk+VFX/MsnK8zz+n+dUfN63xjm/m+Tvjb6e9nNJ3l1Vf5rkkSQ3jo7fnuSWqvpMkleO90cBgI3FR/MAAADQHTuzAAAAdEfMAgAA0B0xCwAAQHfELAAAAN0RswAAAHRHzAIAANAdMQsAAEB3xCwAAADd+f8ALcfCtx/L3y4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "data = pd.concat([titanic['survived'], titanic['fare']], axis=1)\n",
    "f, ax = plt.subplots(figsize=(16, 8))\n",
    "fig = sns.boxplot(x=titanic['survived'], y=titanic['fare'], data=data)\n",
    "plt.xticks(rotation=90);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02041a79",
   "metadata": {},
   "source": [
    "`data = pd.concat([df['survived'], df['fare']], axis=1)`: This line creates a new DataFrame called data by concatenating two columns from an existing DataFrame df. It selects the 'survived' and 'fare' columns and combines them horizontally (axis=1) to form the new DataFrame.\n",
    "\n",
    "`f, ax = plt.subplots(figsize=(16, 8))`: This line creates a figure (f) and an axis (ax) using plt.subplots(). The figsize parameter sets the size of the figure in inches, specifying a width of 16 and a height of 8.\n",
    "\n",
    "`fig = sns.boxplot(x=df['survived'], y=df['fare'], data=data)`: This line creates a box plot using Seaborn's boxplot function. The 'survived' column values are assigned to the x-axis (x=df['survived']), and the 'fare' column values are assigned to the y-axis (y=df['fare']). The data parameter specifies the DataFrame from which the values should be retrieved.\n",
    "\n",
    "`plt.xticks(rotation=90)`: This line rotates the x-axis tick labels by 90 degrees to prevent overlap when the labels are long. It improves the readability of the plot by ensuring that the x-axis labels are displayed vertically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "785eb56e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>pclass</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>boat</th>\n",
       "      <th>body</th>\n",
       "      <th>home.dest</th>\n",
       "      <th>survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>Cardeza, Mrs. James Warburton Martinez (Charlo...</td>\n",
       "      <td>F</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>PC 17755</td>\n",
       "      <td>512.3292</td>\n",
       "      <td>B51 B53 B55</td>\n",
       "      <td>C</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Germantown, Philadelphia, PA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>183</td>\n",
       "      <td>1</td>\n",
       "      <td>Lesurer, Mr. Gustave J</td>\n",
       "      <td>M</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17755</td>\n",
       "      <td>512.3292</td>\n",
       "      <td>B101</td>\n",
       "      <td>C</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>Cardeza, Mr. Thomas Drake Martinez</td>\n",
       "      <td>M</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>PC 17755</td>\n",
       "      <td>512.3292</td>\n",
       "      <td>B51 B53 B55</td>\n",
       "      <td>C</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Austria-Hungary / Germantown, Philadelphia, PA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     passenger_id  pclass                                               name  \\\n",
       "60             50       1  Cardeza, Mrs. James Warburton Martinez (Charlo...   \n",
       "789           183       1                             Lesurer, Mr. Gustave J   \n",
       "795            49       1                 Cardeza, Mr. Thomas Drake Martinez   \n",
       "\n",
       "    sex   age  sibsp  parch    ticket      fare        cabin embarked boat  \\\n",
       "60    F  58.0      0      1  PC 17755  512.3292  B51 B53 B55        C    3   \n",
       "789   M  35.0      0      0  PC 17755  512.3292         B101        C    3   \n",
       "795   M  36.0      0      1  PC 17755  512.3292  B51 B53 B55        C    3   \n",
       "\n",
       "     body                                       home.dest  survived  \n",
       "60    NaN                    Germantown, Philadelphia, PA         1  \n",
       "789   NaN                                             NaN         1  \n",
       "795   NaN  Austria-Hungary / Germantown, Philadelphia, PA         1  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic[titanic['fare'] > 500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "6042d082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix the outlier\n",
    "titanic[\"fare\"].replace({ 512.3292 : 7.25}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c75b29d",
   "metadata": {},
   "source": [
    "### 1.2.8 Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "96b43c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passenger_id      0\n",
      "pclass            0\n",
      "name              0\n",
      "sex               0\n",
      "age               0\n",
      "sibsp             0\n",
      "parch             0\n",
      "ticket            0\n",
      "fare              1\n",
      "cabin           659\n",
      "embarked          0\n",
      "boat            542\n",
      "body            776\n",
      "home.dest       385\n",
      "survived          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(titanic.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5254e1d",
   "metadata": {},
   "source": [
    "As you continue exploring the fascinating Titanic dataset, you might have noticed that there are still some missing values in certain columns. You may choose two of them to do the data cleaning. Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "8eef3474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdeb6dc",
   "metadata": {},
   "source": [
    "## 1.2 Encoding Categorical Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a77b376",
   "metadata": {},
   "source": [
    "Encoding categorical data involves converting categorical variables into numerical representations to be used in machine learning or statistical models. This process assigns numerical values to categories, allowing the data to be processed effectively by algorithms that work with numerical inputs. Common encoding techniques include one-hot encoding, label encoding, ordinal encoding, target encoding, binary encoding, frequency encoding, and hash encoding. By encoding categorical data, we enable the incorporation of these variables into models and leverage the information they provide for analysis and predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d0ca73",
   "metadata": {},
   "source": [
    "There are several ways to encode categorical data, depending on the specific requirements and characteristics of the data. Here are some common methods for categorical data encoding:\n",
    "\n",
    "One-Hot Encoding (Dummy Coding):\n",
    "\n",
    "1. This method creates binary columns for each category in the original variable. Each category is represented by a separate column, where a value of 1 indicates the presence of that category, and 0 indicates its absence. This approach is suitable when the categories are not ordinal.\n",
    "Example: Using **pd.get_dummies()** function in pandas or **OneHotEncoder** class in scikit-learn.\n",
    "Label Encoding:\n",
    "\n",
    "2. Label encoding assigns a unique numerical label to each category in the variable. Each category is replaced with an integer value. This method is useful for ordinal categorical variables where the order matters.\n",
    "Example: Using **LabelEncoder** class in scikit-learn.\n",
    "Ordinal Encoding:\n",
    "\n",
    "3. Ordinal encoding maps the categories to ordered numerical values based on a predefined order or mapping. It assigns integers to categories based on their relative order or specified mapping. This encoding is suitable for ordinal categorical variables.\n",
    "Example: Using a mapping dictionary or the OrdinalEncoder class in scikit-learn.\n",
    "Binary Encoding:\n",
    "\n",
    "4. Binary encoding represents each category with binary digits. It converts the categories into binary representations and uses a combination of 0s and 1s to encode the variables. This approach is suitable for variables with a large number of categories.\n",
    "Example: Using libraries like category_encoders or feature-engine.\n",
    "Frequency Encoding:\n",
    "\n",
    "5. Frequency encoding replaces each category with its frequency or proportion in the dataset. It assigns a numerical value based on the occurrence frequency of each category. This approach is useful when the frequency of categories is informative.\n",
    "Example: Manually calculating frequencies or using libraries like category_encoders.\n",
    "Hash Encoding:\n",
    "\n",
    "These are some common methods for encoding categorical data. The choice of encoding technique depends on the specific characteristics of the data, the nature of the categories, and the requirements of the analysis or modeling task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cda1a23",
   "metadata": {},
   "source": [
    "### 1.2.1 One-Hot Encoding (Dummy Coding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ebb227",
   "metadata": {},
   "source": [
    "One-hot encoding converts categorical variables into binary columns representing each unique category, enabling machine learning algorithms to process categorical data as numerical input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "e1c2c087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with the \"color\" column\n",
    "df = pd.DataFrame({'color': ['red', 'green', 'blue', 'red']})\n",
    "\n",
    "# Apply one-hot encoding\n",
    "one_hot_encoded = pd.get_dummies(df['color'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "1fba4cd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>blue</th>\n",
       "      <th>green</th>\n",
       "      <th>red</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   blue  green  red\n",
       "0     0      0    1\n",
       "1     0      1    0\n",
       "2     1      0    0\n",
       "3     0      0    1"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f4ec9c",
   "metadata": {},
   "source": [
    "The resulting **one_hot_encoded** DataFrame will have three binary columns: \"color_red,\" \"color_green,\" and \"color_blue,\" where 1 indicates the presence of that color and 0 indicates its absence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b81390f",
   "metadata": {},
   "source": [
    "### 1.2.2 Label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "9670fe14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with the \"color\" column\n",
    "label_df = pd.DataFrame({'color': ['red', 'green', 'blue', 'red']})\n",
    "\n",
    "# Apply label encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "label_df['color_encoded'] = label_encoder.fit_transform(df['color'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "37da5a18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color</th>\n",
       "      <th>color_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>red</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>green</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blue</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>red</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   color  color_encoded\n",
       "0    red              2\n",
       "1  green              1\n",
       "2   blue              0\n",
       "3    red              2"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9851de2",
   "metadata": {},
   "source": [
    "The resulting DataFrame will have an additional column named \"color_encoded\" that contains the encoded numerical values for each category: 2 for \"red,\" 1 for \"green,\" and 0 for \"blue.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5078079b",
   "metadata": {},
   "source": [
    "### 1.2.3 Ordinal encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "1964fa63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Size</th>\n",
       "      <th>Size_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Small</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Medium</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Large</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Small</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Large</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Size  Size_encoded\n",
       "0   Small             0\n",
       "1  Medium             1\n",
       "2   Large             2\n",
       "3   Small             0\n",
       "4   Large             2"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame with the categorical variable\n",
    "ordinal_df = pd.DataFrame({'Size': ['Small', 'Medium', 'Large', 'Small', 'Large']})\n",
    "\n",
    "# Define the order of the categories\n",
    "category_order = ['Small', 'Medium', 'Large']\n",
    "\n",
    "# Perform ordinal encoding\n",
    "ordinal_df['Size_encoded'] = ordinal_df['Size'].map(lambda x: category_order.index(x))\n",
    "\n",
    "# Print the encoded DataFrame\n",
    "ordinal_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b119c6",
   "metadata": {},
   "source": [
    "The map() function in combination with the lambda function allows us to apply the ordinal encoding logic to each value in the 'Size' column and obtain the corresponding encoded values. These encoded values are then assigned to the 'Size_encoded' column in the DataFrame.\n",
    "\n",
    "Consider a categorical variable \"Size\" with categories \"Small,\" \"Medium,\" and \"Large.\" After ordinal encoding, \"Small\" might be represented as 0, \"Medium\" as 1, and \"Large\" as 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2999b6e7",
   "metadata": {},
   "source": [
    "### 1.2.4 Binary encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "5b20e385",
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as ce\n",
    "\n",
    "# Create a DataFrame with the \"color\" column\n",
    "df = pd.DataFrame({'color': ['red', 'green', 'blue', 'red']})\n",
    "\n",
    "# Apply binary encoding\n",
    "binary_encoder = ce.BinaryEncoder(cols=['color'])\n",
    "binary_df = binary_encoder.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "d16d21bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color_0</th>\n",
       "      <th>color_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   color_0  color_1\n",
       "0        0        1\n",
       "1        1        0\n",
       "2        1        1\n",
       "3        0        1"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3bc333a",
   "metadata": {},
   "source": [
    "The resulting **df_encoded** DataFrame will have binary-encoded columns for the \"color\" variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d274689",
   "metadata": {},
   "source": [
    "### 1.2.5 Frequency encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "ae46a55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with the \"color\" column\n",
    "df = pd.DataFrame({'color': ['red', 'green', 'blue', 'red']})\n",
    "\n",
    "# Calculate the frequency of each category\n",
    "frequency = df['color'].value_counts(normalize=True)\n",
    "\n",
    "# Apply frequency encoding\n",
    "df['color_encoded'] = df['color'].map(frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "d4d27d80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color</th>\n",
       "      <th>color_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>red</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>green</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blue</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>red</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   color  color_encoded\n",
       "0    red           0.50\n",
       "1  green           0.25\n",
       "2   blue           0.25\n",
       "3    red           0.50"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f52357",
   "metadata": {},
   "source": [
    "The resulting DataFrame will have an additional column named \"color_encoded\" that contains the frequency (proportion) of each category.\n",
    "\n",
    "These examples demonstrate how each encoding method can be applied to a categorical variable. It's important to adapt the code to your specific dataset and encoding requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841ad88b",
   "metadata": {},
   "source": [
    "### 1.2.6 Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "8e7996da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 849 entries, 0 to 848\n",
      "Data columns (total 15 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   passenger_id  849 non-null    int64  \n",
      " 1   pclass        849 non-null    int64  \n",
      " 2   name          849 non-null    object \n",
      " 3   sex           849 non-null    object \n",
      " 4   age           849 non-null    float64\n",
      " 5   sibsp         849 non-null    int64  \n",
      " 6   parch         849 non-null    int64  \n",
      " 7   ticket        849 non-null    object \n",
      " 8   fare          848 non-null    float64\n",
      " 9   cabin         190 non-null    object \n",
      " 10  embarked      849 non-null    object \n",
      " 11  boat          307 non-null    object \n",
      " 12  body          73 non-null     float64\n",
      " 13  home.dest     464 non-null    object \n",
      " 14  survived      849 non-null    int64  \n",
      "dtypes: float64(3), int64(5), object(7)\n",
      "memory usage: 106.1+ KB\n"
     ]
    }
   ],
   "source": [
    "titanic.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade13558",
   "metadata": {},
   "source": [
    "We still have some features that require encoding. Let's pick two of these features and apply the appropriate encoding techniques to convert them into numerical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "3676fe3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c27c0bc",
   "metadata": {},
   "source": [
    "# 2. Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d50d968",
   "metadata": {},
   "source": [
    "## 2.1 Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6a4331",
   "metadata": {},
   "source": [
    "### 2.1.1 What is feature selection and why is it important"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99aa0fd7",
   "metadata": {},
   "source": [
    "Feature selection is a process in machine learning and data analysis that involves selecting a subset of relevant and important features (also known as attributes or variables) from a larger set of features in a dataset. The goal of feature selection is to choose the most informative and significant features that have a strong relationship with the target variable or outcome of interest.\n",
    "\n",
    "In many real-world datasets, there may be numerous features, some of which might be redundant, irrelevant, or even noisy, meaning they do not contribute much to the prediction or analysis task. Including such features in the model can lead to various issues, such as increased computational complexity, overfitting, reduced model interpretability, and degraded model performance on unseen data.\n",
    "\n",
    "By performing feature selection, we aim to:\n",
    "\n",
    "**1. Improve Model Performance:** By selecting only the most relevant features, the model can focus on the most important patterns and relationships in the data, leading to better generalization and improved model performance on new, unseen data.\n",
    "\n",
    "**2. Reduce Overfitting:** Including irrelevant or redundant features in the model can cause overfitting, where the model memorizes the training data but fails to generalize well to new data. Feature selection helps in reducing overfitting and promoting better model generalization.\n",
    "\n",
    "**3. Enhance Model Interpretability:** Models with a smaller number of features are easier to interpret and understand. Feature selection helps create simpler, more interpretable models, which can provide valuable insights into the underlying relationships between features and the target variable.\n",
    "\n",
    "**4. Save Computational Resources:** Removing irrelevant features from the dataset reduces the amount of data that needs to be processed during model training and prediction, leading to faster and more efficient computations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3622429f",
   "metadata": {},
   "source": [
    "### 2.1.2 Common Feature Selection Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9dffe00",
   "metadata": {},
   "source": [
    "Feature selection is a crucial step in data science that involves choosing the most relevant and informative features from a dataset to improve the performance of a machine learning model and reduce overfitting. There are various methods for feature selection, each with its advantages and use cases. Here are some common methods:\n",
    "\n",
    "### 1. Univariate Feature Selection (SelectKBest):\n",
    "Univariate feature selection is a statistical method that ranks each feature based on its individual relationship with the target variable. SelectKBest is one such technique that selects the top K features with the highest scores from a given statistical test. In our case, we use the F-test as the score function. The chosen features are those that show the strongest correlation with the target variable in isolation.\n",
    "\n",
    "\n",
    "### 2. Recursive Feature Elimination (RFE):\n",
    "Recursive Feature Elimination (RFE) is a recursive method that starts with all features and iteratively removes the least important feature at each step. It uses an underlying model (in our case, a linear regression model) to evaluate feature importance and eliminates the least significant feature based on its coefficient value. RFE continues this process until it reaches the desired number of features.\n",
    "\n",
    "\n",
    "### 3. Random Forest Feature Importance:\n",
    "Random Forest is an ensemble learning method that builds multiple decision trees and combines their predictions. Feature importance is calculated based on the average impurity reduction (or information gain) from each feature across all trees. Features with higher importance scores are considered more relevant to the target variable. In this method, we select the top features based on their importance scores without using any threshold.\n",
    "\n",
    "\n",
    "### 4. SelectPercentile:\n",
    "SelectPercentile is another univariate feature selection method that selects the top features based on a user-defined percentile of the highest-scoring features. In our case, we use the F-test score function to rank features based on their correlation with the target variable. The features that have importance scores above the specified percentile are chosen.\n",
    "\n",
    "\n",
    "### 5. Lasso Regression (L1 Regularization):\n",
    "L1 Regularization (Lasso Regression) introduces an L1 penalty term to the loss function, which results in some feature coefficients becoming exactly zero. This sparsity-inducing property of Lasso allows it to perform feature selection by effectively eliminating less important features. We fit a linear regression model with L1 regularization to the data and select the features that have non-zero coefficients after training the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef60cd8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7212281b",
   "metadata": {},
   "source": [
    "## 2.2 Load and Introduce the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "695fde7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_california_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "4512d80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the California housing dataset\n",
    "data = fetch_california_housing(as_frame=True)\n",
    "df = data.frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "250efdf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>MedHouseVal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "\n",
       "   Longitude  MedHouseVal  \n",
       "0    -122.23        4.526  \n",
       "1    -122.22        3.585  \n",
       "2    -122.24        3.521  \n",
       "3    -122.25        3.413  \n",
       "4    -122.25        3.422  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e0ec8c",
   "metadata": {},
   "source": [
    "The California housing dataset is a popular dataset often used for regression tasks in machine learning and data analysis. It contains data from the 1990 California census and provides various features related to housing in different districts of California. The target variable in this dataset is typically the median house value for California districts.\n",
    "\n",
    "The dataset includes the following features:\n",
    "\n",
    "1. **MedInc:** Median income of the district.\n",
    "2. **HouseAge:** Median age of the houses in the district.\n",
    "3. **AveRooms:** Average number of rooms in the houses in the district.\n",
    "4. **AveBedrms:** Average number of bedrooms in the houses in the district.\n",
    "5. **Population:** Total population of the district.\n",
    "6. **AveOccup:** Average household occupancy, i.e., the number of people living in a household in the district.\n",
    "7. **Latitude:** Latitude coordinate of the district's location.\n",
    "8. **Longitude:** Longitude coordinate of the district's location.\n",
    "\n",
    "\n",
    "The target variable is:\n",
    "\n",
    "9. **MedHouseVal:** Median house value for California districts (the target variable for regression)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "53a5b3c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20640 entries, 0 to 20639\n",
      "Data columns (total 9 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   MedInc       20640 non-null  float64\n",
      " 1   HouseAge     20640 non-null  float64\n",
      " 2   AveRooms     20640 non-null  float64\n",
      " 3   AveBedrms    20640 non-null  float64\n",
      " 4   Population   20640 non-null  float64\n",
      " 5   AveOccup     20640 non-null  float64\n",
      " 6   Latitude     20640 non-null  float64\n",
      " 7   Longitude    20640 non-null  float64\n",
      " 8   MedHouseVal  20640 non-null  float64\n",
      "dtypes: float64(9)\n",
      "memory usage: 1.4 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "5c33d28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into features (X) and target variable (y)\n",
    "X = df.drop('MedHouseVal', axis=1)\n",
    "y = df['MedHouseVal']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93916dc4",
   "metadata": {},
   "source": [
    "## 2.3 Feature Selection Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7d1fea",
   "metadata": {},
   "source": [
    "#### 2.3.1 Univariate Feature Selection (SelectKBest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "688581a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features using Univariate Feature Selection (SelectKBest):\n",
      "Index(['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Latitude'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# 1. Univariate Feature Selection (SelectKBest)\n",
    "k_best_features = 5  # Choose the desired number of top features\n",
    "selector_univariate = SelectKBest(score_func=f_regression, k=k_best_features)\n",
    "X_new_univariate = selector_univariate.fit_transform(X, y)\n",
    "selected_features_univariate = X.columns[selector_univariate.get_support()]\n",
    "print(\"Selected features using Univariate Feature Selection (SelectKBest):\")\n",
    "print(selected_features_univariate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "fc237c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features using Univariate Feature Selection (SelectKBest):\n",
      "Index(['MedInc', 'AveRooms', 'Latitude', 'HouseAge', 'AveBedrms'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# 1. Univariate Feature Selection (SelectKBest)\n",
    "k_best_features = 5  # Choose the desired number of top features\n",
    "# Compute feature scores using univariate regression (F-test)\n",
    "scores_univariate = f_regression(X, y)[0]\n",
    "# Get the indices of the top K features\n",
    "selected_indices_univariate = sorted(\n",
    "    range(len(scores_univariate)),\n",
    "    key=lambda i: scores_univariate[i], reverse=True)[:k_best_features]\n",
    "selected_features_univariate = X.columns[selected_indices_univariate]\n",
    "print(\"Selected features using Univariate Feature Selection (SelectKBest):\")\n",
    "print(selected_features_univariate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "0132da80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveBedrms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>37.88</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1.023810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>37.86</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.971880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1.073446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1.073059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1.081081</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  AveRooms  Latitude  HouseAge  AveBedrms\n",
       "0  8.3252  6.984127     37.88      41.0   1.023810\n",
       "1  8.3014  6.238137     37.86      21.0   0.971880\n",
       "2  7.2574  8.288136     37.85      52.0   1.073446\n",
       "3  5.6431  5.817352     37.85      52.0   1.073059\n",
       "4  3.8462  6.281853     37.85      52.0   1.081081"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_univariate = pd.DataFrame(data=df, columns=selected_features_univariate)\n",
    "df_univariate.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2f5d82",
   "metadata": {},
   "source": [
    "#### 2.3.2 Recursive Feature Elimination (RFE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "2ea85d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selected features using Recursive Feature Elimination (RFE):\n",
      "Index(['MedInc', 'AveRooms', 'AveBedrms', 'Latitude', 'Longitude'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "num_features_to_select = 5  # Choose the desired number of features\n",
    "estimator_rfe = LinearRegression()\n",
    "selector_rfe = RFE(estimator_rfe, n_features_to_select=num_features_to_select)\n",
    "X_new_rfe = selector_rfe.fit_transform(X, y)\n",
    "selected_features_rfe = X.columns[selector_rfe.support_]\n",
    "print(\"\\nSelected features using Recursive Feature Elimination (RFE):\")\n",
    "print(selected_features_rfe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "ddb1aa88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selected features using Recursive Feature Elimination (RFE):\n",
      "Index(['MedInc', 'AveRooms', 'AveBedrms', 'Latitude', 'Longitude'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# 2. Recursive Feature Elimination (RFE)\n",
    "num_features_to_select = 5  # Choose the desired number of features\n",
    "# Create a linear regression model\n",
    "estimator_rfe = LinearRegression()\n",
    "# RFE: Start with all features, recursively remove the least important one until reaching the desired number of features\n",
    "selected_indices_rfe = list(range(len(X.columns)))\n",
    "while len(selected_indices_rfe) > num_features_to_select:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X.iloc[:, selected_indices_rfe], y, test_size=0.3, random_state=42)\n",
    "    estimator_rfe.fit(X_train, y_train)\n",
    "    # Get the feature importances (coefficients) from the model\n",
    "    feature_importances_rfe = estimator_rfe.coef_\n",
    "    # Find the index of the least important feature and remove it\n",
    "    min_importance_index = None\n",
    "    min_importance_value = float('inf')\n",
    "    for i, importance in enumerate(feature_importances_rfe):\n",
    "        if abs(importance) < min_importance_value:\n",
    "            min_importance_index = i\n",
    "            min_importance_value = abs(importance)\n",
    "    selected_indices_rfe.pop(min_importance_index)\n",
    "selected_features_rfe = X.columns[selected_indices_rfe]\n",
    "print(\"\\nSelected features using Recursive Feature Elimination (RFE):\")\n",
    "print(selected_features_rfe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "0fc7b15e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  AveRooms  AveBedrms  Latitude  Longitude\n",
       "0  8.3252  6.984127   1.023810     37.88    -122.23\n",
       "1  8.3014  6.238137   0.971880     37.86    -122.22\n",
       "2  7.2574  8.288136   1.073446     37.85    -122.24\n",
       "3  5.6431  5.817352   1.073059     37.85    -122.25\n",
       "4  3.8462  6.281853   1.081081     37.85    -122.25"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rfe = pd.DataFrame(data=df, columns=selected_features_rfe)\n",
    "df_rfe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19de445",
   "metadata": {},
   "source": [
    "#### 2.3.3 Random Forest Feature Importance with Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "350538be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selected features using Random Forest Feature Importance with Threshold:\n",
      "Index(['MedInc', 'HouseAge', 'AveOccup', 'Latitude', 'Longitude'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "threshold_importance = 0.05  # Choose the desired importance threshold\n",
    "estimator_rf = RandomForestRegressor()\n",
    "estimator_rf.fit(X, y)\n",
    "importances = estimator_rf.feature_importances_\n",
    "selected_features_rf = X.columns[importances > threshold_importance]\n",
    "print(\"\\nSelected features using Random Forest Feature Importance with Threshold:\")\n",
    "print(selected_features_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "662fe205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selected features using Random Forest Feature Importance with Threshold:\n",
      "Index(['MedInc', 'HouseAge', 'AveOccup', 'Latitude', 'Longitude'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# 3. Random Forest Feature Importance with Threshold\n",
    "threshold_importance = 0.05  # Choose the desired importance threshold\n",
    "# Create a random forest model\n",
    "estimator_rf = RandomForestRegressor()\n",
    "estimator_rf.fit(X, y)\n",
    "# Get the feature importances from the model\n",
    "importances_rf = estimator_rf.feature_importances_\n",
    "# Find the indices of the features that have importance scores above the threshold\n",
    "selected_indices_rf = []\n",
    "for i, importance in enumerate(importances_rf):\n",
    "    if importance > threshold_importance:\n",
    "        selected_indices_rf.append(i)\n",
    "selected_features_rf = X.columns[selected_indices_rf]\n",
    "print(\"\\nSelected features using Random Forest Feature Importance with Threshold:\")\n",
    "print(selected_features_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "ef00c9af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveOccup  Latitude  Longitude\n",
       "0  8.3252      41.0  2.555556     37.88    -122.23\n",
       "1  8.3014      21.0  2.109842     37.86    -122.22\n",
       "2  7.2574      52.0  2.802260     37.85    -122.24\n",
       "3  5.6431      52.0  2.547945     37.85    -122.25\n",
       "4  3.8462      52.0  2.181467     37.85    -122.25"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rf = pd.DataFrame(data=df, columns=selected_features_rf)\n",
    "df_rf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d5deee",
   "metadata": {},
   "source": [
    "#### 2.3.4 SelectPercentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "91a9b3b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selected features using SelectPercentile:\n",
      "Index(['MedInc', 'HouseAge', 'AveRooms', 'Latitude'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "percentile_features = 50  # Choose the desired percentile of features to keep\n",
    "selector_percentile = SelectPercentile(score_func=f_regression, percentile=percentile_features)\n",
    "X_new_percentile = selector_percentile.fit_transform(X, y)\n",
    "selected_features_percentile = X.columns[selector_percentile.get_support()]\n",
    "print(\"\\nSelected features using SelectPercentile:\")\n",
    "print(selected_features_percentile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "a9539c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selected features using SelectPercentile:\n",
      "Index(['MedInc', 'HouseAge', 'AveRooms', 'Latitude'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# 4. SelectPercentile\n",
    "percentile_features = 50  # Choose the desired percentile of features to keep\n",
    "# Compute feature scores using univariate regression (F-test)\n",
    "scores_percentile = f_regression(X, y)[0]\n",
    "# Find the importance score threshold for the desired percentile\n",
    "importance_threshold = np.percentile(scores_percentile, percentile_features)\n",
    "# Find the indices of the features that have importance scores above the threshold\n",
    "selected_indices_percentile = []\n",
    "for i, score in enumerate(scores_percentile):\n",
    "    if score >= importance_threshold:\n",
    "        selected_indices_percentile.append(i)\n",
    "selected_features_percentile = X.columns[selected_indices_percentile]\n",
    "print(\"\\nSelected features using SelectPercentile:\")\n",
    "print(selected_features_percentile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "638a5c71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>Latitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>37.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>37.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>37.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>37.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>37.85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  Latitude\n",
       "0  8.3252      41.0  6.984127     37.88\n",
       "1  8.3014      21.0  6.238137     37.86\n",
       "2  7.2574      52.0  8.288136     37.85\n",
       "3  5.6431      52.0  5.817352     37.85\n",
       "4  3.8462      52.0  6.281853     37.85"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_percentile = pd.DataFrame(data=df, columns=selected_features_percentile)\n",
    "df_percentile.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5afb1cb",
   "metadata": {},
   "source": [
    "## 2.4 Performance Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd387f93",
   "metadata": {},
   "source": [
    "Here, we choose decision tree as the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "bbdb0b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "def decision_tree_func(df, y = data.target):\n",
    "    # Separate features and target\n",
    "    X = df  # Features\n",
    "\n",
    "    # Split the data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "    # Create a decision tree regressor\n",
    "    tree = DecisionTreeRegressor()\n",
    "\n",
    "    # Fit the model on the training data\n",
    "    tree.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the test data\n",
    "    y_pred = tree.predict(X_test)\n",
    "\n",
    "    # Calculate the mean squared error (MSE)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "    # Calculate the mean absolute error (MAE)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "    # Calculate the R-squared (coefficient of determination)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    # Print the predicted values, MSE, MAE, and R-squared\n",
    "    print(\"Mean Squared Error:\", mse)\n",
    "    print(\"Mean Absolute Error:\", mae)\n",
    "    print(\"R-squared:\", r2)\n",
    "\n",
    "    return r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "5e41b82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of feature selection methods\n",
    "feature_selection_methods = [\n",
    "    \"Univariate Feature Selection (SelectKBest)\",\n",
    "    \"Recursive Feature Elimination (RFE)\",\n",
    "    \"Random Forest Feature Importance with Threshold\",\n",
    "    \"SelectPercentile\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "cac3dbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list =  [df_univariate, df_rfe, df_rf, df_percentile]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "91121d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Univariate Feature Selection (SelectKBest):\n",
      "Mean Squared Error: 0.8281975906393167\n",
      "Mean Absolute Error: 0.6258744937015505\n",
      "R-squared: 0.3648571824308472\n",
      "\n",
      "Recursive Feature Elimination (RFE):\n",
      "Mean Squared Error: 0.44823720077948154\n",
      "Mean Absolute Error: 0.4243681613372094\n",
      "R-squared: 0.6562479269921282\n",
      "\n",
      "Random Forest Feature Importance with Threshold:\n",
      "Mean Squared Error: 0.5067670614769864\n",
      "Mean Absolute Error: 0.4458940649224807\n",
      "R-squared: 0.6113615121371336\n",
      "\n",
      "SelectPercentile:\n",
      "Mean Squared Error: 0.8820342937163275\n",
      "Mean Absolute Error: 0.6382025436046512\n",
      "R-squared: 0.3235699393049998\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy_dict = {}\n",
    "\n",
    "for i in range(len(df_list)):\n",
    "    print(feature_selection_methods[i] + \":\")\n",
    "    \n",
    "    accuracy_dict.update({feature_selection_methods[i]:decision_tree_func(df_list[i])})\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "d1884b47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Univariate Feature Selection (SelectKBest)': 0.3648571824308472,\n",
       " 'Recursive Feature Elimination (RFE)': 0.6562479269921282,\n",
       " 'Random Forest Feature Importance with Threshold': 0.6113615121371336,\n",
       " 'SelectPercentile': 0.3235699393049998}"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "a812d973",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Recursive Feature Elimination (RFE)</th>\n",
       "      <td>0.656248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest Feature Importance with Threshold</th>\n",
       "      <td>0.611362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Univariate Feature Selection (SelectKBest)</th>\n",
       "      <td>0.364857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SelectPercentile</th>\n",
       "      <td>0.323570</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Accuracy\n",
       "Recursive Feature Elimination (RFE)              0.656248\n",
       "Random Forest Feature Importance with Threshold  0.611362\n",
       "Univariate Feature Selection (SelectKBest)       0.364857\n",
       "SelectPercentile                                 0.323570"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalleaderboard = pd.DataFrame.from_dict(accuracy_dict, orient='index', columns=['Accuracy'])\n",
    "finalleaderboard = finalleaderboard.sort_values('Accuracy', ascending=False)\n",
    "finalleaderboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab71a32",
   "metadata": {},
   "source": [
    "# 3. Evaluation Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b66ce5",
   "metadata": {},
   "source": [
    "## 3.1 Introduction\n",
    "In data science, evaluation metrics are used to measure the performance and effectiveness of various machine learning models and algorithms. The choice of evaluation metrics depends on the specific problem being solved and the nature of the data. Here are some commonly used evaluation metrics in data science:\n",
    "\n",
    "**1. Accuracy:** Measures the proportion of correctly predicted instances to the total number of instances in the dataset. It is a straightforward metric but can be misleading in imbalanced datasets.\n",
    "\n",
    "**2. Precision:** The proportion of true positive predictions (correctly predicted positive instances) to the total number of positive predictions made by the model. It is useful when the cost of false positives is high.\n",
    "\n",
    "**3. Recall (Sensitivity or True Positive Rate):** The proportion of true positive predictions to the total number of actual positive instances in the dataset. It is valuable when the cost of false negatives is high.\n",
    "\n",
    "**4. F1 Score:** The harmonic mean of precision and recall. It provides a balance between precision and recall, especially in imbalanced datasets.\n",
    "\n",
    "**5. Specificity (True Negative Rate):** The proportion of true negative predictions to the total number of actual negative instances in the dataset. It is useful when the cost of false negatives is high.\n",
    "\n",
    "**6. ROC-AUC (Receiver Operating Characteristic - Area Under the Curve):** Evaluates the area under the ROC curve, which plots the true positive rate against the false positive rate at various classification thresholds. It provides an aggregate measure of a model's performance across various thresholds.\n",
    "\n",
    "**7. Confusion Matrix:** A table that presents the true positive, true negative, false positive, and false negative counts, allowing for a more detailed evaluation of a classifier's performance.\n",
    "\n",
    "**8. Mean Absolute Error (MAE):** Measures the average absolute difference between the actual and predicted values. It is commonly used for regression tasks.\n",
    "\n",
    "**9. Mean Squared Error (MSE):** Measures the average squared difference between the actual and predicted values. It is another popular metric for regression tasks.\n",
    "\n",
    "**10. Root Mean Squared Error (RMSE):** The square root of MSE, providing a more interpretable metric for regression tasks.\n",
    "\n",
    "**11. R-squared (R2):** Measures the proportion of variance in the dependent variable that is predictable from the independent variables. It represents the goodness of fit of a regression mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79188108",
   "metadata": {},
   "source": [
    "## 3.2 Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2844787",
   "metadata": {},
   "source": [
    "### 3.2.1 Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "692dd9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_curve, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af8bbcd",
   "metadata": {},
   "source": [
    "**Imports**: Here, we import the necessary libraries for our code. `numpy` and `pandas` are used for data manipulation, `matplotlib` for data visualization, `load_iris` from `sklearn.datasets` to load the Iris dataset, `train_test_split` from `sklearn.model_selection` to split the data, `LogisticRegression` from `sklearn.linear_model` for the classification model, and various evaluation metrics (`confusion_matrix`, `classification_report`, `roc_curve`, `roc_auc_score`) from sklearn.metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2026f4b4",
   "metadata": {},
   "source": [
    "### 3.2.2 Load the Iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "46b32e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "wine = load_wine()\n",
    "X, y = wine.data, wine.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e5b835",
   "metadata": {},
   "source": [
    "**Load the Iris Dataset**: We load the Iris dataset using the `load_iris()` function from scikit-learn. The dataset contains features (in `X`) and target labels (in `y`). In this dataset, there are four features (sepal length, sepal width, petal length, petal width) and three classes of iris flowers (setosa, versicolor, virginica)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127e1c48",
   "metadata": {},
   "source": [
    "### 3.2.3 Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "eff796d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714de057",
   "metadata": {},
   "source": [
    "**Data Splitting**: The `train_test_split()` function is used to split the data into training and testing sets. We specify `test_size=0.3`, which means 30% of the data will be used for testing, and the remaining 70% for training. The `random_state` parameter is set to 42 to ensure reproducibility of the split."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b03745",
   "metadata": {},
   "source": [
    "### 3.2.4 Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "f2481f46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create and train a logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a1235d",
   "metadata": {},
   "source": [
    "**Model Training**: We create an instance of the logistic regression model using `LogisticRegression()`. Then, we fit the model to the training data using `model.fit(X_train, y_train)`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59aaa607",
   "metadata": {},
   "source": [
    "### 3.2.5 Model Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "26dbe124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04521fa9",
   "metadata": {},
   "source": [
    "**Model Prediction**: We use the trained model to make predictions on the test set using `model.predict(X_test)`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128880b8",
   "metadata": {},
   "source": [
    "### 3.2.6 Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "32338ada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9814814814814815"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate evaluation metrics\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8e0409",
   "metadata": {},
   "source": [
    "**Evaluation Metrics**: Here, we calculate the evaluation metrics for our classification model. We calculate the accuracy, which is the proportion of correct predictions. We use `np.mean(y_pred == y_test)` to calculate accuracy, where `y_pred` are the model predictions and `y_test` are the true labels. We also compute the confusion matrix using `confusion_matrix(y_test, y_pred)`, and the classification report using `classification_report(y_test, y_pred)`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580841db",
   "metadata": {},
   "source": [
    "### 3.2.7 Predicted Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "37dbd1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predicted probabilities for each class (multi-class OvR strategy)\n",
    "y_probs = model.predict_proba(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a788d57",
   "metadata": {},
   "source": [
    "**Predicted Probabilities**: The `predict_proba()` method returns the probabilities for each class. Since we have a multi-class classification problem, the `y_probs` array has a shape of `(n_samples, n_classes)` where `n_samples` is the number of samples in the test set, and `n_classes` is the number of classes in the dataset (in this case, 3 for the three iris species)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f34ef77",
   "metadata": {},
   "source": [
    "### 3.2.8 ROC-AUC Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "ba0f56dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate ROC-AUC score for each class\n",
    "roc_auc = roc_auc_score(y_test, y_probs, multi_class='ovr')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad43755",
   "metadata": {},
   "source": [
    "**ROC-AUC Score**: We calculate the ROC-AUC score for each class using the `roc_auc_score()` function from scikit-learn. The `multi_class='ovr'` parameter indicates the One-vs-Rest (OvR) strategy, where we treat each class as the positive class and the rest as the negative class. The function returns an array of ROC-AUC scores for each class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ba6d98",
   "metadata": {},
   "source": [
    "### 3.2.9 Data Visualization - Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "862f8bef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Assuming you already have the 'conf_matrix' and 'wine.target_names' variables defined\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.imshow(conf_matrix, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "\n",
    "classes = wine.target_names  # Define 'classes' before using it in the loop\n",
    "\n",
    "# Add numbers to the Confusion Matrix cells\n",
    "for i in range(len(classes)):\n",
    "    for j in range(len(classes)):\n",
    "        plt.text(j, i, str(conf_matrix[i, j]),\n",
    "                 horizontalalignment=\"center\", color=\"white\" if i == j else \"black\")\n",
    "\n",
    "plt.title('Confusion Matrix')\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(classes))\n",
    "plt.xticks(tick_marks, classes, rotation=45)\n",
    "plt.yticks(tick_marks, classes)\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c556920",
   "metadata": {},
   "source": [
    "**Data Visualization** - Confusion Matrix: We use matplotlib to create a heatmap to visualize the confusion matrix. The heatmap's intensity represents the number of correct and incorrect predictions for each class. The color bar indicates the scale of the values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3803798",
   "metadata": {},
   "source": [
    "### 3.2.10 Classification Report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "02a3054b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97        19\n",
      "           1       0.95      1.00      0.98        21\n",
      "           2       1.00      1.00      1.00        14\n",
      "\n",
      "    accuracy                           0.98        54\n",
      "   macro avg       0.98      0.98      0.98        54\n",
      "weighted avg       0.98      0.98      0.98        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification Report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5af5861",
   "metadata": {},
   "source": [
    "**Classification Report**: We print the classification report, which includes metrics like precision, recall, F1-score, and support for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3a41d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
