{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MLcmore2023/MLcmore2023/blob/main/day4_am_morning/neural-network-demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Neural Network\n",
        "Neural network is a supervised machine learning algorithm used to predict a target variable (y) based on independent variables (X). They consist of interconnected nodes called neurons that learn and represent patterns within the data. By adjusting weights and biases, the network minimizes the difference between predicted and actual values during training. When making predictions, input data is processed through the network, producing a summarized prediction that captures complex relationships and nonlinearities in the data.\n",
        "\n",
        "In this demo, we will implement a simple multi-layer sigmoid neuron network to classify hand written digits. For historical reasons, this is sometimes also called multilayer perceptrons (MLP), despite being made up of sigmoid neurons, not perceptrons"
      ],
      "metadata": {
        "id": "e47eKiuZehcm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import libraries and initialize random generator"
      ],
      "metadata": {
        "id": "CKQNF4rHehcq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import time\n",
        "import numpy as np\n",
        "random.seed(0)\n",
        "np.random.seed(0)\n",
        "np.set_printoptions(threshold=10) # printing format"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-11T14:05:43.540504Z",
          "iopub.execute_input": "2023-07-11T14:05:43.541870Z",
          "iopub.status.idle": "2023-07-11T14:05:43.581686Z",
          "shell.execute_reply.started": "2023-07-11T14:05:43.541817Z",
          "shell.execute_reply": "2023-07-11T14:05:43.579943Z"
        },
        "trusted": true,
        "id": "vRQa2F1Kehcr"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### load the MNIST image data\n",
        "Load the MNIST data as a tuple containing the training data,\n",
        "the validation data, and the test data."
      ],
      "metadata": {
        "_uuid": "22315cef-88f4-4bea-9cef-5f51f500e782",
        "_cell_guid": "a3dedc54-92ac-4c42-bfa2-f9dde81c070b",
        "trusted": true,
        "id": "0hdAvIcbehcs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/mnielsen/neural-networks-and-deep-learning/master/data/mnist.pkl.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBgrPU_-hyA7",
        "outputId": "54f4c344-e0e9-43a0-c1c7-58c2ade2da41"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-08-10 13:08:28--  https://raw.githubusercontent.com/mnielsen/neural-networks-and-deep-learning/master/data/mnist.pkl.gz\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 17051982 (16M) [application/octet-stream]\n",
            "Saving to: ‘mnist.pkl.gz.3’\n",
            "\n",
            "mnist.pkl.gz.3      100%[===================>]  16.26M  --.-KB/s    in 0.08s   \n",
            "\n",
            "2023-08-10 13:08:29 (194 MB/s) - ‘mnist.pkl.gz.3’ saved [17051982/17051982]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!yes | gzip -d mnist.pkl.gz"
      ],
      "metadata": {
        "id": "9tLXDVR5h_ts",
        "outputId": "17ecdbbd-d003-4ecd-e732-329e7cc81a2f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gzip: mnist.pkl already exists;\tnot overwritten\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open('mnist.pkl', 'rb') as file:\n",
        "    data = pickle._Unpickler(file)\n",
        "    data.encoding = 'latin1'\n",
        "    training_data, validation_data, test_data = data.load()"
      ],
      "metadata": {
        "_uuid": "232aee20-c920-459f-8e91-704065550e30",
        "_cell_guid": "1486fe75-3196-4f2e-9ec1-d259ac435a2f",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2023-07-11T14:05:43.584410Z",
          "iopub.execute_input": "2023-07-11T14:05:43.585017Z",
          "iopub.status.idle": "2023-07-11T14:05:46.217254Z",
          "shell.execute_reply.started": "2023-07-11T14:05:43.584978Z",
          "shell.execute_reply": "2023-07-11T14:05:46.216187Z"
        },
        "trusted": true,
        "id": "4--EvRBPehcs"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The ``training_data`` is returned as a tuple with two entries.\n",
        "The first entry contains the actual training images.  "
      ],
      "metadata": {
        "id": "nsZOjp2Uehcu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_inputs, training_results = training_data\n",
        "\"\"\"\n",
        "#same as:\n",
        "training_inputs =training_data[0]\n",
        "training_results =training_data[1]\n",
        "\"\"\""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-11T14:05:46.218745Z",
          "iopub.execute_input": "2023-07-11T14:05:46.219479Z",
          "iopub.status.idle": "2023-07-11T14:05:46.228687Z",
          "shell.execute_reply.started": "2023-07-11T14:05:46.219432Z",
          "shell.execute_reply": "2023-07-11T14:05:46.227551Z"
        },
        "trusted": true,
        "id": "nPysA1oHehcu",
        "outputId": "d96d1122-c0bc-4a8c-ff62-ab9196662c67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n#same as:\\ntraining_inputs =training_data[0]\\ntraining_results =training_data[1]\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a\n",
        "numpy ndarray with 50,000 entries.  Each entry is, in turn, a\n",
        "numpy ndarray with 784 values, representing the 28 * 28 = 784\n",
        "pixels in a single MNIST image.\n",
        "\n",
        "One example image:\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/MLcmore2023/MLcmore2023/main/.images/neuralnetwork1.png\" alt=\"Image Description\" width=\"30%\">\n"
      ],
      "metadata": {
        "id": "lJF5LFqaehcv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "display(training_inputs)\n",
        "display(training_inputs.shape)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-11T14:05:46.232759Z",
          "iopub.execute_input": "2023-07-11T14:05:46.233869Z",
          "iopub.status.idle": "2023-07-11T14:05:46.250859Z",
          "shell.execute_reply.started": "2023-07-11T14:05:46.233812Z",
          "shell.execute_reply": "2023-07-11T14:05:46.249298Z"
        },
        "trusted": true,
        "id": "ST4D2GIRehcw",
        "outputId": "aed4dc4a-e8f4-41e9-ad8e-428157ffe356",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(50000, 784)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The second entry in the ``training_data`` tuple is a numpy ndarray\n",
        "containing 50,000 entries.  Those entries are just the digit\n",
        "values (0...9) for the corresponding images contained in the first\n",
        "entry of the tuple.\n",
        "\n"
      ],
      "metadata": {
        "id": "ZqtnNrnLehcw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "display(training_results)\n",
        "display(training_results.shape)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-11T14:05:46.252530Z",
          "iopub.execute_input": "2023-07-11T14:05:46.252935Z",
          "iopub.status.idle": "2023-07-11T14:05:46.269564Z",
          "shell.execute_reply.started": "2023-07-11T14:05:46.252896Z",
          "shell.execute_reply": "2023-07-11T14:05:46.268127Z"
        },
        "trusted": true,
        "id": "-jk23abmehcx",
        "outputId": "3e2f4958-ffc9-486f-916d-09b27143a393",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([5, 0, 4, ..., 8, 4, 8])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(50000,)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The ``validation_data`` and ``test_data`` are the same, except\n",
        "each contains only 10,000 images."
      ],
      "metadata": {
        "id": "6xCHVIZoehcy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(validation_data[0].shape,validation_data[1].shape)\n",
        "print(test_data[0].shape,test_data[1].shape)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-11T14:05:46.271023Z",
          "iopub.execute_input": "2023-07-11T14:05:46.271641Z",
          "iopub.status.idle": "2023-07-11T14:05:46.282300Z",
          "shell.execute_reply.started": "2023-07-11T14:05:46.271588Z",
          "shell.execute_reply": "2023-07-11T14:05:46.280761Z"
        },
        "trusted": true,
        "id": "Ms62_Opxehcy",
        "outputId": "358f463a-888d-4e7e-f6d4-6e462c6ce51a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 784) (10000,)\n",
            "(10000, 784) (10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vectorizing the labels\n",
        "This convert categorical labels (such as digits 0-9) into a vector numerical format. Later, our model will not directly predict the digits of handwritten images. Rather, our model gives a probability distribution of what digit an image might be. For example, an image of 2 will be [0%,0%, 100%, 0%,0%,0%,0%,0%,0%,0%] meaning it have 100% probability of being a 2, and 0% probability of being other digits.\n",
        "By vectorizing the training data, we make later calculations more efficient."
      ],
      "metadata": {
        "id": "t0iK3TjSehcy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def vectorized_result(j):\n",
        "    \"\"\"Return a 10-dimensional unit vector with a 1.0 in the jth\n",
        "    position and zeroes elsewhere.  This is used to convert a digit\n",
        "    (0...9) into a corresponding desired output from the neural\n",
        "    network.\"\"\"\n",
        "    unit_vector = np.zeros((10, 1))\n",
        "    unit_vector[j] = 1.0\n",
        "    return unit_vector"
      ],
      "metadata": {
        "_uuid": "b1dabc7a-741d-4c16-8f73-eb2c3e195497",
        "_cell_guid": "b8a9beab-7de5-4a7c-a658-0442aff26fdd",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2023-07-11T14:05:46.285221Z",
          "iopub.execute_input": "2023-07-11T14:05:46.285771Z",
          "iopub.status.idle": "2023-07-11T14:05:46.294714Z",
          "shell.execute_reply.started": "2023-07-11T14:05:46.285720Z",
          "shell.execute_reply": "2023-07-11T14:05:46.293117Z"
        },
        "trusted": true,
        "id": "ggvmYzWqehcz"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#for example:\n",
        "vectorized_result(2)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-11T14:05:46.297228Z",
          "iopub.execute_input": "2023-07-11T14:05:46.298811Z",
          "iopub.status.idle": "2023-07-11T14:05:46.314480Z",
          "shell.execute_reply.started": "2023-07-11T14:05:46.298751Z",
          "shell.execute_reply": "2023-07-11T14:05:46.312677Z"
        },
        "trusted": true,
        "id": "cafUGfzoehcz",
        "outputId": "da51ddae-d191-43e0-bf0d-077cd6ae6c71",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "now we apply vectorization to every training label. We also reshape the training inputs from row to column vectors"
      ],
      "metadata": {
        "id": "WUG_YTNiehcz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_set = []\n",
        "for i in range(50000):\n",
        "    image_vector = training_inputs[i]\n",
        "    # convert the row vectors to column vectors (for the purpose of doing matrix multiplications later)\n",
        "    image_vector = np.reshape(image_vector, (784,1))\n",
        "\n",
        "    image_label = training_results[i]\n",
        "    # vectorize the image labels\n",
        "    image_label = vectorized_result(image_label)\n",
        "\n",
        "    training_set.append((image_vector,image_label))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-11T14:05:46.316640Z",
          "iopub.execute_input": "2023-07-11T14:05:46.318430Z",
          "iopub.status.idle": "2023-07-11T14:05:46.669111Z",
          "shell.execute_reply.started": "2023-07-11T14:05:46.318370Z",
          "shell.execute_reply": "2023-07-11T14:05:46.667386Z"
        },
        "trusted": true,
        "id": "87_adWZgehcz"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# perform the same operation for validation set and testing set.\n",
        "# to save space, the code below is written using Python's list comprehension shortcut.\n",
        "# the outcome is the same as the code above, except the labels are NOT vectorized\n",
        "validation_inputs = [np.reshape(x, (784, 1)) for x in validation_data[0]]\n",
        "validation_set = list(zip(validation_inputs, validation_data[1]))\n",
        "test_inputs = [np.reshape(x, (784, 1)) for x in test_data[0]]\n",
        "test_set = list(zip(test_inputs, test_data[1]))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-11T14:05:46.673558Z",
          "iopub.execute_input": "2023-07-11T14:05:46.673998Z",
          "iopub.status.idle": "2023-07-11T14:05:46.839961Z",
          "shell.execute_reply.started": "2023-07-11T14:05:46.673967Z",
          "shell.execute_reply": "2023-07-11T14:05:46.838932Z"
        },
        "trusted": true,
        "id": "6AFpIDbYehc0"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Neural Network\n",
        "Below implements the stochastic gradient descent learning\n",
        "algorithm for a feedforward neural network.  Gradients are calculated\n",
        "using backpropagation. For the sake of simplicity and readability, the code is not optimized, and omits many desirable performance features.\n",
        "\n",
        "The rough idea is:\n",
        "1. Randomly initialize the weights and biases.\n",
        "2. Compute the gradient of the cost function in respect to the weights and biases for EVERY image. (i.e. computing how we should change the weights and biases so that the network is less wrong in EVERY image)\n",
        "3. Now we know how we should change the weights and biases so that the network is less wrong, we use this gradient to update the weights and biases (minus the weights and biases by the gradients times a tiny number called learning rate)\n",
        "4. Repeat for as many times as time and computation resource permits\n",
        "\n",
        "The above is called gradient descent.\n",
        "However, computing the gradient for EVERY image is often too slow. Therefore, we only use SOME subset of the dataset, which the exact amount is called the mini_batch_size. This is called stochastic gradient descent.\n",
        "\n",
        "![image.png](https://raw.githubusercontent.com/MLcmore2023/MLcmore2023/main/.images/neuralnetwork2.png)\n",
        "\n",
        "Gradient descent is like a smooth ball rolling down the hill perfectly towards the steepest direction. Stochastic gradient descent is like a dice stumbling down the hill, sometimes rolling side ways, sometimes rolling up, but in general still going down."
      ],
      "metadata": {
        "_uuid": "f118c5f1-bd21-46c5-9e51-ea9291797657",
        "_cell_guid": "980cc559-d4ec-4c64-ae5b-e4c5a326e6ff",
        "trusted": true,
        "id": "r23IPKOhehc0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### sigmoid function\n",
        "We will use the sigmoid function as our activation function. It is popular in early NN models for several reason.\n",
        "1. It is continuous and differentiable, enabling calculation of gradients.\n",
        "2. It is non-linear, which means it can solve non-linearly separable problem\n",
        "3. It's output is between 0 and 1, which stabilize the training process by preventing large, unbounded values from propagating through the network. It also allows for a natural interpretation of the output as a probability.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/MLcmore2023/MLcmore2023/main/.images/neuralnetwork3.png\" alt=\"Image Description\" width=\"50%\">\n",
        "\n",
        "Note: in modern deep neural networks, sigmoid function has been replaced by other functions such as RELU (rectified linear unit).\n"
      ],
      "metadata": {
        "id": "0yhdBC6hehc1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(z):\n",
        "    return 1.0 / (1.0 + np.exp(-z))\n",
        "\n",
        "def sigmoid_prime(z):\n",
        "    return sigmoid(z) * (1 - sigmoid(z))\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-11T14:05:46.841193Z",
          "iopub.execute_input": "2023-07-11T14:05:46.841750Z",
          "iopub.status.idle": "2023-07-11T14:05:46.848223Z",
          "shell.execute_reply.started": "2023-07-11T14:05:46.841718Z",
          "shell.execute_reply": "2023-07-11T14:05:46.846951Z"
        },
        "trusted": true,
        "id": "MX5xxIIeehc1"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initialize the network (weights & biases)\n",
        "We will make a network with 3 layers. The input layer have 784 neurons, the middle layer have 15 neurons, and output layer have 10 neurons.\n",
        "\n",
        "We chose 3 layers in this demo just to keep the training time quick. Usually, larger networks of more layers will perform better.\n",
        "\n",
        "![image.png](https://raw.githubusercontent.com/MLcmore2023/MLcmore2023/main/.images/neuralnetwork4.png)"
      ],
      "metadata": {
        "id": "ZQHsyNt8ehc2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The biases and weights are all initialized randomly, using the Numpy np.random.randn function to generate Gaussian distributions with mean 0 and standard deviation 1. This random initialization gives our stochastic gradient descent algorithm a place to start from. Biases and weights are stored as lists of Numpy matrices.\n",
        "\n",
        "Since the first layer of neurons is an input layer, we do not set any biases for those neurons, since biases are only ever used in computing the outputs from later layers.\n"
      ],
      "metadata": {
        "id": "DbAZWrRxehc2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "layer1_size, layer2_size, layer3_size = (784, 15, 10)\n",
        "num_layers = 3\n",
        "\n",
        "biases = []\n",
        "\n",
        "# layer 1 bias: first layer of neurons is an input layer, se we don't set any biases for those neurons,\n",
        "# since biases are only ever used in computing the outputs from later layers.\n",
        "layer2_bias = np.random.randn(15,1)\n",
        "biases.append(layer2_bias)\n",
        "layer3_bias = np.random.randn(10,1)\n",
        "biases.append(layer3_bias)\n",
        "\n",
        "weights = []\n",
        "layer1_to_2_weight = np.random.randn(15,784)\n",
        "weights.append(layer1_to_2_weight)\n",
        "layer2_to_3_weight = np.random.randn(10, 15)\n",
        "weights.append(layer2_to_3_weight)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-11T14:05:46.850891Z",
          "iopub.execute_input": "2023-07-11T14:05:46.851497Z",
          "iopub.status.idle": "2023-07-11T14:05:46.868401Z",
          "shell.execute_reply.started": "2023-07-11T14:05:46.851448Z",
          "shell.execute_reply": "2023-07-11T14:05:46.867207Z"
        },
        "trusted": true,
        "id": "g44MEuLmehc2"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feedforward\n",
        "<img src=\"https://raw.githubusercontent.com/MLcmore2023/MLcmore2023/main/.images/neuralnetwork5.png\" alt=\"Image Description\" width=\"20%\">\n",
        "\n",
        "a is the vector of activations of the n-th layer of neurons. To obtain a′ (n+1 th layer),\n",
        "we multiply a by the weight matrix w, and add the vector b of biases. We then apply the function σ elementwise to every entry in the vector wa+b.\n",
        "\n",
        "Because we have 3 layers of neurons, we need to apply this process twice (layer1-->2, layer2-->3)"
      ],
      "metadata": {
        "id": "7UK7iVtoehc2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def feedforward(a, biases, weights):\n",
        "    #layer 1 --> 2\n",
        "    b = biases[0]\n",
        "    w = weights[0]\n",
        "    a_layer2 = sigmoid(np.dot(w, a) + b)\n",
        "\n",
        "    #layer 2 --> 3\n",
        "    b = biases[1]\n",
        "    w = weights[1]\n",
        "    a_layer3 = sigmoid(np.dot(w, a_layer2) + b)\n",
        "    return a_layer3\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-11T14:05:46.869932Z",
          "iopub.execute_input": "2023-07-11T14:05:46.871288Z",
          "iopub.status.idle": "2023-07-11T14:05:46.879952Z",
          "shell.execute_reply.started": "2023-07-11T14:05:46.871248Z",
          "shell.execute_reply": "2023-07-11T14:05:46.878666Z"
        },
        "trusted": true,
        "id": "6OHfLHpDehc3"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluating accuracy (to count the amount of correct predictions)\n"
      ],
      "metadata": {
        "id": "fRAD_2Cjehc3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(test_data, biases, weights):\n",
        "    correct_prediction_count = 0\n",
        "    for x, y in test_data:\n",
        "        # example: [0, 0, 0.9, 0.05, 0.05, 0, 0,0 ,0,0]\n",
        "        predicted_y = np.argmax(feedforward(x, biases, weights))\n",
        "        if predicted_y == y:\n",
        "            correct_prediction_count +=1\n",
        "    return correct_prediction_count"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-11T14:05:46.881770Z",
          "iopub.execute_input": "2023-07-11T14:05:46.882206Z",
          "iopub.status.idle": "2023-07-11T14:05:46.903427Z",
          "shell.execute_reply.started": "2023-07-11T14:05:46.882168Z",
          "shell.execute_reply": "2023-07-11T14:05:46.901426Z"
        },
        "trusted": true,
        "id": "HiV3I_GXehc3"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Stochastic gradient descent\n",
        "To speed up training, we only use a subset of all the data during one iteration. These subsets are called mini-batches.\n",
        "In each epoch, we start by randomly shuffling the training data. Then, we slice it into mini-batches. Then for each mini_batch we apply a single step of gradient descent, which updates the network weights and biases according to a single iteration of gradient descent, using just the training data in mini_batch."
      ],
      "metadata": {
        "id": "eW7Ewu4iehc4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def SGD(training_data, num_epochs, mini_batch_size, learning_rate, num_layers, test_data=None):\n",
        "    #the purpose of SGD is to change the biases and weights\n",
        "    global biases, weights\n",
        "\n",
        "    n = len(training_data)\n",
        "\n",
        "    for j in range(num_epochs):\n",
        "        time1 = time.time()\n",
        "\n",
        "        random.shuffle(training_data)\n",
        "\n",
        "        for k in range(0, n, mini_batch_size): # for(int k=0; k<50000; k+=mini_batch_size)\n",
        "            #slice the dataset into batches\n",
        "            mini_batch = training_data[k:k + mini_batch_size]\n",
        "            #apply a single step of gradient descent\n",
        "            biases, weights = update_mini_batch(mini_batch, learning_rate, biases, weights, num_layers)\n",
        "\n",
        "        time2 = time.time()\n",
        "\n",
        "        count = evaluate(test_data, biases, weights)\n",
        "        accuracy = count / len(test_data)\n",
        "        print(f\"Epoch {j}: {count} / {len(test_data)}, took {(time2-time1):.2f} seconds\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-11T14:05:46.905046Z",
          "iopub.execute_input": "2023-07-11T14:05:46.906053Z",
          "iopub.status.idle": "2023-07-11T14:05:46.917875Z",
          "shell.execute_reply.started": "2023-07-11T14:05:46.906011Z",
          "shell.execute_reply": "2023-07-11T14:05:46.916555Z"
        },
        "trusted": true,
        "id": "gCH7iwrwehc4"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using a minibatch for SGD\n",
        "This function computes the gradients for every training image in the mini_batch, and then updating weights and biases appropriately.\n"
      ],
      "metadata": {
        "id": "DaJrdtNDehc4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def update_mini_batch(mini_batch, learning_rate, biases, weights, num_layers):\n",
        "    mini_batch_size = len(mini_batch)\n",
        "\n",
        "    # initializes nabla_b and nabla_w, with arrays of zeros, and same shape as the biases and weights.\n",
        "    \"\"\"\n",
        "    simplified version:\n",
        "    nabla_b = [np.zeros(b.shape) for b in biases]\n",
        "    nabla_w = [np.zeros(w.shape) for w in weights]\n",
        "    explicit version:\n",
        "    \"\"\"\n",
        "    nabla_b = []\n",
        "    nabla_w = []\n",
        "    for b in biases:\n",
        "        nabla_b.append(np.zeros(b.shape))\n",
        "    for w in weights:\n",
        "        nabla_w.append(np.zeros(w.shape))\n",
        "\n",
        "    #computes the gradients (of cost function) for every training image in the mini_batch.\n",
        "    for x, y in mini_batch:\n",
        "        delta_nabla_b, delta_nabla_w = backprop(x, y, num_layers, biases, weights)\n",
        "\n",
        "        for i in range(len(nabla_b)):\n",
        "            nabla_b[i] += delta_nabla_b[i]\n",
        "\n",
        "        for i in range(len(nabla_w)):\n",
        "            nabla_w[i] += delta_nabla_w[i]\n",
        "\n",
        "    # updating weights and biases appropriately:\n",
        "    # (take a step in the direction opposite to the gradient, with step size proportional to the learning_rate)\n",
        "    # we divide by mini_batch_size to obtain average\n",
        "    for i in range(len(weights)):\n",
        "        weights[i] -= (learning_rate / mini_batch_size) * nabla_w[i]\n",
        "    for i in range(len(biases)):\n",
        "        biases[i] -= (learning_rate / mini_batch_size) * nabla_b[i]\n",
        "\n",
        "    return biases, weights\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-11T14:05:46.919622Z",
          "iopub.execute_input": "2023-07-11T14:05:46.921290Z",
          "iopub.status.idle": "2023-07-11T14:05:46.936735Z",
          "shell.execute_reply.started": "2023-07-11T14:05:46.921235Z",
          "shell.execute_reply": "2023-07-11T14:05:46.935383Z"
        },
        "trusted": true,
        "id": "SgW0Y-Hlehc4"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Backpropagation\n",
        "The backpropagation algorithm is a fast way of computing the gradient of the cost function. It takes in a single example and returns the gradient of the cost function in respect to the weights and biases. In other words, we give this function an image + label, and the function tells us how the biases and weights should be altered such that the biases and weights can correctly classify this image.\n",
        "\n",
        "The activation of every layer depends on the previous layer:\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/MLcmore2023/MLcmore2023/main/.images/neuralnetwork6.png\" alt=\"Image Description\" width=\"17%\">\n",
        "\n",
        "We will name the inside part \"weighted input\", or z\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/MLcmore2023/MLcmore2023/main/.images/neuralnetwork7.png\" alt=\"Image Description\" width=\"15%\">\n",
        "\n",
        "The following are the fundamental equations of back propagation. Proofs can be found here: http://neuralnetworksanddeeplearning.com/chap2.html\n",
        "\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/MLcmore2023/MLcmore2023/main/.images/neuralnetwork8.png\" alt=\"Image Description\" width=\"40%\">\n"
      ],
      "metadata": {
        "id": "JFR_HleCehc5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cost_derivative(output_activations, y):\n",
        "    return output_activations - y\n",
        "\n",
        "def backprop(x, y, num_layers, biases, weights):\n",
        "    \"\"\"Return a tuple \"(nabla_b, nabla_w)\" representing the\n",
        "    gradient for the cost function C_x.  \"nabla_b\" and\n",
        "    \"nabla_w\" are layer-by-layer lists of numpy arrays, similar\n",
        "    to \"self.biases\" and \"self.weights\".\"\"\"\n",
        "\n",
        "    # initializes nabla_b and nabla_w, with arrays of zeros, and same shape as the biases and weights.\n",
        "    \"\"\"\n",
        "    simplified version:\n",
        "    nabla_b = [np.zeros(b.shape) for b in biases]\n",
        "    nabla_w = [np.zeros(w.shape) for w in weights]\n",
        "    explicit version:\"\"\"\n",
        "    nabla_b = []\n",
        "    nabla_w = []\n",
        "    for b in biases:\n",
        "        nabla_b.append(np.zeros(b.shape))\n",
        "    for w in weights:\n",
        "        nabla_w.append(np.zeros(w.shape))\n",
        "\n",
        "    activation = x\n",
        "    activation_layers = [x]  #list to store all the activations, layer by layer\n",
        "    z_layers = []   #list to store all the weighted inputs, layer by layer\n",
        "\n",
        "    # calculate the activations and weighted inputs for all layers\n",
        "    # if there are 3 layers, the activations needs to back propagate twice\n",
        "    # (layer3 --> layer2,  layer2 --> layer1)\n",
        "    for i in range(2):\n",
        "        b = biases[i]\n",
        "        w = weights[i]\n",
        "\n",
        "        z = np.dot(w, activation) + b\n",
        "        z_layers.append(z)\n",
        "        activation = sigmoid(z)\n",
        "        activation_layers.append(activation)\n",
        "\n",
        "    # apply equation BP1 and BP2, which finds the gradient for the last layer\n",
        "    delta = cost_derivative(activation_layers[-1], y) * sigmoid_prime(z_layers[-1])\n",
        "    nabla_b[-1] = delta\n",
        "    nabla_w[-1] = np.dot(delta, activation_layers[-2].transpose())\n",
        "\n",
        "    # apply equation BP3 and BP4, which finds the gradient for all previous layer\n",
        "    for l in range(2, num_layers):\n",
        "        delta = np.dot(weights[-l + 1].T, delta) * sigmoid_prime(z_layers[-l])\n",
        "        nabla_b[-l] = delta\n",
        "        nabla_w[-l] = np.dot(delta, activation_layers[-l - 1].T)\n",
        "\n",
        "    return nabla_b, nabla_w"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-11T14:05:46.938564Z",
          "iopub.execute_input": "2023-07-11T14:05:46.939296Z",
          "iopub.status.idle": "2023-07-11T14:05:46.957378Z",
          "shell.execute_reply.started": "2023-07-11T14:05:46.939258Z",
          "shell.execute_reply": "2023-07-11T14:05:46.956122Z"
        },
        "trusted": true,
        "id": "T1i9i5rqehc5"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 20\n",
        "mini_batch_size = 5\n",
        "learning_rate = 0.2\n",
        "SGD(training_set, epochs, mini_batch_size, learning_rate, num_layers,test_set)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-11T14:54:25.600518Z",
          "iopub.execute_input": "2023-07-11T14:54:25.601011Z",
          "iopub.status.idle": "2023-07-11T14:57:14.082479Z",
          "shell.execute_reply.started": "2023-07-11T14:54:25.600977Z",
          "shell.execute_reply": "2023-07-11T14:57:14.080878Z"
        },
        "trusted": true,
        "id": "3dUnCcvzehc5",
        "outputId": "020b90ad-e6fa-48ab-9e85-5543a4e7369b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: 6409 / 10000, took 8.96 seconds\n",
            "Epoch 1: 7444 / 10000, took 7.23 seconds\n",
            "Epoch 2: 7649 / 10000, took 9.11 seconds\n",
            "Epoch 3: 7786 / 10000, took 8.75 seconds\n",
            "Epoch 4: 8860 / 10000, took 7.08 seconds\n",
            "Epoch 5: 8959 / 10000, took 8.99 seconds\n",
            "Epoch 6: 9040 / 10000, took 9.13 seconds\n",
            "Epoch 7: 9066 / 10000, took 7.23 seconds\n",
            "Epoch 8: 9107 / 10000, took 11.99 seconds\n",
            "Epoch 9: 9124 / 10000, took 10.36 seconds\n",
            "Epoch 10: 9167 / 10000, took 9.00 seconds\n",
            "Epoch 11: 9161 / 10000, took 7.11 seconds\n",
            "Epoch 12: 9183 / 10000, took 10.45 seconds\n",
            "Epoch 13: 9204 / 10000, took 8.87 seconds\n",
            "Epoch 14: 9218 / 10000, took 7.71 seconds\n",
            "Epoch 15: 9227 / 10000, took 7.71 seconds\n",
            "Epoch 16: 9239 / 10000, took 8.97 seconds\n",
            "Epoch 17: 9239 / 10000, took 7.06 seconds\n",
            "Epoch 18: 9228 / 10000, took 8.38 seconds\n",
            "Epoch 19: 9222 / 10000, took 8.91 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: training this model takes a lot more time than other models we have seen in the past. In a later session, we will learn to use GPU's to make this faster."
      ],
      "metadata": {
        "id": "kmHQPLJYjNIM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = evaluate(validation_set, biases, weights) / len(validation_set)\n",
        "print(\"accuracy\",accuracy)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-11T14:07:18.935717Z",
          "iopub.execute_input": "2023-07-11T14:07:18.937246Z",
          "iopub.status.idle": "2023-07-11T14:07:19.854214Z",
          "shell.execute_reply.started": "2023-07-11T14:07:18.937169Z",
          "shell.execute_reply": "2023-07-11T14:07:19.852271Z"
        },
        "trusted": true,
        "id": "ZTEcmOgYehc5",
        "outputId": "82771d60-a609-42fc-c31d-139deea3c65d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy 0.9268\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercises\n",
        "1. Change the middle layer of the network from 15 neurons to 30 neurons, and observe the result\n",
        "2. Explain how does learning_rate affect the training process\n",
        "3. Explain how does epoch count affect the training process\n",
        "4. Bonus: change the network to 4 layers, with two middle layers both with 30 neurons.\n",
        "5. Bonus: choose another activation function here, and replace the sigmoid & sigmoid_price functions with it.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/MLcmore2023/MLcmore2023/main/.images/neuralnetwork9.png\" alt=\"Image Description\" width=\"50%\">\n"
      ],
      "metadata": {
        "id": "eC73YrQKehc6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def relu(z):\n",
        "    # exercise: code here\n",
        "    pass\n",
        "def relu_prime(z):\n",
        "    # exercise: code here\n",
        "    pass\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-11T14:07:19.857400Z",
          "iopub.execute_input": "2023-07-11T14:07:19.859176Z",
          "iopub.status.idle": "2023-07-11T14:07:19.873590Z",
          "shell.execute_reply.started": "2023-07-11T14:07:19.858981Z",
          "shell.execute_reply": "2023-07-11T14:07:19.872106Z"
        },
        "trusted": true,
        "id": "t7PqnPNoehc6"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### References\n",
        "- http://neuralnetworksanddeeplearning.com/\n",
        "- https://machinelearningmastery.com/a-gentle-introduction-to-sigmoid-function/\n",
        "- https://www.3blue1brown.com/topics/neural-networks\n",
        "- https://towardsdatascience.com/stochastic-gradient-descent-clearly-explained-53d239905d31?gi=7c68464316bd"
      ],
      "metadata": {
        "id": "5X2qhmFpehdC"
      }
    }
  ]
}