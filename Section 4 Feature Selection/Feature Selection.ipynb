{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "458eec78",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9daa97",
   "metadata": {},
   "source": [
    "# 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c244cd",
   "metadata": {},
   "source": [
    "Feature selection is a crucial step in data science that involves choosing the most relevant and informative features from a dataset to improve the performance of a machine learning model and reduce overfitting. There are various methods for feature selection, each with its advantages and use cases. Here are some common methods:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e077851c",
   "metadata": {},
   "source": [
    "### 1. Univariate Feature Selection:\n",
    "- Univariate feature selection methods consider each feature independently and rank them based on their individual relevance to the target variable. They are particularly useful for classification tasks with categorical target variables. Common univariate selection methods include chi-squared, ANOVA F-value, and mutual information.\n",
    "- SelectKBest: This method selects the top K features with the highest scores from a given statistical test. For instance, SelectKBest with chi-squared test is appropriate for categorical target variables, while SelectKBest with ANOVA is suitable for numerical target variables.\n",
    "- SelectPercentile: This method selects the top features based on a user-defined percentile of the highest-scoring features. It is useful when you want to keep a specific percentage of the most relevant features.\n",
    "\n",
    "### 2. Recursive Feature Elimination (RFE):\n",
    "- RFE is a recursive method that starts with all features and iteratively removes the least important feature at each step. It repeatedly trains the model and evaluates performance until the desired number of features is reached or the model's performance stops improving. RFE is applicable to both classification and regression problems and is commonly used with linear models and tree-based models like Random Forest.\n",
    "- It is important to note that RFE relies on model performance as the criterion for feature removal, and its effectiveness may depend on the choice of the underlying model.\n",
    "\n",
    "### 3. Lasso Regression (L1 Regularization):\n",
    "- Lasso regression introduces an L1 penalty term to the loss function, which results in some feature coefficients becoming exactly zero. This sparsity-inducing property of Lasso allows it to perform feature selection by effectively eliminating less important features. Lasso is suitable for linear models and can handle both regression and classification tasks.\n",
    "- The regularization strength (alpha) determines the degree of sparsity, and cross-validation can be used to find the optimal alpha value.\n",
    "\n",
    "### 4. Random Forest Feature Importance:\n",
    "- Random Forest is an ensemble learning method that builds multiple decision trees and combines their predictions. Feature importance is calculated based on the average impurity reduction (or information gain) from each feature across all trees. Features with higher importance scores are considered more relevant to the target variable.\n",
    "- Random Forest is a powerful and versatile model, making it well-suited for a wide range of problems. Feature importance from Random Forest can also be used to interpret the impact of features on the model's predictions.\n",
    "\n",
    "### 5. Recursive Feature Addition (RFA):\n",
    "- RFA is the opposite of RFE. It starts with an empty set of features and iteratively adds the most important feature based on model performance. This method can be useful when the goal is to identify a minimal set of features that achieve satisfactory model performance.\n",
    "\n",
    "### 6. Tree-based Methods:\n",
    "- Decision trees and tree-based ensembles, such as Gradient Boosting Machines, provide feature importances during the tree-building process. Tree-based models are capable of handling various data types (e.g., numerical and categorical) and can capture complex relationships between features and the target variable.\n",
    "- Feature importances from tree-based methods can be used to select the most informative features or gain insights into the underlying data patterns.\n",
    "\n",
    "### 7. Principal Component Analysis (PCA):\n",
    "- PCA is a dimensionality reduction technique that transforms the original features into a new set of uncorrelated variables called principal components. These components represent the maximum variance in the data. By selecting the top principal components, you effectively perform feature selection and reduce the dimensionality of the data.\n",
    "- PCA is particularly useful when dealing with high-dimensional datasets and can aid in visualization and computation efficiency.\n",
    "\n",
    "### 8. Regularization-Based Methods:\n",
    "- Regularization techniques, such as L1 (Lasso) and L2 (Ridge) regularization, can be applied to linear models to shrink or eliminate coefficients. L1 regularization results in sparse models by setting some coefficients to zero, while L2 regularization penalizes large coefficients without eliminating them entirely.\n",
    "- Regularization allows models to be more robust to multicollinearity and reduces the risk of overfitting when dealing with high-dimensional datasets.\n",
    "\n",
    "### 9. Feature Importance from Gradient Boosting Machines (GBM):\n",
    "- Gradient Boosting Machines (GBM) are a powerful ensemble method that builds decision trees sequentially, each tree attempting to correct the errors of its predecessors. Similar to Random Forest, GBM provides feature importances, which can be used for feature selection.\n",
    "- GBM's ability to handle both numerical and categorical features makes it applicable to a wide range of problems, and its feature importances can be leveraged to identify relevant features and improve model interpretability.\n",
    "\n",
    "### 10. Correlation-based Feature Selection:\n",
    "- Correlation-based feature selection aims to identify and remove features that have high correlation with one another. Highly correlated features can carry redundant information, leading to potential overfitting and model instability.\n",
    "- Before applying correlation-based feature selection, it's essential to preprocess and normalize the data to ensure meaningful correlation measures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0f2f0d",
   "metadata": {},
   "source": [
    "# 2. Load the California housing dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5088aff2",
   "metadata": {},
   "source": [
    "### 1. Introduction to the Iris Dataset:\n",
    "The California housing dataset is a widely-used dataset in machine learning and statistics. It was derived from the 1990 U.S. census and includes housing data from various districts in California. The dataset is often used for regression tasks, where the goal is to predict the median house value for each district based on several features.\n",
    "\n",
    "Here is a more detailed description of the features in the California housing dataset:\n",
    "\n",
    "1. MedInc: Median income of the households in the district. This feature represents the key predictor of the median house value. Districts with higher median incomes tend to have higher median house values.\n",
    "\n",
    "2. HouseAge: Median age of the houses in the district. This feature indicates the age of the housing structures in the district. Older houses might have lower values compared to newer ones.\n",
    "\n",
    "3. AveRooms: Average number of rooms in the houses in the district. This feature provides information about the average size of houses in the district. Larger houses may have higher median values.\n",
    "\n",
    "4. AveBedrms: Average number of bedrooms in the houses in the district. This feature reflects the average size of households. Districts with more bedrooms may have higher median house values.\n",
    "\n",
    "5. Population: Total population of the district. This feature gives an idea of the population density, which can be related to the housing demand and thus affect housing prices.\n",
    "\n",
    "6. AveOccup: Average household occupancy. This feature represents the average number of people living in a household. Higher occupancy might lead to higher demand for housing.\n",
    "\n",
    "7. Latitude: Latitude of the district's location. Geographical location can play a role in determining housing prices.\n",
    "\n",
    "8. Longitude: Longitude of the district's location. Similar to latitude, geographical location can influence housing values.\n",
    "\n",
    "9. MedHouseVal: Median house value for California districts (the target variable). This is the value we want to predict in a regression task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff5f892",
   "metadata": {},
   "source": [
    "### 2. Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "96c61375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, SelectPercentile, mutual_info_regression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_selection import RFE, VarianceThreshold, SelectFromModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ecd9af",
   "metadata": {},
   "source": [
    "- We import the required libraries: `numpy` for numerical computations, `pandas` for data manipulation, and various feature selection methods and models from scikit-learn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e98905",
   "metadata": {},
   "source": [
    "### 3. Load the California housing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4b711780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the California housing dataset\n",
    "california = fetch_california_housing()\n",
    "X = california.data\n",
    "y = california.target\n",
    "feature_names = california.feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d2b501",
   "metadata": {},
   "source": [
    "- We load the California housing dataset using `fetch_california_housing()`.\n",
    "- We extract the input features (`X`), target variable (`y`), and feature names (`feature_names`) from the dataset.\n",
    "\n",
    "\n",
    "Now, let's move on to each feature selection method and explain the code for each part:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cf6965",
   "metadata": {},
   "source": [
    "# 3. Univariate Feature Selection using SelectKBest with F-regression scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b4c2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_best = SelectKBest(score_func=f_regression, k=3)\n",
    "X_k_best = k_best.fit_transform(X, y)\n",
    "selected_feature_names_k_best = [feature_names[i] for i in k_best.get_support(indices=True)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686790b9",
   "metadata": {},
   "source": [
    "- We create a `SelectKBest` object with `score_func=f_regression` to perform univariate feature selection using F-regression scoring.\n",
    "- We set `k=3` to select the top 3 features with the highest F-values.\n",
    "- `k_best.fit_transform(X, y)` fits the feature selection model to the data and transforms the data to include only the selected features.\n",
    "- `k_best.get_support(indices=True)` returns the indices of the selected features.\n",
    "- We use list comprehension to extract the names of the selected features from `feature_names`, and store them in `selected_feature_names_k_best`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b0fc3b14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>Latitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>37.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>37.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>37.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>37.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>37.85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  AveRooms  Latitude\n",
       "0  8.3252  6.984127     37.88\n",
       "1  8.3014  6.238137     37.86\n",
       "2  7.2574  8.288136     37.85\n",
       "3  5.6431  5.817352     37.85\n",
       "4  3.8462  6.281853     37.85"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_k_best = pd.DataFrame(data=X_k_best, columns=selected_feature_names_k_best)\n",
    "df_k_best.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec49d9a",
   "metadata": {},
   "source": [
    "# 4. Univariate Feature Selection using SelectPercentile with Mutual Information scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "53ffb75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentile_selector = SelectPercentile(score_func=mutual_info_regression, percentile=50)\n",
    "X_percentile = percentile_selector.fit_transform(X, y)\n",
    "selected_feature_names_percentile = [feature_names[i] for i in percentile_selector.get_support(indices=True)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02ff314",
   "metadata": {},
   "source": [
    "- We create a `SelectPercentile` object with `score_func=mutual_info_regression` to perform univariate feature selection using mutual information scoring.\n",
    "- We set `percentile=50` to select the top 50% of features with the highest mutual information.\n",
    "- `percentile_selector.fit_transform(X, y)` fits the feature selection model to the data and transforms the data to include only the selected features.\n",
    "- `percentile_selector.get_support(indices=True)` returns the indices of the selected features.\n",
    "- We use list comprehension to extract the names of the selected features from feature_names, and store them in `selected_feature_names_percentile`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3294bed2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  AveRooms  Latitude  Longitude\n",
       "0  8.3252  6.984127     37.88    -122.23\n",
       "1  8.3014  6.238137     37.86    -122.22\n",
       "2  7.2574  8.288136     37.85    -122.24\n",
       "3  5.6431  5.817352     37.85    -122.25\n",
       "4  3.8462  6.281853     37.85    -122.25"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_percentile = pd.DataFrame(data=X_percentile, columns=selected_feature_names_percentile)\n",
    "df_percentile.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b31386",
   "metadata": {},
   "source": [
    "# 5. Lasso Regression (L1 Regularization) for Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "071a3f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = Lasso(alpha=0.1)\n",
    "lasso.fit(X, y)\n",
    "lasso_selected_features = np.where(lasso.coef_ != 0)[0]\n",
    "X_lasso = X[:, lasso_selected_features]\n",
    "selected_feature_names_lasso = [feature_names[i] for i in lasso_selected_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebde1835",
   "metadata": {},
   "source": [
    "- We create a `Lasso` object with `alpha=0.1` to perform feature selection based on L1 regularization.\n",
    "- `lasso.fit(X, y)` fits the Lasso regression model to the data.\n",
    "- `np.where(lasso.coef_ != 0)[0]` returns the indices of non-zero coefficients, which correspond to the selected features.\n",
    "- `X[:, lasso_selected_features]` selects the data with the selected features.\n",
    "- We use list comprehension to extract the names of the selected features from `feature_names`, and store them in `selected_feature_names_lasso`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "82f734d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  Population  AveOccup  Latitude  Longitude\n",
       "0  8.3252      41.0       322.0  2.555556     37.88    -122.23\n",
       "1  8.3014      21.0      2401.0  2.109842     37.86    -122.22\n",
       "2  7.2574      52.0       496.0  2.802260     37.85    -122.24\n",
       "3  5.6431      52.0       558.0  2.547945     37.85    -122.25\n",
       "4  3.8462      52.0       565.0  2.181467     37.85    -122.25"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lasso = pd.DataFrame(data=X_lasso, columns=selected_feature_names_lasso)\n",
    "df_lasso.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71f5c0e",
   "metadata": {},
   "source": [
    "# 6. Random Forest Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b4b6c514",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestRegressor(random_state=42)\n",
    "forest.fit(X, y)\n",
    "importances = forest.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "X_forest_importance = X[:, indices[:3]]\n",
    "selected_feature_names_forest = [feature_names[i] for i in indices[:3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae45476",
   "metadata": {},
   "source": [
    "- We create a `RandomForestRegressor` object to determine feature importance using Random Forest.\n",
    "- `forest.fit(X, y)` fits the Random Forest model to the data.\n",
    "- `forest.feature_importances_ stores` the feature importances calculated by the model.\n",
    "- `np.argsort(importances)[::-1]` sorts the importances in descending order and returns the indices of the sorted features.\n",
    "- `X[:, indices[:3]]` selects the data with the top 3 most important features.\n",
    "- We use list comprehension to extract the names of the selected features from `feature_names`, and store them in `selected_feature_names_forest`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5e612972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  AveOccup  Latitude\n",
       "0  8.3252  2.555556     37.88\n",
       "1  8.3014  2.109842     37.86\n",
       "2  7.2574  2.802260     37.85\n",
       "3  5.6431  2.547945     37.85\n",
       "4  3.8462  2.181467     37.85"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_forest = pd.DataFrame(data=X_forest_importance, columns=selected_feature_names_forest)\n",
    "df_forest.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e6c269",
   "metadata": {},
   "source": [
    "# 7. Recursive Feature Elimination (RFE) with a Random Forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c6dab8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe_selector = RFE(estimator=forest, n_features_to_select=3, step=1)\n",
    "X_rfe = rfe_selector.fit_transform(X, y)\n",
    "selected_feature_names_rfe = [feature_names[i] for i in rfe_selector.get_support(indices=True)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb40d09",
   "metadata": {},
   "source": [
    "- We create an `RFE` object with `estimator=forest` to perform recursive feature elimination using the Random Forest model.\n",
    "- We set `n_features_to_select=3` to select the top 3 features recursively.\n",
    "- `rfe_selector.fit_transform(X, y)` fits the RFE model to the data and transforms the data to include only the selected features.\n",
    "- `rfe_selector.get_support(indices=True)` returns the indices of the selected features.\n",
    "- We use list comprehension to extract the names of the selected features from `feature_names`, and store them in `selected_feature_names_rfe`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0b18948e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>-122.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>-122.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>-122.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>-122.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>-122.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  AveOccup  Longitude\n",
       "0  8.3252  2.555556    -122.23\n",
       "1  8.3014  2.109842    -122.22\n",
       "2  7.2574  2.802260    -122.24\n",
       "3  5.6431  2.547945    -122.25\n",
       "4  3.8462  2.181467    -122.25"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rfe = pd.DataFrame(data=X_rfe, columns=selected_feature_names_rfe)\n",
    "df_rfe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079cb451",
   "metadata": {},
   "source": [
    "# 8. Variance Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7af66b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "variance_selector = VarianceThreshold(threshold=0.1)\n",
    "X_variance = variance_selector.fit_transform(X)\n",
    "selected_feature_names_variance = [feature_names[i] for i in variance_selector.get_support(indices=True)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea8ae32",
   "metadata": {},
   "source": [
    "- We create a `VarianceThreshold` object with `threshold=0.1` to remove features with low variance.\n",
    "- `variance_selector.fit_transform(X)` fits the feature selection model to the data and transforms the data to include only the selected features.\n",
    "- `variance_selector.get_support(indices=True)` returns the indices of the selected features.\n",
    "- We use list comprehension to extract the names of the selected features from `feature_names`, and store them in `selected_feature_names_variance`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "852617a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "\n",
       "   Longitude  \n",
       "0    -122.23  \n",
       "1    -122.22  \n",
       "2    -122.24  \n",
       "3    -122.25  \n",
       "4    -122.25  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_variance = pd.DataFrame(data=X_variance, columns=selected_feature_names_variance)\n",
    "df_variance.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c33ce5",
   "metadata": {},
   "source": [
    "# 9. SelectFromModel with L1-based feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0a87213e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sfm = SelectFromModel(estimator=forest, threshold=0.1)\n",
    "X_sfm = sfm.fit_transform(X, y)\n",
    "selected_feature_names_sfm = [feature_names[i] for i in sfm.get_support(indices=True)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6930d86f",
   "metadata": {},
   "source": [
    "- We create a `SelectFromModel` object with estimator=forest to perform L1-based feature selection using the Random Forest model.\n",
    "- We set `threshold=0.1` to select features with importance greater than the threshold.\n",
    "- `sfm.fit_transform(X, y)` fits the feature selection model to the data and transforms the data to include only the selected features.\n",
    "- `sfm.get_support(indices=True)` returns the indices of the selected features.\n",
    "- We use list comprehension to extract the names of the selected features from `feature_names`, and store them in `selected_feature_names_sfm`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "216c43cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>AveOccup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>2.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>2.109842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>2.802260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>2.547945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>2.181467</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  AveOccup\n",
       "0  8.3252  2.555556\n",
       "1  8.3014  2.109842\n",
       "2  7.2574  2.802260\n",
       "3  5.6431  2.547945\n",
       "4  3.8462  2.181467"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sfm = pd.DataFrame(data=X_sfm, columns=selected_feature_names_sfm)\n",
    "df_sfm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311439b3",
   "metadata": {},
   "source": [
    "# 10. Pinting the Name of the Seclected Features for each Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c3554925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features using SelectKBest (F-regression scoring):\n",
      "['MedInc', 'AveRooms', 'Latitude']\n",
      "\n",
      "Selected features using SelectPercentile (Mutual Information scoring):\n",
      "['MedInc', 'AveRooms', 'Latitude', 'Longitude']\n",
      "\n",
      "Selected features using Lasso Regression (L1 Regularization):\n",
      "['MedInc', 'HouseAge', 'Population', 'AveOccup', 'Latitude', 'Longitude']\n",
      "\n",
      "Selected features using Random Forest Feature Importance:\n",
      "['MedInc', 'AveOccup', 'Latitude']\n",
      "\n",
      "Selected features using Recursive Feature Elimination (RFE) with Random Forest:\n",
      "['MedInc', 'AveOccup', 'Longitude']\n",
      "\n",
      "Selected features using Variance Thresholding:\n",
      "['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup', 'Latitude', 'Longitude']\n",
      "\n",
      "Selected features using SelectFromModel with L1-based feature selection:\n",
      "['MedInc', 'AveOccup']\n"
     ]
    }
   ],
   "source": [
    "print(\"Selected features using SelectKBest (F-regression scoring):\")\n",
    "print(selected_feature_names_k_best)\n",
    "\n",
    "print(\"\\nSelected features using SelectPercentile (Mutual Information scoring):\")\n",
    "print(selected_feature_names_percentile)\n",
    "\n",
    "print(\"\\nSelected features using Lasso Regression (L1 Regularization):\")\n",
    "print(selected_feature_names_lasso)\n",
    "\n",
    "print(\"\\nSelected features using Random Forest Feature Importance:\")\n",
    "print(selected_feature_names_forest)\n",
    "\n",
    "print(\"\\nSelected features using Recursive Feature Elimination (RFE) with Random Forest:\")\n",
    "print(selected_feature_names_rfe)\n",
    "\n",
    "print(\"\\nSelected features using Variance Thresholding:\")\n",
    "print(selected_feature_names_variance)\n",
    "\n",
    "print(\"\\nSelected features using SelectFromModel with L1-based feature selection:\")\n",
    "print(selected_feature_names_sfm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34eb12fe",
   "metadata": {},
   "source": [
    "# 11. Methods comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "380c3352",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "def decision_tree_func(df, y = california.target):\n",
    "    # Separate features and target\n",
    "    X = df  # Features\n",
    "\n",
    "    # Split the data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "    # Create a decision tree regressor\n",
    "    tree = DecisionTreeRegressor()\n",
    "\n",
    "    # Fit the model on the training data\n",
    "    tree.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the test data\n",
    "    y_pred = tree.predict(X_test)\n",
    "\n",
    "    # Calculate the mean squared error (MSE)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "    # Calculate the mean absolute error (MAE)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "    # Calculate the R-squared (coefficient of determination)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    # Print the predicted values, MSE, MAE, and R-squared\n",
    "    print(\"Mean Squared Error:\", mse)\n",
    "    print(\"Mean Absolute Error:\", mae)\n",
    "    print(\"R-squared:\", r2)\n",
    "\n",
    "    return r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ab20e55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of feature selection methods\n",
    "feature_selection_methods = [\n",
    "    \"SelectKBest (F-regression scoring)\",\n",
    "    \"SelectPercentile (Mutual Information scoring)\",\n",
    "    \"Lasso Regression (L1 Regularization)\",\n",
    "    \"Random Forest Feature Importance\",\n",
    "    \"Recursive Feature Elimination (RFE) with Random Forest\",\n",
    "    \"Variance Thresholding\",\n",
    "    \"SelectFromModel with L1-based feature selection\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "9962b950",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list =  [df_k_best, df_percentile, df_lasso, df_forest, df_rfe, df_variance, df_sfm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "e0872475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SelectKBest (F-regression scoring):\n",
      "Mean Squared Error: 0.970543324312088\n",
      "Mean Absolute Error: 0.6727642999031007\n",
      "R-squared: 0.25569256836322907\n",
      "\n",
      "SelectPercentile (Mutual Information scoring):\n",
      "Mean Squared Error: 0.4101511023006056\n",
      "Mean Absolute Error: 0.4078502156007752\n",
      "R-squared: 0.6854560678651489\n",
      "\n",
      "Lasso Regression (L1 Regularization):\n",
      "Mean Squared Error: 0.467098898478125\n",
      "Mean Absolute Error: 0.4406198570736434\n",
      "R-squared: 0.6417829346329904\n",
      "\n",
      "Random Forest Feature Importance:\n",
      "Mean Squared Error: 0.7631435721311046\n",
      "Mean Absolute Error: 0.5934224127906976\n",
      "R-squared: 0.41474695882781343\n",
      "\n",
      "Recursive Feature Elimination (RFE) with Random Forest:\n",
      "Mean Squared Error: 0.7399170514728439\n",
      "Mean Absolute Error: 0.5773742708333334\n",
      "R-squared: 0.4325593238237416\n",
      "\n",
      "Variance Thresholding:\n",
      "Mean Squared Error: 0.5317524887394863\n",
      "Mean Absolute Error: 0.4692128536821705\n",
      "R-squared: 0.5922002457327926\n",
      "\n",
      "SelectFromModel with L1-based feature selection:\n",
      "Mean Squared Error: 1.0750386456495882\n",
      "Mean Absolute Error: 0.7490424297480621\n",
      "R-squared: 0.17555534800997885\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy_dict = {}\n",
    "\n",
    "for i in range(len(df_list)):\n",
    "    print(feature_selection_methods[i] + \":\")\n",
    "    \n",
    "    accuracy_dict.update({feature_selection_methods[i]:decision_tree_func(df_list[i])})\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "ccd3a306",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SelectKBest (F-regression scoring)': 0.25569256836322907,\n",
       " 'SelectPercentile (Mutual Information scoring)': 0.6854560678651489,\n",
       " 'Lasso Regression (L1 Regularization)': 0.6417829346329904,\n",
       " 'Random Forest Feature Importance': 0.41474695882781343,\n",
       " 'Recursive Feature Elimination (RFE) with Random Forest': 0.4325593238237416,\n",
       " 'Variance Thresholding': 0.5922002457327926,\n",
       " 'SelectFromModel with L1-based feature selection': 0.17555534800997885}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b20663e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SelectPercentile (Mutual Information scoring)</th>\n",
       "      <td>0.685456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso Regression (L1 Regularization)</th>\n",
       "      <td>0.641783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Variance Thresholding</th>\n",
       "      <td>0.592200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recursive Feature Elimination (RFE) with Random Forest</th>\n",
       "      <td>0.432559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest Feature Importance</th>\n",
       "      <td>0.414747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SelectKBest (F-regression scoring)</th>\n",
       "      <td>0.255693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SelectFromModel with L1-based feature selection</th>\n",
       "      <td>0.175555</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Accuracy\n",
       "SelectPercentile (Mutual Information scoring)       0.685456\n",
       "Lasso Regression (L1 Regularization)                0.641783\n",
       "Variance Thresholding                               0.592200\n",
       "Recursive Feature Elimination (RFE) with Random...  0.432559\n",
       "Random Forest Feature Importance                    0.414747\n",
       "SelectKBest (F-regression scoring)                  0.255693\n",
       "SelectFromModel with L1-based feature selection     0.175555"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalleaderboard = pd.DataFrame.from_dict(accuracy_dict, orient='index', columns=['Accuracy'])\n",
    "finalleaderboard = finalleaderboard.sort_values('Accuracy', ascending=False)\n",
    "finalleaderboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f4fe01ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['MedInc', 'AveRooms', 'Latitude', 'Longitude'], dtype='object')"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_percentile.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
